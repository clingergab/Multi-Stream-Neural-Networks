[
  {
    "combination_id": 0,
    "parameters": {
      "learning_rate": 0.001,
      "batch_size": 64,
      "optimizer": "sgd",
      "weight_decay": 1e-05,
      "scheduler": "cosine",
      "transform": true
    },
    "metrics": {
      "best_val_loss": Infinity,
      "best_val_accuracy": 0.0,
      "final_val_loss": Infinity,
      "final_val_accuracy": 0.0,
      "epochs_completed": 0,
      "converged": false,
      "early_stopped": false,
      "early_stopping_info": {},
      "error": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/Users/gclinger/Documents/projects/Multi-Stream-Neural-Networks/src/data_utils/dual_channel_dataset.py\", line 99, in __getitem__\n    brightness = self.transform(brightness)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n          ^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 277, in forward\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 350, in normalize\n    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/_functional_tensor.py\", line 928, in normalize\n    return tensor.sub_(mean).div_(std)\n           ^^^^^^^^^^^^^^^^^\nRuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]\n"
    },
    "start_time": "2025-07-09T21:53:46.296244",
    "end_time": "2025-07-09T21:53:49.316372",
    "duration_minutes": 0.05033546666666667
  },
  {
    "combination_id": 1,
    "parameters": {
      "learning_rate": 0.001,
      "batch_size": 64,
      "optimizer": "sgd",
      "weight_decay": 1e-05,
      "scheduler": "cosine",
      "transform": false
    },
    "metrics": {
      "best_val_loss": Infinity,
      "best_val_accuracy": 0.0,
      "final_val_loss": Infinity,
      "final_val_accuracy": 0.0,
      "epochs_completed": 0,
      "converged": false,
      "early_stopped": false,
      "early_stopping_info": {},
      "error": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/Users/gclinger/Documents/projects/Multi-Stream-Neural-Networks/src/data_utils/dual_channel_dataset.py\", line 99, in __getitem__\n    brightness = self.transform(brightness)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n          ^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 277, in forward\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 350, in normalize\n    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/_functional_tensor.py\", line 928, in normalize\n    return tensor.sub_(mean).div_(std)\n           ^^^^^^^^^^^^^^^^^\nRuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]\n"
    },
    "start_time": "2025-07-09T21:53:49.316745",
    "end_time": "2025-07-09T21:53:52.417740",
    "duration_minutes": 0.05168325
  }
]