[
  {
    "combination_id": 0,
    "parameters": {
      "learning_rate": 0.001,
      "batch_size": 64,
      "optimizer": "sgd",
      "weight_decay": 1e-05,
      "scheduler": "cosine",
      "transform": true
    },
    "metrics": {
      "best_val_loss": Infinity,
      "best_val_accuracy": 0.0,
      "final_val_loss": Infinity,
      "final_val_accuracy": 0.0,
      "epochs_completed": 0,
      "converged": false,
      "early_stopped": false,
      "early_stopping_info": {},
      "error": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/Users/gclinger/Documents/projects/Multi-Stream-Neural-Networks/src/data_utils/dual_channel_dataset.py\", line 94, in __getitem__\n    rgb = self.transform(rgb)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n          ^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n    return F.to_tensor(pic)\n           ^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 142, in to_tensor\n    raise TypeError(f\"pic should be PIL Image or ndarray. Got {type(pic)}\")\nTypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>\n"
    },
    "start_time": "2025-07-09T21:51:38.102034",
    "end_time": "2025-07-09T21:51:41.224813",
    "duration_minutes": 0.05204631666666667
  }
]