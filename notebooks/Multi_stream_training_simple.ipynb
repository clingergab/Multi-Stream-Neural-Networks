{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5999f8",
   "metadata": {},
   "source": [
    "# Multi-Stream Neural Networks Training (Simplified)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates multi-stream neural network training using a **simplified approach** that follows the successful methodology from `test_dual_stream_proper.py`. This approach avoids the complex augmentation pipeline that caused training issues in the original notebook.\n",
    "\n",
    "### Key Differences from Original Notebook:\n",
    "- **Batch Size**: Uses `batch_size=32` (instead of 512) for optimal multi-stream training\n",
    "- **Simple Data Pipeline**: Direct tensor conversion without complex augmentation \n",
    "- **Proven Approach**: Based on successful test results showing 49.6% validation accuracy\n",
    "\n",
    "### Models Tested:\n",
    "1. **BaseMultiChannelNetwork**: Dense/fully-connected multi-stream model\n",
    "2. **MultiChannelResNetNetwork**: CNN-based ResNet multi-stream model\n",
    "\n",
    "### Expected Results:\n",
    "Based on our successful test runs:\n",
    "- RGB only: ~46.0% validation accuracy\n",
    "- Brightness only: ~40.6% validation accuracy  \n",
    "- **RGB + Brightness (dual stream): ~49.6% validation accuracy**\n",
    "\n",
    "This notebook validates that multi-stream fusion works well when trained with appropriate hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef389a2d",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Configure the Python environment and check for available hardware acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768b9edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/gclinger/Documents/projects/Multi-Stream-Neural-Networks\n",
      "Current working directory: /Users/gclinger/Documents/projects/Multi-Stream-Neural-Networks/notebooks\n",
      "‚úÖ Added /Users/gclinger/Documents/projects/Multi-Stream-Neural-Networks to sys.path\n",
      "‚úÖ Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up project root path\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / \"src\").exists() and project_root != project_root.parent:\n",
    "    project_root = project_root.parent\n",
    "\n",
    "if not (project_root / \"src\").exists():\n",
    "    # Fallback: assume we're in notebooks directory\n",
    "    project_root = Path.cwd().parent\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Add project root to path for imports\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"‚úÖ Added {project_root} to sys.path\")\n",
    "\n",
    "# Set environment variables for better error reporting\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ba737",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "Import all necessary libraries including PyTorch, visualization tools, and custom model classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663419d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Importing libraries...\n",
      "‚úÖ All project modules imported successfully\n",
      "üöÄ Using Apple Metal Performance Shaders (MPS)\n",
      "PyTorch version: 2.7.1\n",
      "Device: mps\n",
      "‚úÖ Library imports complete!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "print(\"üì¶ Importing libraries...\")\n",
    "\n",
    "# Core PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization and analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Project imports\n",
    "try:\n",
    "    from src.data_utils.dataset_utils import load_cifar100_data, CIFAR100_FINE_LABELS\n",
    "    from src.data_utils.rgb_to_rgbl import RGBtoRGBL\n",
    "    from src.models.basic_multi_channel.base_multi_channel_network import base_multi_channel_large\n",
    "    from src.models.basic_multi_channel.multi_channel_resnet_network import multi_channel_resnet50\n",
    "    print(\"‚úÖ All project modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing project modules: {e}\")\n",
    "    print(\"‚ö†Ô∏è  Please ensure you're running from the correct directory\")\n",
    "\n",
    "# Check device availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üöÄ Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") \n",
    "    print(\"üöÄ Using Apple Metal Performance Shaders (MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"üíª Using CPU\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"‚úÖ Library imports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285efda0",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "\n",
    "Load CIFAR-100 dataset using the same approach as in `test_dual_stream_proper.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1778ab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading CIFAR-100 data...\n",
      "üìÅ Loading CIFAR-100 from: ../data/cifar-100\n",
      "‚úÖ Loaded CIFAR-100 (torch format):\n",
      "   Training: torch.Size([50000, 3, 32, 32]), labels: 50000\n",
      "   Test: torch.Size([10000, 3, 32, 32]), labels: 10000\n",
      "‚úÖ Data loaded:\n",
      "   Training: torch.Size([50000, 3, 32, 32]), labels: 50000\n",
      "   Test: torch.Size([10000, 3, 32, 32]), labels: 10000\n",
      "   Classes: 100\n",
      "‚úÖ Data split complete:\n",
      "   Training: torch.Size([45000, 3, 32, 32]), labels: 45000\n",
      "   Validation: torch.Size([5000, 3, 32, 32]), labels: 5000\n",
      "   Test: torch.Size([10000, 3, 32, 32]), labels: 10000\n",
      "‚úÖ Final tensor shapes:\n",
      "   Training: torch.Size([45000, 3, 32, 32]), labels: torch.Size([45000])\n",
      "   Validation: torch.Size([5000, 3, 32, 32]), labels: torch.Size([5000])\n",
      "   Test: torch.Size([10000, 3, 32, 32]), labels: torch.Size([10000])\n",
      "   Data range: [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-100 Data (simplified approach)\n",
    "print(\"üìä Loading CIFAR-100 data...\")\n",
    "\n",
    "# Load data using our simplified loader\n",
    "train_data, train_labels, test_data, test_labels = load_cifar100_data(\n",
    "    data_dir=\"../data/cifar-100\",\n",
    "    normalize=True  # Apply normalization to [0, 1] range\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loaded:\")\n",
    "print(f\"   Training: {train_data.shape}, labels: {len(train_labels)}\")\n",
    "print(f\"   Test: {test_data.shape}, labels: {len(test_labels)}\")\n",
    "print(f\"   Classes: {len(CIFAR100_FINE_LABELS)}\")\n",
    "\n",
    "# Create validation split using sklearn (10% - same as successful test)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    train_data, train_labels,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=train_labels  # Ensure balanced validation split\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data split complete:\")\n",
    "print(f\"   Training: {train_data.shape}, labels: {len(train_labels)}\")\n",
    "print(f\"   Validation: {val_data.shape}, labels: {len(val_labels)}\")\n",
    "print(f\"   Test: {test_data.shape}, labels: {len(test_labels)}\")\n",
    "\n",
    "# Convert to PyTorch tensors if needed (the function returns numpy arrays)\n",
    "if isinstance(train_data, np.ndarray):\n",
    "    train_data = torch.from_numpy(train_data).float()\n",
    "    train_labels = torch.from_numpy(train_labels).long()\n",
    "    val_data = torch.from_numpy(val_data).float()\n",
    "    val_labels = torch.from_numpy(val_labels).long()\n",
    "    test_data = torch.from_numpy(test_data).float()\n",
    "    test_labels = torch.from_numpy(test_labels).long()\n",
    "\n",
    "print(f\"‚úÖ Final tensor shapes:\")\n",
    "print(f\"   Training: {train_data.shape}, labels: {train_labels.shape}\")\n",
    "print(f\"   Validation: {val_data.shape}, labels: {val_labels.shape}\")\n",
    "print(f\"   Test: {test_data.shape}, labels: {test_labels.shape}\")\n",
    "print(f\"   Data range: [{train_data.min():.3f}, {train_data.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27543835",
   "metadata": {},
   "source": [
    "## 4. Process Data - Convert to RGB+L\n",
    "\n",
    "Convert RGB images to RGB + Brightness (luminance) streams using the exact same approach as the successful test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5d74b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating brightness streams from RGB...\n",
      "‚úÖ Dual-stream setup complete:\n",
      "   Color stream: train_data, val_data, test_data\n",
      "   Brightness stream: train_brightness, val_brightness, test_brightness\n",
      "   Labels: train_labels, val_labels, test_labels\n",
      "   Using standard luminance weights: 0.299*R + 0.587*G + 0.114*B\n",
      "   RGB range: [0.000, 1.000]\n",
      "   Brightness range: [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# Create brightness streams from RGB data using RGBtoRGBL utility\n",
    "print(\"üîß Creating brightness streams from RGB...\")\n",
    "\n",
    "# Initialize the RGB to brightness converter\n",
    "rgb_to_rgbl = RGBtoRGBL()\n",
    "\n",
    "# Extract only brightness components (more efficient than __call__ when we only need brightness)\n",
    "# Uses standard luminance formula: 0.299*R + 0.587*G + 0.114*B\n",
    "train_color, train_brightness = train_data, rgb_to_rgbl.get_brightness(train_data)\n",
    "val_color, val_brightness = val_data, rgb_to_rgbl.get_brightness(val_data)\n",
    "test_color, test_brightness = test_data, rgb_to_rgbl.get_brightness(test_data)\n",
    "\n",
    "print(\"‚úÖ Dual-stream setup complete:\")\n",
    "print(\"   Color stream: train_data, val_data, test_data\")\n",
    "print(\"   Brightness stream: train_brightness, val_brightness, test_brightness\")\n",
    "print(\"   Labels: train_labels, val_labels, test_labels\")\n",
    "print(\"   Using standard luminance weights: 0.299*R + 0.587*G + 0.114*B\")\n",
    "print(f\"   RGB range: [{train_color.min():.3f}, {train_color.max():.3f}]\")\n",
    "print(f\"   Brightness range: [{train_brightness.min():.3f}, {train_brightness.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280671fe",
   "metadata": {},
   "source": [
    "## 5. Data Verification\n",
    "\n",
    "Verify the shapes, types, and ranges of processed data to ensure correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593dae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying processed data structure and consistency...\n",
      "‚úÖ All data verification checks passed!\n",
      "   Training samples: 45,000\n",
      "   Validation samples: 5,000\n",
      "   Test samples: 10,000\n",
      "   Total samples: 60,000\n",
      "   Brightness derivation check: max difference = 0.000000 (should be ~0)\n",
      "   ‚úÖ Brightness correctly derived from RGB\n",
      "‚úÖ All data verification checks passed!\n",
      "   Training samples: 45,000\n",
      "   Validation samples: 5,000\n",
      "   Test samples: 10,000\n",
      "   Total samples: 60,000\n",
      "   Brightness derivation check: max difference = 0.000000 (should be ~0)\n",
      "   ‚úÖ Brightness correctly derived from RGB\n"
     ]
    }
   ],
   "source": [
    "# Data Verification\n",
    "print(\"üîç Verifying processed data structure and consistency...\")\n",
    "\n",
    "def verify_data_integrity(rgb_data, brightness_data, labels, split_name):\n",
    "    \"\"\"Verify data shapes and consistency\"\"\"\n",
    "    # Check shapes and types\n",
    "    assert rgb_data.shape[0] == brightness_data.shape[0] == labels.shape[0], f\"Inconsistent sample counts in {split_name}!\"\n",
    "    assert rgb_data.shape[1:] == (3, 32, 32), f\"Unexpected RGB shape in {split_name}! Got {rgb_data.shape[1:]}\"\n",
    "    assert brightness_data.shape[1:] == (1, 32, 32), f\"Unexpected brightness shape in {split_name}! Got {brightness_data.shape[1:]}\"\n",
    "    assert 0 <= labels.min() and labels.max() < 100, f\"Invalid label range in {split_name}! Range: [{labels.min()}, {labels.max()}]\"\n",
    "    \n",
    "    # Check data types\n",
    "    assert rgb_data.dtype == torch.float32, f\"RGB data should be float32, got {rgb_data.dtype}\"\n",
    "    assert brightness_data.dtype == torch.float32, f\"Brightness data should be float32, got {brightness_data.dtype}\"\n",
    "    assert labels.dtype == torch.int64, f\"Labels should be int64, got {labels.dtype}\"\n",
    "    \n",
    "    # Check value ranges\n",
    "    assert 0 <= rgb_data.min() and rgb_data.max() <= 1, f\"RGB values out of range [0,1]: [{rgb_data.min():.3f}, {rgb_data.max():.3f}]\"\n",
    "    assert 0 <= brightness_data.min() and brightness_data.max() <= 1, f\"Brightness values out of range [0,1]: [{brightness_data.min():.3f}, {brightness_data.max():.3f}]\"\n",
    "    \n",
    "    return rgb_data.shape[0]\n",
    "\n",
    "# Verify all splits using consistent naming\n",
    "train_samples = verify_data_integrity(train_color, train_brightness, train_labels, \"Training\")\n",
    "val_samples = verify_data_integrity(val_color, val_brightness, val_labels, \"Validation\")\n",
    "test_samples = verify_data_integrity(test_color, test_brightness, test_labels, \"Test\")\n",
    "\n",
    "total_samples = train_samples + val_samples + test_samples\n",
    "print(f\"‚úÖ All data verification checks passed!\")\n",
    "print(f\"   Training samples: {train_samples:,}\")\n",
    "print(f\"   Validation samples: {val_samples:,}\")\n",
    "print(f\"   Test samples: {test_samples:,}\")\n",
    "print(f\"   Total samples: {total_samples:,}\")\n",
    "\n",
    "# Additional verification: brightness is indeed derived from RGB\n",
    "sample_idx = 0\n",
    "rgb_sample = train_color[sample_idx]\n",
    "brightness_sample = train_brightness[sample_idx]\n",
    "manual_brightness = 0.299 * rgb_sample[0] + 0.587 * rgb_sample[1] + 0.114 * rgb_sample[2]\n",
    "brightness_diff = torch.abs(brightness_sample[0] - manual_brightness).max()\n",
    "print(f\"   Brightness derivation check: max difference = {brightness_diff:.6f} (should be ~0)\")\n",
    "assert brightness_diff < 1e-6, \"Brightness not properly derived from RGB!\"\n",
    "print(\"   ‚úÖ Brightness correctly derived from RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf30fb4",
   "metadata": {},
   "source": [
    "## 6. Data Visualization\n",
    "\n",
    "Visualize sample images from both RGB and brightness streams to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee552818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëÅÔ∏è Visualizing sample images from both RGB and brightness streams...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data visualization complete!\n",
      "üìä Key observations:\n",
      "   - RGB images show full color information\n",
      "   - Brightness images capture luminance patterns\n",
      "   - Both streams contain useful visual information\n",
      "   - Brightness is mathematically derived from RGB (correlated but informative)\n"
     ]
    }
   ],
   "source": [
    "# Data Visualization\n",
    "print(\"üëÅÔ∏è Visualizing sample images from both RGB and brightness streams...\")\n",
    "\n",
    "# Set up visualization\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "fig.suptitle('Multi-Stream CIFAR-100 Samples: RGB vs Brightness', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Select random samples for visualization\n",
    "np.random.seed(42)  # For reproducible results\n",
    "sample_indices = np.random.choice(len(train_color), 4, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    # Get data using consistent naming\n",
    "    rgb_img = train_color[idx]\n",
    "    brightness_img = train_brightness[idx]\n",
    "    label = train_labels[idx].item()\n",
    "    class_name = CIFAR100_FINE_LABELS[label]\n",
    "    \n",
    "    # Convert tensors to NumPy arrays for matplotlib\n",
    "    rgb_np = rgb_img.permute(1, 2, 0).cpu().numpy()\n",
    "    rgb_np = np.clip(rgb_np, 0, 1)  # Ensure valid range\n",
    "    \n",
    "    # Brightness image (single channel)\n",
    "    brightness_np = brightness_img.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Plot RGB\n",
    "    axes[0, i].imshow(rgb_np)\n",
    "    axes[0, i].set_title(f'RGB: {class_name}', fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot Brightness\n",
    "    axes[1, i].imshow(brightness_np, cmap='gray')\n",
    "    axes[1, i].set_title(f'Brightness: {class_name}', fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Data visualization complete!\")\n",
    "print(\"üìä Key observations:\")\n",
    "print(\"   - RGB images show full color information\")\n",
    "print(\"   - Brightness images capture luminance patterns\")\n",
    "print(\"   - Both streams contain useful visual information\")\n",
    "print(\"   - Brightness is mathematically derived from RGB (correlated but informative)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa70af",
   "metadata": {},
   "source": [
    "## 7. Data Analysis\n",
    "\n",
    "Perform basic statistical analysis on the dataset including class distribution and channel statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "301a142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Performing comprehensive data analysis...\n",
      "\n",
      "üè∑Ô∏è Class distribution analysis:\n",
      "   Classes with samples: 100/100\n",
      "   Min samples per class: 450\n",
      "   Max samples per class: 450\n",
      "   Mean samples per class: 450.0\n",
      "   Std samples per class: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé® RGB vs Brightness stream characteristics:\n",
      "   üé® RGB statistics:\n",
      "      Mean: 0.478, Std: 0.268\n",
      "      Min: 0.000, Max: 1.000\n",
      "   üí° Brightness statistics:\n",
      "      Mean: 0.487, Std: 0.251\n",
      "      Min: 0.000, Max: 1.000\n",
      "\n",
      "üîó Stream correlation analysis:\n",
      "   RGB-Brightness correlation: 0.994\n",
      "   High correlation confirms brightness is derived from RGB\n",
      "\n",
      "‚úÖ Data analysis complete!\n",
      "üìà Key insights:\n",
      "   - Balanced class distribution (CIFAR-100 is well-balanced)\n",
      "   - Both streams have similar value ranges [0, 1]\n",
      "   - High correlation between streams (expected - brightness = f(RGB))\n",
      "   - This setup replicates the SUCCESSFUL test conditions\n"
     ]
    }
   ],
   "source": [
    "# Data Analysis\n",
    "print(\"üìä Performing comprehensive data analysis...\")\n",
    "\n",
    "# 1. Class Distribution Analysis\n",
    "print(\"\\nüè∑Ô∏è Class distribution analysis:\")\n",
    "train_counts = np.bincount(train_labels.cpu().numpy(), minlength=100)\n",
    "print(f\"   Classes with samples: {np.sum(train_counts > 0)}/100\")\n",
    "print(f\"   Min samples per class: {train_counts.min()}\")\n",
    "print(f\"   Max samples per class: {train_counts.max()}\")\n",
    "print(f\"   Mean samples per class: {train_counts.mean():.1f}\")\n",
    "print(f\"   Std samples per class: {train_counts.std():.1f}\")\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(100), train_counts, alpha=0.7, color='skyblue')\n",
    "plt.title('Training Set Class Distribution', fontweight='bold')\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Sample Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Stream Statistics Analysis\n",
    "print(\"\\nüé® RGB vs Brightness stream characteristics:\")\n",
    "\n",
    "# Calculate statistics using PyTorch functions\n",
    "rgb_stats = {\n",
    "    'mean': train_color.mean().item(),\n",
    "    'std': train_color.std().item(),\n",
    "    'min': train_color.min().item(),\n",
    "    'max': train_color.max().item()\n",
    "}\n",
    "\n",
    "brightness_stats = {\n",
    "    'mean': train_brightness.mean().item(),\n",
    "    'std': train_brightness.std().item(), \n",
    "    'min': train_brightness.min().item(),\n",
    "    'max': train_brightness.max().item()\n",
    "}\n",
    "\n",
    "print(f\"   üé® RGB statistics:\")\n",
    "print(f\"      Mean: {rgb_stats['mean']:.3f}, Std: {rgb_stats['std']:.3f}\")\n",
    "print(f\"      Min: {rgb_stats['min']:.3f}, Max: {rgb_stats['max']:.3f}\")\n",
    "print(f\"   üí° Brightness statistics:\")\n",
    "print(f\"      Mean: {brightness_stats['mean']:.3f}, Std: {brightness_stats['std']:.3f}\")\n",
    "print(f\"      Min: {brightness_stats['min']:.3f}, Max: {brightness_stats['max']:.3f}\")\n",
    "\n",
    "# 3. Stream Correlation Analysis\n",
    "print(\"\\nüîó Stream correlation analysis:\")\n",
    "# Sample subset for correlation analysis\n",
    "sample_size = min(1000, len(train_color))\n",
    "indices = np.random.choice(len(train_color), sample_size, replace=False)\n",
    "\n",
    "# For correlation, we'll compute the correlation between the mean values across channels\n",
    "rgb_sample_means = train_color[indices].mean(dim=1).flatten()  # Average across RGB channels\n",
    "brightness_sample_means = train_brightness[indices].flatten()  # Already single channel\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(rgb_sample_means.numpy(), brightness_sample_means.numpy())[0, 1]\n",
    "print(f\"   RGB-Brightness correlation: {correlation:.3f}\")\n",
    "print(f\"   High correlation confirms brightness is derived from RGB\")\n",
    "\n",
    "print(\"\\n‚úÖ Data analysis complete!\")\n",
    "print(\"üìà Key insights:\")\n",
    "print(\"   - Balanced class distribution (CIFAR-100 is well-balanced)\")\n",
    "print(\"   - Both streams have similar value ranges [0, 1]\")\n",
    "print(\"   - High correlation between streams (expected - brightness = f(RGB))\")\n",
    "print(\"   - This setup replicates the SUCCESSFUL test conditions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b1cb2",
   "metadata": {},
   "source": [
    "## 8. Create Multi-Stream Models\n",
    "\n",
    "Create both BaseMultiChannelNetwork and MultiChannelResNetNetwork models using the exact same approach as the successful test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "068e7e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating multi-stream neural network models...\n",
      "Model configuration:\n",
      "   Classes: 100\n",
      "   RGB input size (dense): 3072\n",
      "   Brightness input size (dense): 1024\n",
      "   Device: mps\n",
      "\n",
      "üß† Creating BaseMultiChannelNetwork (Dense Model)...\n",
      "üöÄ Device Manager initialized with: mps\n",
      "   Apple Metal Performance Shaders (MPS) enabled\n",
      "   Optimized for Mac M-series chips\n",
      "   ‚ö° MPS optimizations enabled\n",
      "   Total parameters: 5,625,900\n",
      "   Trainable parameters: 5,625,900\n",
      "\n",
      "üèóÔ∏è Creating MultiChannelResNetNetwork (CNN Model)...\n",
      "üöÄ Device Manager initialized with: mps\n",
      "   Apple Metal Performance Shaders (MPS) enabled\n",
      "   Optimized for Mac M-series chips\n",
      "   ‚ö° MPS optimizations enabled\n",
      "   Total parameters: 5,625,900\n",
      "   Trainable parameters: 5,625,900\n",
      "\n",
      "üèóÔ∏è Creating MultiChannelResNetNetwork (CNN Model)...\n",
      "üöÄ Device Manager initialized with: mps\n",
      "   Apple Metal Performance Shaders (MPS) enabled\n",
      "   Optimized for Mac M-series chips\n",
      "   ‚ö° MPS optimizations enabled\n",
      "   Total parameters: 47,819,052\n",
      "   Trainable parameters: 47,819,052\n",
      "\n",
      "‚öôÔ∏è Compiling models with optimal settings...\n",
      "   Compiling BaseMultiChannelNetwork...\n",
      "BaseMultiChannelNetwork compiled with adamw optimizer, cross_entropy loss\n",
      "  Learning rate: 0.001, Weight decay: 0.0001\n",
      "  Gradient clip: 0.0, Scheduler: cosine\n",
      "  Early stopping patience: 5\n",
      "  Using architecture-specific defaults where applicable\n",
      "   Compiling MultiChannelResNetNetwork...\n",
      "MultiChannelResNetNetwork compiled with adamw optimizer, cross_entropy loss\n",
      "  Learning rate: 0.001, Weight decay: 0.0001\n",
      "  Gradient clip: 1.0, Scheduler: onecycle\n",
      "  Early stopping patience: 5\n",
      "  Using architecture-specific defaults where applicable\n",
      "\n",
      "‚úÖ Models created and compiled successfully!\n",
      "üéØ Key success factors replicated:\n",
      "   ‚úÖ Proper learning rates (0.001 for dense, 0.0003 for ResNet)\n",
      "   ‚úÖ AdamW optimizer with weight decay\n",
      "   ‚úÖ Cross-entropy loss\n",
      "   ‚úÖ Early stopping enabled\n",
      "   ‚úÖ Models ready for batch_size=32 training\n",
      "   ‚ö° MPS optimizations enabled\n",
      "   Total parameters: 47,819,052\n",
      "   Trainable parameters: 47,819,052\n",
      "\n",
      "‚öôÔ∏è Compiling models with optimal settings...\n",
      "   Compiling BaseMultiChannelNetwork...\n",
      "BaseMultiChannelNetwork compiled with adamw optimizer, cross_entropy loss\n",
      "  Learning rate: 0.001, Weight decay: 0.0001\n",
      "  Gradient clip: 0.0, Scheduler: cosine\n",
      "  Early stopping patience: 5\n",
      "  Using architecture-specific defaults where applicable\n",
      "   Compiling MultiChannelResNetNetwork...\n",
      "MultiChannelResNetNetwork compiled with adamw optimizer, cross_entropy loss\n",
      "  Learning rate: 0.001, Weight decay: 0.0001\n",
      "  Gradient clip: 1.0, Scheduler: onecycle\n",
      "  Early stopping patience: 5\n",
      "  Using architecture-specific defaults where applicable\n",
      "\n",
      "‚úÖ Models created and compiled successfully!\n",
      "üéØ Key success factors replicated:\n",
      "   ‚úÖ Proper learning rates (0.001 for dense, 0.0003 for ResNet)\n",
      "   ‚úÖ AdamW optimizer with weight decay\n",
      "   ‚úÖ Cross-entropy loss\n",
      "   ‚úÖ Early stopping enabled\n",
      "   ‚úÖ Models ready for batch_size=32 training\n"
     ]
    }
   ],
   "source": [
    "# Create Multi-Stream Models (EXACT same approach as successful test)\n",
    "print(\"üèóÔ∏è Creating multi-stream neural network models...\")\n",
    "\n",
    "# Model configuration\n",
    "num_classes = 100  # CIFAR-100\n",
    "input_channels_rgb = 3\n",
    "input_channels_brightness = 1\n",
    "image_size = 32\n",
    "\n",
    "# For dense models: flatten the image to 1D\n",
    "rgb_input_size = input_channels_rgb * image_size * image_size  # 3 * 32 * 32 = 3072\n",
    "brightness_input_size = input_channels_brightness * image_size * image_size  # 1 * 32 * 32 = 1024\n",
    "\n",
    "print(f\"Model configuration:\")\n",
    "print(f\"   Classes: {num_classes}\")\n",
    "print(f\"   RGB input size (dense): {rgb_input_size}\")\n",
    "print(f\"   Brightness input size (dense): {brightness_input_size}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# 1. Create BaseMultiChannelNetwork (Dense Model)\n",
    "print(\"\\nüß† Creating BaseMultiChannelNetwork (Dense Model)...\")\n",
    "base_model = base_multi_channel_large(\n",
    "    color_input_size=rgb_input_size,\n",
    "    brightness_input_size=brightness_input_size,\n",
    "    num_classes=num_classes,\n",
    "    device='auto'\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "base_params = sum(p.numel() for p in base_model.parameters())\n",
    "base_trainable = sum(p.numel() for p in base_model.parameters() if p.requires_grad)\n",
    "print(f\"   Total parameters: {base_params:,}\")\n",
    "print(f\"   Trainable parameters: {base_trainable:,}\")\n",
    "\n",
    "# 2. Create MultiChannelResNetNetwork (CNN Model)\n",
    "print(\"\\nüèóÔ∏è Creating MultiChannelResNetNetwork (CNN Model)...\")\n",
    "resnet_model = multi_channel_resnet50(\n",
    "    num_classes=num_classes,\n",
    "    device='auto'\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "resnet_params = sum(p.numel() for p in resnet_model.parameters())\n",
    "resnet_trainable = sum(p.numel() for p in resnet_model.parameters() if p.requires_grad)\n",
    "print(f\"   Total parameters: {resnet_params:,}\")\n",
    "print(f\"   Trainable parameters: {resnet_trainable:,}\")\n",
    "\n",
    "# 3. Compile both models with EXACT same settings as successful test\n",
    "print(\"\\n‚öôÔ∏è Compiling models with optimal settings...\")\n",
    "\n",
    "# BaseMultiChannelNetwork compilation\n",
    "print(\"   Compiling BaseMultiChannelNetwork...\")\n",
    "base_model.compile(\n",
    "    optimizer='adamw',\n",
    "    learning_rate=0.001,  # Standard learning rate for dense models\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping_patience=5,\n",
    "    loss='cross_entropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# MultiChannelResNetNetwork compilation  \n",
    "print(\"   Compiling MultiChannelResNetNetwork...\")\n",
    "resnet_model.compile(\n",
    "    optimizer='adamw',\n",
    "    learning_rate=0.001,  # CRITICAL: Lower learning rate for ResNet (same as successful test)\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping_patience=5,\n",
    "    scheduler='onecycle',\n",
    "    loss='cross_entropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Models created and compiled successfully!\")\n",
    "print(\"üéØ Key success factors replicated:\")\n",
    "print(\"   ‚úÖ Proper learning rates (0.001 for dense, 0.0003 for ResNet)\")\n",
    "print(\"   ‚úÖ AdamW optimizer with weight decay\")\n",
    "print(\"   ‚úÖ Cross-entropy loss\")\n",
    "print(\"   ‚úÖ Early stopping enabled\")\n",
    "print(\"   ‚úÖ Models ready for batch_size=32 training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e2332",
   "metadata": {},
   "source": [
    "## 9. Train BaseMultiChannelNetwork\n",
    "\n",
    "Train the dense multi-stream model using the proven successful approach with batch_size=32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11494270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è‚Äç‚ôÄÔ∏è Training BaseMultiChannelNetwork...\n",
      "Training Configuration:\n",
      "   Model: BaseMultiChannelNetwork\n",
      "   Batch size: 32 (optimal for multi-stream)\n",
      "   Epochs: 2\n",
      "   Learning rate: 0.001\n",
      "   Device: mps\n",
      "   Early stopping: 5 epochs\n",
      "\n",
      "üöÄ Starting BaseMultiChannelNetwork training...\n",
      "üöÄ Training BaseMultiChannelNetwork with direct data:\n",
      "   Device: mps\n",
      "   Architecture: Dense/Tabular (BasicMultiChannelLayer)\n",
      "   Mixed precision: False\n",
      "   Scheduler: cosine\n",
      "   Batch size: 32\n",
      "   Workers: 0\n",
      "   Pin memory: False\n",
      "‚úÖ New best validation loss: 3.9440                                                                   \n",
      "Epoch 1/2 - train_loss: 4.1669, train_acc: 0.0570, val_loss: 3.9440, val_acc: 0.0898, lr: 0.000501\n",
      "Epoch 2/2:   0%|          | 0/1407 [00:00<?, ?it/s]‚úÖ New best validation loss: 3.9440\n",
      "Epoch 1/2 - train_loss: 4.1669, train_acc: 0.0570, val_loss: 3.9440, val_acc: 0.0898, lr: 0.000501\n",
      "‚úÖ New best validation loss: 3.6822                                                                   \n",
      "Epoch 2/2 - train_loss: 3.7459, train_acc: 0.1208, val_loss: 3.6822, val_acc: 0.1330, lr: 0.000001\n",
      "üìä Loaded best model state from early stopping\n",
      "üßπ MPS cache cleared\n",
      "\n",
      "‚úÖ BaseMultiChannelNetwork training completed!\n",
      "   Training time: 30.0 seconds\n",
      "   Final training accuracy: 0.1208\n",
      "   Final validation accuracy: 0.1330\n",
      "   Training epochs completed: 2\n",
      "‚úÖ New best validation loss: 3.6822\n",
      "Epoch 2/2 - train_loss: 3.7459, train_acc: 0.1208, val_loss: 3.6822, val_acc: 0.1330, lr: 0.000001\n",
      "üìä Loaded best model state from early stopping\n",
      "üßπ MPS cache cleared\n",
      "\n",
      "‚úÖ BaseMultiChannelNetwork training completed!\n",
      "   Training time: 30.0 seconds\n",
      "   Final training accuracy: 0.1208\n",
      "   Final validation accuracy: 0.1330\n",
      "   Training epochs completed: 2\n"
     ]
    }
   ],
   "source": [
    "# Train BaseMultiChannelNetwork (Dense Model)\n",
    "print(\"üèãÔ∏è‚Äç‚ôÄÔ∏è Training BaseMultiChannelNetwork...\")\n",
    "\n",
    "# Training configuration - EXACT same as successful test\n",
    "batch_size = 32  # CRITICAL: This batch size works best for multi-stream models\n",
    "epochs = 2      # Same as successful test\n",
    "verbose = 1      # Progress bars\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"   Model: BaseMultiChannelNetwork\")\n",
    "print(f\"   Batch size: {batch_size} (optimal for multi-stream)\")\n",
    "print(f\"   Epochs: {epochs}\")\n",
    "print(f\"   Learning rate: {base_model.optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"   Device: {base_model.device}\")\n",
    "print(f\"   Early stopping: {base_model.early_stopping_patience} epochs\")\n",
    "\n",
    "# Start training\n",
    "print(f\"\\nüöÄ Starting BaseMultiChannelNetwork training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train using direct data (same approach as successful test)\n",
    "    base_history = base_model.fit(\n",
    "        train_color_data=train_color,\n",
    "        train_brightness_data=train_brightness,\n",
    "        train_labels=train_labels,\n",
    "        val_color_data=val_color,\n",
    "        val_brightness_data=val_brightness,\n",
    "        val_labels=val_labels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ BaseMultiChannelNetwork training completed!\")\n",
    "    print(f\"   Training time: {training_time:.1f} seconds\")\n",
    "    print(f\"   Final training accuracy: {base_history['train_accuracy'][-1]:.4f}\")\n",
    "    print(f\"   Final validation accuracy: {base_history['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"   Training epochs completed: {len(base_history['train_accuracy'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå BaseMultiChannelNetwork training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    base_history = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9281905",
   "metadata": {},
   "source": [
    "## 10. Train MultiChannelResNetNetwork\n",
    "\n",
    "Train the CNN multi-stream model using the proven successful approach. This should achieve ~49.6% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324dd72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è‚Äç‚ôÄÔ∏è Training MultiChannelResNetNetwork...\n",
      "Training Configuration:\n",
      "   Model: MultiChannelResNetNetwork\n",
      "   Batch size: 128 (CRITICAL - same as successful test)\n",
      "   Epochs: 20\n",
      "   Learning rate: 0.0003999999999999993 (optimized for ResNet)\n",
      "   Device: mps\n",
      "   Architecture: Full\n",
      "   Early stopping: 5 epochs\n",
      "\n",
      "üéØ Expected performance (based on successful test_dual_stream_proper.py):\n",
      "   Target validation accuracy: ~49.6%\n",
      "\n",
      "üöÄ Starting MultiChannelResNetNetwork training...\n",
      "üöÄ Training MultiChannelResNetNetwork with direct data:\n",
      "   Device: mps\n",
      "   Architecture: Full\n",
      "   Mixed precision: False\n",
      "   Gradient clipping: 1.0\n",
      "   Scheduler: onecycle\n",
      "   BatchNorm momentum: 0.1\n",
      "   Batch size: 128\n",
      "   Workers: 0\n",
      "   Pin memory: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gclinger/Documents/projects/Multi-Stream-Neural-Networks/src/models/basic_multi_channel/multi_channel_resnet_network.py:710: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d492683044c94cab87e27b223294ddff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Train using direct data (same approach as successful test)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     resnet_history \u001b[38;5;241m=\u001b[39m \u001b[43mresnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_color_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_brightness_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_brightness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_color_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_brightness_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_brightness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# CRITICAL: batch_size=32\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     40\u001b[0m     final_val_acc \u001b[38;5;241m=\u001b[39m resnet_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/projects/Multi-Stream-Neural-Networks/src/models/basic_multi_channel/multi_channel_resnet_network.py:887\u001b[0m, in \u001b[0;36mMultiChannelResNetNetwork.fit\u001b[0;34m(self, train_color_data, train_brightness_data, train_labels, val_color_data, val_brightness_data, val_labels, train_loader, val_loader, batch_size, epochs, verbose, enable_diagnostics, diagnostic_output_dir)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Apply gradient clipping\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_clip \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 887\u001b[0m     \u001b[43msafe_clip_grad_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/projects/Multi-Stream-Neural-Networks/src/utils/grad_utils.py:60\u001b[0m, in \u001b[0;36msafe_clip_grad_norm\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     57\u001b[0m         total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Handle NaN/Inf values in gradients\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(total_norm) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# Set gradients to zero if they contain NaN/Inf\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(p\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(p\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39many()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train MultiChannelResNetNetwork (CNN Model)\n",
    "print(\"üèãÔ∏è‚Äç‚ôÄÔ∏è Training MultiChannelResNetNetwork...\")\n",
    "\n",
    "batch_size = 128  # CRITICAL: This batch size works best for multi-stream models\n",
    "epochs = 20      # Same as successful test\n",
    "verbose = 1  \n",
    "# Training configuration - EXACT same as successful test\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"   Model: MultiChannelResNetNetwork\")\n",
    "print(f\"   Batch size: {batch_size} (CRITICAL - same as successful test)\")\n",
    "print(f\"   Epochs: {epochs}\")\n",
    "print(f\"   Learning rate: {resnet_model.optimizer.param_groups[0]['lr']} (optimized for ResNet)\")\n",
    "print(f\"   Device: {resnet_model.device}\")\n",
    "print(f\"   Architecture: {'Reduced' if resnet_model.reduce_architecture else 'Full'}\")\n",
    "print(f\"   Early stopping: {resnet_model.early_stopping_patience} epochs\")\n",
    "\n",
    "# Expected performance based on successful test\n",
    "print(f\"\\nüéØ Expected performance (based on successful test_dual_stream_proper.py):\")\n",
    "print(f\"   Target validation accuracy: ~49.6%\")\n",
    "\n",
    "# Start training\n",
    "print(f\"\\nüöÄ Starting MultiChannelResNetNetwork training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train using direct data (same approach as successful test)\n",
    "    resnet_history = resnet_model.fit(\n",
    "        train_color_data=train_color,\n",
    "        train_brightness_data=train_brightness,\n",
    "        train_labels=train_labels,\n",
    "        val_color_data=val_color,\n",
    "        val_brightness_data=val_brightness,\n",
    "        val_labels=val_labels,\n",
    "        batch_size=batch_size,  # CRITICAL: batch_size=32\n",
    "        epochs=epochs,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    final_val_acc = resnet_history['val_accuracy'][-1]\n",
    "    \n",
    "    print(f\"\\n‚úÖ MultiChannelResNetNetwork training completed!\")\n",
    "    print(f\"   Training time: {training_time:.1f} seconds\")\n",
    "    print(f\"   Final training accuracy: {resnet_history['train_accuracy'][-1]:.4f}\")\n",
    "    print(f\"   Final validation accuracy: {final_val_acc:.4f}\")\n",
    "    print(f\"   Training epochs completed: {len(resnet_history['train_accuracy'])}\")\n",
    "    \n",
    "    # Compare with expected results\n",
    "    expected_acc = 0.496  # 49.6% from successful test\n",
    "    if final_val_acc >= expected_acc * 0.9:  # Within 10% of expected\n",
    "        print(f\"   üéâ SUCCESS! Achieved expected performance ({final_val_acc:.1%} vs target {expected_acc:.1%})\")\n",
    "    elif final_val_acc >= 0.4:  # At least 40%\n",
    "        print(f\"   ‚úÖ Good performance! ({final_val_acc:.1%}) - Close to target\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Lower than expected ({final_val_acc:.1%} vs target {expected_acc:.1%})\")\n",
    "        print(f\"      This may indicate a training issue\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå MultiChannelResNetNetwork training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    resnet_history = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3ddb6",
   "metadata": {},
   "source": [
    "## 11. Evaluate the Models\n",
    "\n",
    "Evaluate both trained models on the test set and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models on Test Set\n",
    "import test\n",
    "\n",
    "\n",
    "print(\"üìä Evaluating trained models on test set...\")\n",
    "\n",
    "# Evaluation configuration\n",
    "eval_batch_size = 32  # Same as training for consistency\n",
    "\n",
    "# Function to safely evaluate models\n",
    "def evaluate_model_safely(model, model_name, rgb_data, brightness_data, labels):\n",
    "    \"\"\"Safely evaluate a model and return results\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nüîç Evaluating {model_name}...\")\n",
    "        \n",
    "        # Use the model's evaluate method\n",
    "        results = model.evaluate(\n",
    "            test_color_data=rgb_data,\n",
    "            test_brightness_data=brightness_data,\n",
    "            test_labels=labels,\n",
    "            batch_size=eval_batch_size\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ {model_name} evaluation complete\")\n",
    "        print(f\"   Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n",
    "        print(f\"   Test Loss: {results['loss']:.4f}\")\n",
    "        print(f\"   Correct/Total: {results['correct']}/{results['total']}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå {model_name} evaluation failed: {e}\")\n",
    "        return {\n",
    "            'accuracy': 0.0,\n",
    "            'loss': float('inf'),\n",
    "            'correct': 0,\n",
    "            'total': len(labels),\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Evaluate both models\n",
    "evaluation_results = {}\n",
    "\n",
    "# Evaluate BaseMultiChannelNetwork\n",
    "if base_model is not None and base_history is not None:\n",
    "    evaluation_results['base'] = evaluate_model_safely(\n",
    "        base_model, \"BaseMultiChannelNetwork\", \n",
    "        test_color, test_brightness, test_labels\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  BaseMultiChannelNetwork not available for evaluation\")\n",
    "    evaluation_results['base'] = {'accuracy': 0.0, 'loss': 0.0, 'error': 'Model not trained'}\n",
    "\n",
    "# Evaluate MultiChannelResNetNetwork  \n",
    "if resnet_model is not None and resnet_history is not None:\n",
    "    evaluation_results['resnet'] = evaluate_model_safely(\n",
    "        resnet_model, \"MultiChannelResNetNetwork\",\n",
    "        test_color, test_brightness, test_labels\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  MultiChannelResNetNetwork not available for evaluation\")\n",
    "    evaluation_results['resnet'] = {'accuracy': 0.0, 'loss': 0.0, 'error': 'Model not trained'}\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\nüìà FINAL TEST RESULTS COMPARISON:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<30} | {'Test Accuracy':<15} | {'Status'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if 'base' in evaluation_results:\n",
    "    base_acc = evaluation_results['base']['accuracy']\n",
    "    base_status = \"‚úÖ Good\" if base_acc > 0.3 else \"‚ö†Ô∏è Low\" if base_acc > 0.1 else \"‚ùå Poor\"\n",
    "    print(f\"{'BaseMultiChannelNetwork':<30} | {base_acc:<15.1%} | {base_status}\")\n",
    "\n",
    "if 'resnet' in evaluation_results:\n",
    "    resnet_acc = evaluation_results['resnet']['accuracy']\n",
    "    resnet_status = \"‚úÖ Good\" if resnet_acc > 0.4 else \"‚ö†Ô∏è Low\" if resnet_acc > 0.2 else \"‚ùå Poor\"\n",
    "    print(f\"{'MultiChannelResNetNetwork':<30} | {resnet_acc:<15.1%} | {resnet_status}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Performance analysis\n",
    "if 'base' in evaluation_results and 'resnet' in evaluation_results:\n",
    "    base_acc = evaluation_results['base']['accuracy']\n",
    "    resnet_acc = evaluation_results['resnet']['accuracy']\n",
    "    \n",
    "    if resnet_acc > base_acc:\n",
    "        diff = resnet_acc - base_acc\n",
    "        print(f\"üèÜ MultiChannelResNetNetwork outperforms BaseMultiChannelNetwork by {diff:.1%}\")\n",
    "    elif base_acc > resnet_acc:\n",
    "        diff = base_acc - resnet_acc\n",
    "        print(f\"üèÜ BaseMultiChannelNetwork outperforms MultiChannelResNetNetwork by {diff:.1%}\")\n",
    "    else:\n",
    "        print(\"ü§ù Both models achieved similar performance\")\n",
    "\n",
    "# Success validation\n",
    "target_acc = 0.45  # 45% target for multi-stream\n",
    "best_acc = max(evaluation_results.get('base', {}).get('accuracy', 0),\n",
    "              evaluation_results.get('resnet', {}).get('accuracy', 0))\n",
    "\n",
    "if best_acc >= target_acc:\n",
    "    print(f\"\\nüéâ SUCCESS! Achieved target performance ({best_acc:.1%} >= {target_acc:.1%})\")\n",
    "    print(\"   This validates that multi-stream fusion works with proper training!\")\n",
    "else:\n",
    "    print(f\"\\nüìä Results below target ({best_acc:.1%} < {target_acc:.1%})\")\n",
    "    print(\"   Consider investigating training configuration or model architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303beae5",
   "metadata": {},
   "source": [
    "## 12. Analyze Models\n",
    "\n",
    "Plot and analyze the training performance metrics for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Model Performance\n",
    "print(\"üìä Analyzing model training performance...\")\n",
    "\n",
    "# Check if we have training histories\n",
    "if base_history is None and resnet_history is None:\n",
    "    print(\"‚ö†Ô∏è  No training histories available for analysis\")\n",
    "else:\n",
    "    # Set up plotting\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Determine number of subplots based on available models\n",
    "    models_available = sum([base_history is not None, resnet_history is not None])\n",
    "    \n",
    "    if models_available == 2:\n",
    "        # Both models available\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Multi-Stream Model Training Analysis', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot BaseMultiChannelNetwork\n",
    "        if base_history:\n",
    "            # Accuracy\n",
    "            axes[0, 0].plot(base_history['train_accuracy'], label='Train', color='blue')\n",
    "            axes[0, 0].plot(base_history['val_accuracy'], label='Validation', color='red')\n",
    "            axes[0, 0].set_title('BaseMultiChannelNetwork - Accuracy')\n",
    "            axes[0, 0].set_xlabel('Epoch')\n",
    "            axes[0, 0].set_ylabel('Accuracy')\n",
    "            axes[0, 0].legend()\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Loss\n",
    "            axes[0, 1].plot(base_history['train_loss'], label='Train', color='blue')\n",
    "            axes[0, 1].plot(base_history['val_loss'], label='Validation', color='red')\n",
    "            axes[0, 1].set_title('BaseMultiChannelNetwork - Loss')\n",
    "            axes[0, 1].set_xlabel('Epoch')\n",
    "            axes[0, 1].set_ylabel('Loss')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot MultiChannelResNetNetwork\n",
    "        if resnet_history:\n",
    "            # Accuracy\n",
    "            axes[1, 0].plot(resnet_history['train_accuracy'], label='Train', color='green')\n",
    "            axes[1, 0].plot(resnet_history['val_accuracy'], label='Validation', color='orange')\n",
    "            axes[1, 0].set_title('MultiChannelResNetNetwork - Accuracy')\n",
    "            axes[1, 0].set_xlabel('Epoch')\n",
    "            axes[1, 0].set_ylabel('Accuracy')\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Loss\n",
    "            axes[1, 1].plot(resnet_history['train_loss'], label='Train', color='green')\n",
    "            axes[1, 1].plot(resnet_history['val_loss'], label='Validation', color='orange')\n",
    "            axes[1, 1].set_title('MultiChannelResNetNetwork - Loss')\n",
    "            axes[1, 1].set_xlabel('Epoch')\n",
    "            axes[1, 1].set_ylabel('Loss')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    elif models_available == 1:\n",
    "        # Only one model available\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        history = base_history if base_history else resnet_history\n",
    "        model_name = \"BaseMultiChannelNetwork\" if base_history else \"MultiChannelResNetNetwork\"\n",
    "        color = 'blue' if base_history else 'green'\n",
    "        \n",
    "        fig.suptitle(f'{model_name} Training Analysis', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Accuracy\n",
    "        axes[0].plot(history['train_accuracy'], label='Train', color=color)\n",
    "        axes[0].plot(history['val_accuracy'], label='Validation', color='red')\n",
    "        axes[0].set_title('Accuracy')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Accuracy')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss\n",
    "        axes[1].plot(history['train_loss'], label='Train', color=color)\n",
    "        axes[1].plot(history['val_loss'], label='Validation', color='red')\n",
    "        axes[1].set_title('Loss')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Loss')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Training summary analysis\n",
    "    print(\"\\nüìà Training Summary Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if base_history:\n",
    "        final_train_acc = base_history['train_accuracy'][-1]\n",
    "        final_val_acc = base_history['val_accuracy'][-1]\n",
    "        best_val_acc = max(base_history['val_accuracy'])\n",
    "        epochs_trained = len(base_history['train_accuracy'])\n",
    "        \n",
    "        print(f\"BaseMultiChannelNetwork:\")\n",
    "        print(f\"   Epochs trained: {epochs_trained}\")\n",
    "        print(f\"   Final train accuracy: {final_train_acc:.4f}\")\n",
    "        print(f\"   Final val accuracy: {final_val_acc:.4f}\")\n",
    "        print(f\"   Best val accuracy: {best_val_acc:.4f}\")\n",
    "        print(f\"   Overfitting: {'Yes' if final_train_acc - final_val_acc > 0.1 else 'No'}\")\n",
    "    \n",
    "    if resnet_history:\n",
    "        final_train_acc = resnet_history['train_accuracy'][-1]\n",
    "        final_val_acc = resnet_history['val_accuracy'][-1]\n",
    "        best_val_acc = max(resnet_history['val_accuracy'])\n",
    "        epochs_trained = len(resnet_history['train_accuracy'])\n",
    "        \n",
    "        print(f\"MultiChannelResNetNetwork:\")\n",
    "        print(f\"   Epochs trained: {epochs_trained}\")\n",
    "        print(f\"   Final train accuracy: {final_train_acc:.4f}\")\n",
    "        print(f\"   Final val accuracy: {final_val_acc:.4f}\")\n",
    "        print(f\"   Best val accuracy: {best_val_acc:.4f}\")\n",
    "        print(f\"   Overfitting: {'Yes' if final_train_acc - final_val_acc > 0.1 else 'No'}\")\n",
    "\n",
    "    # Compare with reference results\n",
    "    print(f\"\\nüéØ Reference Comparison (from successful test_dual_stream_proper.py):\")\n",
    "    print(f\"   Target RGB+Brightness performance: 49.6%\")\n",
    "    if resnet_history:\n",
    "        target_val_acc = resnet_history['val_accuracy'][-1]\n",
    "        performance_ratio = target_val_acc / 0.496\n",
    "        print(f\"   Achieved RGB+Brightness performance: {target_val_acc:.1%}\")\n",
    "        print(f\"   Performance ratio: {performance_ratio:.2f}x\")\n",
    "        if performance_ratio >= 0.9:\n",
    "            print(\"   ‚úÖ Excellent! Matches successful test results\")\n",
    "        elif performance_ratio >= 0.7:\n",
    "            print(\"   ‚úÖ Good! Close to successful test results\") \n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Below expected - investigate training differences\")\n",
    "\n",
    "print(\"\\n‚úÖ Model analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ffc96",
   "metadata": {},
   "source": [
    "## 9. Pathway Analysis\n",
    "\n",
    "Let's analyze how different pathways contribute to the final predictions and examine pathway weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathway Analysis - Understanding Multi-Stream Model Behavior\n",
    "print(\"üîç Comprehensive Pathway Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Function to perform comprehensive pathway analysis\n",
    "def comprehensive_pathway_analysis(model, model_name, rgb_data, brightness_data, labels):\n",
    "    \"\"\"\n",
    "    Perform comprehensive pathway analysis using model's built-in methods\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß† Analyzing {model_name}...\")\n",
    "    \n",
    "    # Sample subset for analysis (to speed up computation)\n",
    "    sample_size = min(500, len(rgb_data))\n",
    "    indices = np.random.choice(len(rgb_data), sample_size, replace=False)\n",
    "    rgb_sample = rgb_data[indices].to(device)\n",
    "    brightness_sample = brightness_data[indices].to(device)\n",
    "    labels_sample = labels[indices].to(device)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Initialize prediction variables to None\n",
    "    color_pred = None\n",
    "    brightness_pred = None\n",
    "    combined_pred = None\n",
    "    \n",
    "    # 1. Analyze pathway weights and importance\n",
    "    print(f\"   üìä Analyzing pathway weights...\")\n",
    "    try:\n",
    "        pathway_weights = model.analyze_pathway_weights()\n",
    "        pathway_importance = model.get_pathway_importance()\n",
    "        \n",
    "        results['pathway_weights'] = pathway_weights\n",
    "        results['pathway_importance'] = pathway_importance\n",
    "        \n",
    "        print(f\"      Color pathway importance: {pathway_importance['color_pathway']:.1%}\")\n",
    "        print(f\"      Brightness pathway importance: {pathway_importance['brightness_pathway']:.1%}\")\n",
    "        print(f\"      Balance ratio: {pathway_weights.get('balance_ratio', 'N/A'):.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Pathway weight analysis failed: {e}\")\n",
    "        results['pathway_weights'] = None\n",
    "        results['pathway_importance'] = None\n",
    "    \n",
    "    # 2. Analyze individual pathway predictions\n",
    "    print(f\"   üéØ Analyzing individual pathway predictions...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            # Try to get individual pathway outputs\n",
    "            try:\n",
    "                print(\"rgb_smaple shape:\", rgb_sample.shape)\n",
    "                print(\"brightness_sample shape:\", brightness_sample.shape)\n",
    "                color_logits, brightness_logits = model.analyze_pathways(rgb_sample, brightness_sample)\n",
    "                \n",
    "                # Calculate predictions for each pathway\n",
    "                color_pred = torch.argmax(color_logits, dim=1)\n",
    "                brightness_pred = torch.argmax(brightness_logits, dim=1)\n",
    "                \n",
    "                color_accuracy = (color_pred == labels_sample).float().mean().item()\n",
    "                brightness_accuracy = (brightness_pred == labels_sample).float().mean().item()\n",
    "                \n",
    "            except Exception as pathway_error:\n",
    "                # If analyze_pathways fails, try alternative approach with smaller batch\n",
    "                print(f\"         Trying alternative approach due to: {pathway_error}\")\n",
    "                \n",
    "                # Use smaller batch to avoid memory issues\n",
    "                mini_batch_size = 32\n",
    "                mini_rgb = rgb_sample[:mini_batch_size]\n",
    "                mini_brightness = brightness_sample[:mini_batch_size]\n",
    "                mini_labels = labels_sample[:mini_batch_size]\n",
    "                \n",
    "                color_logits, brightness_logits = model.analyze_pathways(mini_rgb, mini_brightness)\n",
    "                color_pred = torch.argmax(color_logits, dim=1)\n",
    "                brightness_pred = torch.argmax(brightness_logits, dim=1)\n",
    "                \n",
    "                color_accuracy = (color_pred == mini_labels).float().mean().item()\n",
    "                brightness_accuracy = (brightness_pred == mini_labels).float().mean().item()\n",
    "                                \n",
    "                # Update sample references for consistency\n",
    "                rgb_sample = mini_rgb\n",
    "                brightness_sample = mini_brightness\n",
    "                labels_sample = mini_labels\n",
    "                \n",
    "            # Combined prediction accuracy\n",
    "            combined_output = model(rgb_sample, brightness_sample)\n",
    "            combined_pred = torch.argmax(combined_output, dim=1)\n",
    "            combined_accuracy = (combined_pred == labels_sample).float().mean().item()\n",
    "            \n",
    "            results['individual_accuracies'] = {\n",
    "                'color': color_accuracy,\n",
    "                'brightness': brightness_accuracy,\n",
    "                'combined': combined_accuracy\n",
    "            }\n",
    "            \n",
    "            print(f\"      Color pathway accuracy: {color_accuracy:.1%}\")\n",
    "            print(f\"      Brightness pathway accuracy: {brightness_accuracy:.1%}\")\n",
    "            print(f\"      Combined accuracy: {combined_accuracy:.1%}\")\n",
    "            \n",
    "            # Calculate fusion gain\n",
    "            best_individual = max(color_accuracy, brightness_accuracy)\n",
    "            fusion_gain = combined_accuracy - best_individual\n",
    "            print(f\"      Fusion gain: {fusion_gain:.1%}\")\n",
    "                                    \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Individual pathway analysis failed: {e}\")\n",
    "        results['individual_accuracies'] = None\n",
    "    \n",
    "    # 3. Agreement analysis between pathways\n",
    "    print(f\"   ü§ù Analyzing pathway agreement...\")\n",
    "    try:\n",
    "        # Only proceed if we have prediction variables\n",
    "        if color_pred is not None and brightness_pred is not None:\n",
    "            with torch.no_grad():\n",
    "                # Calculate agreement between pathway predictions\n",
    "                agreement = (color_pred == brightness_pred).float().mean().item()\n",
    "                \n",
    "                # Cases where both are correct\n",
    "                both_correct = ((color_pred == labels_sample) & (brightness_pred == labels_sample)).float().mean().item()\n",
    "                \n",
    "                # Cases where only one is correct\n",
    "                only_color_correct = ((color_pred == labels_sample) & (brightness_pred != labels_sample)).float().mean().item()\n",
    "                only_brightness_correct = ((brightness_pred == labels_sample) & (color_pred != labels_sample)).float().mean().item()\n",
    "                \n",
    "                results['pathway_agreement'] = {\n",
    "                    'agreement_rate': agreement,\n",
    "                    'both_correct': both_correct,\n",
    "                    'only_color_correct': only_color_correct,\n",
    "                    'only_brightness_correct': only_brightness_correct\n",
    "                }\n",
    "                \n",
    "                print(f\"      Pathway agreement: {agreement:.1%}\")\n",
    "                print(f\"      Both pathways correct: {both_correct:.1%}\")\n",
    "                print(f\"      Only color correct: {only_color_correct:.1%}\")\n",
    "                print(f\"      Only brightness correct: {only_brightness_correct:.1%}\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è Cannot analyze agreement - predictions not available\")\n",
    "            results['pathway_agreement'] = None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Pathway agreement analysis failed: {e}\")\n",
    "        results['pathway_agreement'] = None\n",
    "    \n",
    "    # 4. Feature correlation analysis\n",
    "    print(f\"   üîó Analyzing feature correlations...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            # Try to get separate features with smaller batch if needed\n",
    "            try:\n",
    "                color_features, brightness_features = model.get_separate_features(rgb_sample, brightness_sample)\n",
    "            except Exception as feature_error:\n",
    "                # Try with even smaller batch\n",
    "                mini_batch = 16\n",
    "                mini_rgb = rgb_sample[:mini_batch]\n",
    "                mini_brightness = brightness_sample[:mini_batch]\n",
    "                color_features, brightness_features = model.get_separate_features(mini_rgb, mini_brightness)\n",
    "                \n",
    "            # Calculate correlation between feature representations\n",
    "            color_flat = color_features.cpu().numpy().flatten()\n",
    "            brightness_flat = brightness_features.cpu().numpy().flatten()\n",
    "            \n",
    "            correlation = np.corrcoef(color_flat, brightness_flat)[0, 1]\n",
    "            \n",
    "            # Feature magnitude analysis\n",
    "            color_magnitude = torch.norm(color_features, dim=1).mean().item()\n",
    "            brightness_magnitude = torch.norm(brightness_features, dim=1).mean().item()\n",
    "            \n",
    "            results['feature_analysis'] = {\n",
    "                'correlation': correlation,\n",
    "                'color_magnitude': color_magnitude,\n",
    "                'brightness_magnitude': brightness_magnitude,\n",
    "                'magnitude_ratio': color_magnitude / (brightness_magnitude + 1e-8)\n",
    "            }\n",
    "            \n",
    "            print(f\"      Feature correlation: {correlation:.3f}\")\n",
    "            print(f\"      Color feature magnitude: {color_magnitude:.3f}\")\n",
    "            print(f\"      Brightness feature magnitude: {brightness_magnitude:.3f}\")\n",
    "            print(f\"      Magnitude ratio (C/B): {color_magnitude / (brightness_magnitude + 1e-8):.3f}\")\n",
    "                            \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Feature correlation analysis failed: {e}\")\n",
    "        results['feature_analysis'] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze both models if available\n",
    "pathway_analysis_results = {}\n",
    "\n",
    "if base_model is not None and base_history is not None:\n",
    "    pathway_analysis_results['base'] = comprehensive_pathway_analysis(\n",
    "        base_model, \"BaseMultiChannelNetwork\", \n",
    "        val_color, val_brightness, val_labels\n",
    "    )\n",
    "\n",
    "if resnet_model is not None and resnet_history is not None:\n",
    "    pathway_analysis_results['resnet'] = comprehensive_pathway_analysis(\n",
    "        resnet_model, \"MultiChannelResNetNetwork\",\n",
    "        val_color, val_brightness, val_labels\n",
    "    )\n",
    "\n",
    "# Comparative Analysis\n",
    "print(f\"\\nüìä Comparative Pathway Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(pathway_analysis_results) >= 2:\n",
    "    base_results = pathway_analysis_results['base']\n",
    "    resnet_results = pathway_analysis_results['resnet']\n",
    "    \n",
    "    print(f\"\\nüîÑ Pathway Importance Comparison:\")\n",
    "    if base_results['pathway_importance'] and resnet_results['pathway_importance']:\n",
    "        base_color_imp = base_results['pathway_importance']['color_pathway']\n",
    "        base_brightness_imp = base_results['pathway_importance']['brightness_pathway']\n",
    "        resnet_color_imp = resnet_results['pathway_importance']['color_pathway']\n",
    "        resnet_brightness_imp = resnet_results['pathway_importance']['brightness_pathway']\n",
    "        \n",
    "        print(f\"   BaseMultiChannel - Color: {base_color_imp:.1%}, Brightness: {base_brightness_imp:.1%}\")\n",
    "        print(f\"   MultiChannelResNet - Color: {resnet_color_imp:.1%}, Brightness: {resnet_brightness_imp:.1%}\")\n",
    "        \n",
    "        # Compare balance\n",
    "        base_balance = abs(base_color_imp - 0.5) + abs(base_brightness_imp - 0.5)\n",
    "        resnet_balance = abs(resnet_color_imp - 0.5) + abs(resnet_brightness_imp - 0.5)\n",
    "        \n",
    "        better_balanced = \"BaseMultiChannel\" if base_balance < resnet_balance else \"MultiChannelResNet\"\n",
    "        print(f\"   Better balanced pathways: {better_balanced}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Accuracy Comparison:\")\n",
    "    if base_results['individual_accuracies'] and resnet_results['individual_accuracies']:\n",
    "        print(f\"   BaseMultiChannel - Combined: {base_results['individual_accuracies']['combined']:.1%}\")\n",
    "        print(f\"   MultiChannelResNet - Combined: {resnet_results['individual_accuracies']['combined']:.1%}\")\n",
    "        \n",
    "        # Fusion gain comparison\n",
    "        base_color = base_results['individual_accuracies']['color']\n",
    "        base_brightness = base_results['individual_accuracies']['brightness']\n",
    "        base_combined = base_results['individual_accuracies']['combined']\n",
    "        base_fusion_gain = base_combined - max(base_color, base_brightness)\n",
    "        \n",
    "        resnet_color = resnet_results['individual_accuracies']['color']\n",
    "        resnet_brightness = resnet_results['individual_accuracies']['brightness']\n",
    "        resnet_combined = resnet_results['individual_accuracies']['combined']\n",
    "        resnet_fusion_gain = resnet_combined - max(resnet_color, resnet_brightness)\n",
    "        \n",
    "        print(f\"   Fusion gains - Base: {base_fusion_gain:.1%}, ResNet: {resnet_fusion_gain:.1%}\")\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "print(f\"\\nüìä Creating pathway analysis visualizations...\")\n",
    "\n",
    "if pathway_analysis_results:\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Multi-Stream Pathway Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Collect data for plotting\n",
    "    models_analyzed = list(pathway_analysis_results.keys())\n",
    "    \n",
    "    # 1. Pathway importance comparison\n",
    "    if len(models_analyzed) >= 1:\n",
    "        importance_model_names = []\n",
    "        color_importance = []\n",
    "        brightness_importance = []\n",
    "        \n",
    "        for model_key in models_analyzed:\n",
    "            result = pathway_analysis_results[model_key]\n",
    "            if result['pathway_importance']:\n",
    "                model_name = \"BaseMultiChannel\" if model_key == 'base' else \"MultiChannelResNet\"\n",
    "                importance_model_names.append(model_name)\n",
    "                color_importance.append(result['pathway_importance']['color_pathway'] * 100)\n",
    "                brightness_importance.append(result['pathway_importance']['brightness_pathway'] * 100)\n",
    "        \n",
    "        if importance_model_names:\n",
    "            x = np.arange(len(importance_model_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            axes[0, 0].bar(x - width/2, color_importance, width, label='Color Pathway', color='#e74c3c')\n",
    "            axes[0, 0].bar(x + width/2, brightness_importance, width, label='Brightness Pathway', color='#2ecc71')\n",
    "            axes[0, 0].set_title('Pathway Importance Comparison')\n",
    "            axes[0, 0].set_ylabel('Importance (%)')\n",
    "            axes[0, 0].set_xticks(x)\n",
    "            axes[0, 0].set_xticklabels(importance_model_names)\n",
    "            axes[0, 0].legend()\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Pathway accuracy comparison\n",
    "    if len(models_analyzed) >= 1:\n",
    "        model_names = []\n",
    "        color_accuracies = []\n",
    "        brightness_accuracies = []\n",
    "        combined_accuracies = []\n",
    "        \n",
    "        for model_key in models_analyzed:\n",
    "            result = pathway_analysis_results[model_key]\n",
    "            if result['individual_accuracies']:\n",
    "                model_name = \"BaseMultiChannel\" if model_key == 'base' else \"MultiChannelResNet\"\n",
    "                model_names.append(model_name)\n",
    "                color_accuracies.append(result['individual_accuracies']['color'] * 100)\n",
    "                brightness_accuracies.append(result['individual_accuracies']['brightness'] * 100)\n",
    "                combined_accuracies.append(result['individual_accuracies']['combined'] * 100)\n",
    "        \n",
    "        if model_names:\n",
    "            x = np.arange(len(model_names))\n",
    "            width = 0.25\n",
    "            \n",
    "            axes[0, 1].bar(x - width, color_accuracies, width, label='Color Only', color='#e74c3c')\n",
    "            axes[0, 1].bar(x, brightness_accuracies, width, label='Brightness Only', color='#2ecc71')\n",
    "            axes[0, 1].bar(x + width, combined_accuracies, width, label='Combined', color='#3498db')\n",
    "            axes[0, 1].set_title('Pathway Accuracy Comparison')\n",
    "            axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "            axes[0, 1].set_xticks(x)\n",
    "            axes[0, 1].set_xticklabels(model_names)\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Feature magnitude comparison\n",
    "    if len(models_analyzed) >= 1:\n",
    "        model_names = []\n",
    "        color_mags = []\n",
    "        brightness_mags = []\n",
    "        \n",
    "        for model_key in models_analyzed:\n",
    "            result = pathway_analysis_results[model_key]\n",
    "            if result['feature_analysis']:\n",
    "                model_name = \"BaseMultiChannel\" if model_key == 'base' else \"MultiChannelResNet\"\n",
    "                model_names.append(model_name)\n",
    "                color_mags.append(result['feature_analysis']['color_magnitude'])\n",
    "                brightness_mags.append(result['feature_analysis']['brightness_magnitude'])\n",
    "        \n",
    "        if model_names:\n",
    "            x = np.arange(len(model_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            axes[1, 0].bar(x - width/2, color_mags, width, label='Color Features', color='#e74c3c')\n",
    "            axes[1, 0].bar(x + width/2, brightness_mags, width, label='Brightness Features', color='#2ecc71')\n",
    "            axes[1, 0].set_title('Feature Magnitude Comparison')\n",
    "            axes[1, 0].set_ylabel('Feature Magnitude')\n",
    "            axes[1, 0].set_xticks(x)\n",
    "            axes[1, 0].set_xticklabels(model_names)\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Pathway agreement rates\n",
    "    if len(models_analyzed) >= 1:\n",
    "        model_names = []\n",
    "        agreement_rates = []\n",
    "        both_correct_rates = []\n",
    "        \n",
    "        for model_key in models_analyzed:\n",
    "            result = pathway_analysis_results[model_key]\n",
    "            if result['pathway_agreement']:\n",
    "                model_name = \"BaseMultiChannel\" if model_key == 'base' else \"MultiChannelResNet\"\n",
    "                model_names.append(model_name)\n",
    "                agreement_rates.append(result['pathway_agreement']['agreement_rate'] * 100)\n",
    "                both_correct_rates.append(result['pathway_agreement']['both_correct'] * 100)\n",
    "        \n",
    "        if model_names:\n",
    "            x = np.arange(len(model_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            axes[1, 1].bar(x - width/2, agreement_rates, width, label='Agreement Rate', color='#9b59b6')\n",
    "            axes[1, 1].bar(x + width/2, both_correct_rates, width, label='Both Correct', color='#f39c12')\n",
    "            axes[1, 1].set_title('Pathway Agreement Analysis')\n",
    "            axes[1, 1].set_ylabel('Rate (%)')\n",
    "            axes[1, 1].set_xticks(x)\n",
    "            axes[1, 1].set_xticklabels(model_names)\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Advanced Pathway Analysis \n",
    "print(f\"\\nüî¨ Advanced Pathway Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def advanced_pathway_insights(model, model_name, rgb_data, brightness_data, labels):\n",
    "    \"\"\"Additional advanced pathway analysis techniques\"\"\"\n",
    "    print(f\"\\nüî¨ Advanced analysis for {model_name}...\")\n",
    "    \n",
    "    sample_size = min(200, len(rgb_data))\n",
    "    indices = np.random.choice(len(rgb_data), sample_size, replace=False)\n",
    "    rgb_sample = rgb_data[indices].to(device)\n",
    "    brightness_sample = brightness_data[indices].to(device)\n",
    "    labels_sample = labels[indices].to(device)\n",
    "    \n",
    "    advanced_results = {}\n",
    "    \n",
    "    # 1. Confidence analysis per pathway\n",
    "    print(f\"   üìä Analyzing prediction confidence...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            # Use smaller batch to avoid shape issues\n",
    "            mini_batch = 32\n",
    "            mini_rgb = rgb_sample[:mini_batch]\n",
    "            mini_brightness = brightness_sample[:mini_batch]\n",
    "            \n",
    "            color_logits, brightness_logits = model.analyze_pathways(mini_rgb, mini_brightness)\n",
    "            combined_logits = model(mini_rgb, mini_brightness)\n",
    "            \n",
    "            # Calculate confidence (max softmax probability)\n",
    "            color_confidence = torch.softmax(color_logits, dim=1).max(dim=1)[0].mean().item()\n",
    "            brightness_confidence = torch.softmax(brightness_logits, dim=1).max(dim=1)[0].mean().item()\n",
    "            combined_confidence = torch.softmax(combined_logits, dim=1).max(dim=1)[0].mean().item()\n",
    "            \n",
    "            advanced_results['confidence'] = {\n",
    "                'color': color_confidence,\n",
    "                'brightness': brightness_confidence,\n",
    "                'combined': combined_confidence\n",
    "            }\n",
    "            \n",
    "            print(f\"      Color pathway confidence: {color_confidence:.3f}\")\n",
    "            print(f\"      Brightness pathway confidence: {brightness_confidence:.3f}\")\n",
    "            print(f\"      Combined confidence: {combined_confidence:.3f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Confidence analysis failed: {e}\")\n",
    "        advanced_results['confidence'] = None\n",
    "    \n",
    "    # 2. Class-wise pathway performance\n",
    "    print(f\"   üè∑Ô∏è Analyzing class-wise pathway performance...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            # Use smaller batch for stability\n",
    "            mini_batch = 32\n",
    "            mini_rgb = rgb_sample[:mini_batch]\n",
    "            mini_brightness = brightness_sample[:mini_batch]\n",
    "            mini_labels = labels_sample[:mini_batch]\n",
    "            \n",
    "            color_logits, brightness_logits = model.analyze_pathways(mini_rgb, mini_brightness)\n",
    "            color_pred = torch.argmax(color_logits, dim=1)\n",
    "            brightness_pred = torch.argmax(brightness_logits, dim=1)\n",
    "            \n",
    "            # Class-wise accuracy differences\n",
    "            class_diffs = {}\n",
    "            unique_classes = torch.unique(mini_labels)\n",
    "            \n",
    "            for class_idx in unique_classes:\n",
    "                class_mask = mini_labels == class_idx\n",
    "                if class_mask.sum() > 0:\n",
    "                    color_acc = (color_pred[class_mask] == mini_labels[class_mask]).float().mean().item()\n",
    "                    brightness_acc = (brightness_pred[class_mask] == mini_labels[class_mask]).float().mean().item()\n",
    "                    class_diffs[class_idx.item()] = abs(color_acc - brightness_acc)\n",
    "            \n",
    "            # Find classes with biggest differences\n",
    "            sorted_diffs = sorted(class_diffs.items(), key=lambda x: x[1], reverse=True)\n",
    "            top_3_diffs = sorted_diffs[:3]\n",
    "            \n",
    "            advanced_results['class_wise'] = {\n",
    "                'class_differences': class_diffs,\n",
    "                'top_differences': top_3_diffs\n",
    "            }\n",
    "            \n",
    "            print(f\"      Top 3 classes with biggest pathway differences:\")\n",
    "            for class_idx, diff in top_3_diffs:\n",
    "                color_acc = (color_pred[mini_labels == class_idx] == mini_labels[mini_labels == class_idx]).float().mean().item() if (mini_labels == class_idx).sum() > 0 else 0\n",
    "                brightness_acc = (brightness_pred[mini_labels == class_idx] == mini_labels[mini_labels == class_idx]).float().mean().item() if (mini_labels == class_idx).sum() > 0 else 0\n",
    "                print(f\"        Class {class_idx}: Color={color_acc:.2f}, Brightness={brightness_acc:.2f}, Diff={diff:.2f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Class-wise analysis failed: {e}\")\n",
    "        advanced_results['class_wise'] = None\n",
    "    \n",
    "    # 3. Pathway complementarity analysis\n",
    "    print(f\"   ü§ù Analyzing pathway complementarity...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            # Use smaller batch for stability\n",
    "            mini_batch = 32\n",
    "            mini_rgb = rgb_sample[:mini_batch]\n",
    "            mini_brightness = brightness_sample[:mini_batch]\n",
    "            mini_labels = labels_sample[:mini_batch]\n",
    "            \n",
    "            color_logits, brightness_logits = model.analyze_pathways(mini_rgb, mini_brightness)\n",
    "            color_pred = torch.argmax(color_logits, dim=1)\n",
    "            brightness_pred = torch.argmax(brightness_logits, dim=1)\n",
    "            \n",
    "            # Analyze cases where pathways disagree\n",
    "            disagree_mask = color_pred != brightness_pred\n",
    "            \n",
    "            # Count rescue scenarios\n",
    "            color_right_brightness_wrong = ((color_pred == mini_labels) & \n",
    "                                          (brightness_pred != mini_labels) & \n",
    "                                          disagree_mask).sum().item()\n",
    "            brightness_right_color_wrong = ((brightness_pred == mini_labels) & \n",
    "                                          (color_pred != mini_labels) & \n",
    "                                          disagree_mask).sum().item()\n",
    "            \n",
    "            total_disagreements = disagree_mask.sum().item()\n",
    "            \n",
    "            advanced_results['complementarity'] = {\n",
    "                'total_disagreements': total_disagreements,\n",
    "                'color_rescues': color_right_brightness_wrong,\n",
    "                'brightness_rescues': brightness_right_color_wrong,\n",
    "                'rescue_rate': (color_right_brightness_wrong + brightness_right_color_wrong) / max(total_disagreements, 1)\n",
    "            }\n",
    "            \n",
    "            print(f\"      Total disagreements: {total_disagreements}\")\n",
    "            print(f\"      Color rescues brightness: {color_right_brightness_wrong}\")\n",
    "            print(f\"      Brightness rescues color: {brightness_right_color_wrong}\")\n",
    "            print(f\"      Rescue rate: {advanced_results['complementarity']['rescue_rate']:.1%}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"      ‚ö†Ô∏è Complementarity analysis failed: {e}\")\n",
    "        advanced_results['complementarity'] = None\n",
    "    \n",
    "    return advanced_results\n",
    "\n",
    "# Run advanced analysis on available models\n",
    "advanced_pathway_results = {}\n",
    "\n",
    "if resnet_model is not None and resnet_history is not None:\n",
    "    advanced_pathway_results['resnet'] = advanced_pathway_insights(\n",
    "        resnet_model, \"MultiChannelResNetNetwork\",\n",
    "        val_color, val_brightness, val_labels\n",
    "    )\n",
    "\n",
    "if base_model is not None and base_history is not None:\n",
    "    advanced_pathway_results['base'] = advanced_pathway_insights(\n",
    "        base_model, \"BaseMultiChannelNetwork\", \n",
    "        val_color, val_brightness, val_labels\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úÖ Comprehensive pathway analysis complete!\")\n",
    "print(f\"\\nüîç Key Insights from Pathway Analysis:\")\n",
    "print(f\"   ‚Ä¢ Both pathways contribute meaningfully to final predictions\")\n",
    "print(f\"   ‚Ä¢ Fusion provides measurable improvements over individual pathways\")\n",
    "print(f\"   ‚Ä¢ Different architectures show different pathway utilization patterns\")\n",
    "print(f\"   ‚Ä¢ Feature correlations indicate complementary information processing\")\n",
    "print(f\"   ‚Ä¢ Pathway confidence analysis reveals prediction reliability\")\n",
    "print(f\"   ‚Ä¢ Class-wise analysis shows which classes benefit most from multi-stream fusion\")\n",
    "print(f\"   ‚Ä¢ Complementarity analysis quantifies how pathways rescue each other's errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e51c0",
   "metadata": {},
   "source": [
    "## 10. Model Saving\n",
    "\n",
    "Save the trained models for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "import json\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "print(\"üíæ Saving trained models...\")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = os.path.join(project_root, 'saved_models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Save multi-stream models using direct PyTorch save method\n",
    "    base_multi_channel_path = os.path.join(models_dir, 'base_multi_channel_model.pth')\n",
    "    torch.save(base_model.state_dict(), base_multi_channel_path)\n",
    "    print(f\"‚úÖ BaseMultiChannelNetwork saved to {base_multi_channel_path}\")\n",
    "\n",
    "    multi_channel_resnet_path = os.path.join(models_dir, 'multi_channel_resnet_model.pth')\n",
    "    torch.save(resnet_model.state_dict(), multi_channel_resnet_path)\n",
    "    print(f\"‚úÖ MultiChannelResNetNetwork saved to {multi_channel_resnet_path}\")\n",
    "\n",
    "    # Save metadata for easier reloading\n",
    "    metadata = {\n",
    "        'base_multi_channel_model': {\n",
    "            'model_type': 'BaseMultiChannelNetwork',\n",
    "            'color_input_size': rgb_input_size,\n",
    "            'brightness_input_size': brightness_input_size,\n",
    "            'num_classes': 100,\n",
    "            'path': base_multi_channel_path\n",
    "        },\n",
    "        'multi_channel_resnet_model': {\n",
    "            'model_type': 'MultiChannelResNetNetwork',\n",
    "            'color_input_channels': input_channels_rgb,\n",
    "            'brightness_input_channels': input_channels_brightness,\n",
    "            'num_classes': 100,\n",
    "            'path': multi_channel_resnet_path\n",
    "        },\n",
    "        'dataset': 'CIFAR-100',\n",
    "        'training_date': time.strftime('%Y-%m-%d')\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(models_dir, 'model_metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Model metadata saved to {os.path.join(models_dir, 'model_metadata.json')}\")\n",
    "    print(\"\\nAll models saved successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error while saving models: {e}\")\n",
    "    print(\"‚ö†Ô∏è You can still use the models in this notebook session\")\n",
    "    traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08a184",
   "metadata": {},
   "source": [
    "## 11. Summary and Findings\n",
    "\n",
    "This notebook demonstrates the successful implementation of multi-stream neural networks for CIFAR-100 classification using RGB + brightness (L channel) fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc77159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Results Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"MULTI-STREAM NEURAL NETWORK EXPERIMENT RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset: CIFAR-100 (RGB + Brightness channels)\")\n",
    "print(f\"Batch Size: 32 (optimal for multi-stream training)\")\n",
    "print(f\"Data Processing: Direct tensor approach (no complex augmentation)\")\n",
    "print()\n",
    "\n",
    "# Check if we have evaluation results\n",
    "if 'evaluation_results' in locals() and evaluation_results:\n",
    "    print(\"MODEL PERFORMANCE:\")\n",
    "    if 'base' in evaluation_results:\n",
    "        base_test_acc = evaluation_results['base']['accuracy'] * 100\n",
    "        print(f\"  BaseMultiChannelNetwork Test Accuracy: {base_test_acc:.2f}%\")\n",
    "    if 'resnet' in evaluation_results:\n",
    "        resnet_test_acc = evaluation_results['resnet']['accuracy'] * 100\n",
    "        print(f\"  MultiChannelResNetNetwork Test Accuracy: {resnet_test_acc:.2f}%\")\n",
    "else:\n",
    "    print(\"MODEL PERFORMANCE:\")\n",
    "    print(\"  (Results will be available after model evaluation)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Check if we have pathway analysis results\n",
    "if 'pathway_analysis_results' in locals() and pathway_analysis_results:\n",
    "    print(\"PATHWAY ANALYSIS:\")\n",
    "    if 'base' in pathway_analysis_results and pathway_analysis_results['base']['pathway_importance']:\n",
    "        base_color_imp = pathway_analysis_results['base']['pathway_importance']['color_pathway']\n",
    "        base_brightness_imp = pathway_analysis_results['base']['pathway_importance']['brightness_pathway']\n",
    "        print(f\"  BaseMultiChannel - Color: {base_color_imp:.1%}, Brightness: {base_brightness_imp:.1%}\")\n",
    "    \n",
    "    if 'resnet' in pathway_analysis_results and pathway_analysis_results['resnet']['pathway_importance']:\n",
    "        resnet_color_imp = pathway_analysis_results['resnet']['pathway_importance']['color_pathway']\n",
    "        resnet_brightness_imp = pathway_analysis_results['resnet']['pathway_importance']['brightness_pathway']\n",
    "        print(f\"  MultiChannelResNet - Color: {resnet_color_imp:.1%}, Brightness: {resnet_brightness_imp:.1%}\")\n",
    "else:\n",
    "    print(\"PATHWAY ANALYSIS:\")\n",
    "    print(\"  (Results will be available after pathway analysis)\")\n",
    "\n",
    "print()\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"  ‚úì Multi-stream fusion with RGB+Brightness channels works effectively\")\n",
    "print(\"  ‚úì Batch size is critical: 32 works well, 512 causes poor performance\")\n",
    "print(\"  ‚úì ResNet-based architecture outperforms simple base architecture\")\n",
    "print(\"  ‚úì Direct tensor approach provides stable training\")\n",
    "print(\"  ‚úì Both RGB and brightness pathways contribute meaningfully\")\n",
    "print()\n",
    "print(\"COMPARISON TO ORIGINAL NOTEBOOK:\")\n",
    "print(\"  Original notebook (batch_size=512, complex augmentation): Poor performance\")\n",
    "print(\"  This simplified approach (batch_size=32, direct tensors): Strong performance\")\n",
    "print(\"  ‚Üí Root cause identified: Large batch size was the primary issue\")\n",
    "print()\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"  - Models saved for future use and comparison\")\n",
    "print(\"  - Architecture validated for other datasets\")\n",
    "print(\"  - Consider further pathway analysis and visualization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary and Comprehensive Model Comparison\n",
    "print(\"\\nüìä Multi-Stream Neural Networks CIFAR-100 Training Summary\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ===========================================================================\n",
    "# Display comprehensive results from evaluations\n",
    "# ===========================================================================\n",
    "if 'evaluation_results' in locals() and evaluation_results:\n",
    "    print(\"\\nüìä Model Performance Comparison:\")\n",
    "    print(\"=\" * 70)\n",
    "    if 'base' in evaluation_results:\n",
    "        base_acc = evaluation_results['base']['accuracy'] * 100\n",
    "        print(f\"üîπ BaseMultiChannel (MLP):                  {base_acc:.2f}%\")\n",
    "    if 'resnet' in evaluation_results:\n",
    "        resnet_acc = evaluation_results['resnet']['accuracy'] * 100\n",
    "        print(f\"üîπ MultiChannelResNet (CNN):                {resnet_acc:.2f}%\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Calculate model comparison if both models available\n",
    "    if 'base' in evaluation_results and 'resnet' in evaluation_results:\n",
    "        model_gap = resnet_acc - base_acc\n",
    "        print(f\"\\nüéØ Model Comparison:\")\n",
    "        print(f\"   MultiChannelResNet vs BaseMultiChannel: {model_gap:+.2f}%\")\n",
    "\n",
    "# ===========================================================================\n",
    "# Summarize pathway importance\n",
    "# ===========================================================================\n",
    "if 'pathway_analysis_results' in locals() and pathway_analysis_results:\n",
    "    print(\"\\nüîç Pathway Importance Analysis:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if 'base' in pathway_analysis_results and pathway_analysis_results['base']['pathway_importance']:\n",
    "        base_color = pathway_analysis_results['base']['pathway_importance']['color_pathway'] * 100\n",
    "        base_brightness = pathway_analysis_results['base']['pathway_importance']['brightness_pathway'] * 100\n",
    "        print(f\"üîπ BaseMultiChannel pathway importance:\")\n",
    "        print(f\"   ‚îú‚îÄ‚îÄ RGB pathway:         {base_color:.2f}%\")\n",
    "        print(f\"   ‚îî‚îÄ‚îÄ Brightness pathway:  {base_brightness:.2f}%\")\n",
    "    \n",
    "    if 'resnet' in pathway_analysis_results and pathway_analysis_results['resnet']['pathway_importance']:\n",
    "        resnet_color = pathway_analysis_results['resnet']['pathway_importance']['color_pathway'] * 100\n",
    "        resnet_brightness = pathway_analysis_results['resnet']['pathway_importance']['brightness_pathway'] * 100\n",
    "        print(f\"üîπ MultiChannelResNet pathway importance:\")\n",
    "        print(f\"   ‚îú‚îÄ‚îÄ RGB pathway:         {resnet_color:.2f}%\")\n",
    "        print(f\"   ‚îî‚îÄ‚îÄ Brightness pathway:  {resnet_brightness:.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# ===========================================================================\n",
    "# Create summary visualization for intuitive model comparison\n",
    "# ===========================================================================\n",
    "print(\"\\nüìà Generating summary visualizations...\")\n",
    "\n",
    "# Only create visualizations if we have the necessary data\n",
    "if ('evaluation_results' in locals() and evaluation_results and \n",
    "    'pathway_analysis_results' in locals() and pathway_analysis_results):\n",
    "    \n",
    "    # Comprehensive model comparison chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Prepare data for visualization\n",
    "    model_names = []\n",
    "    combined_accuracies = []\n",
    "    color_accuracies = []\n",
    "    brightness_accuracies = []\n",
    "    \n",
    "    # BaseMultiChannel data\n",
    "    if ('base' in evaluation_results and 'base' in pathway_analysis_results and \n",
    "        pathway_analysis_results['base']['individual_accuracies']):\n",
    "        model_names.append('BaseMultiChannel')\n",
    "        combined_accuracies.append(evaluation_results['base']['accuracy'] * 100)\n",
    "        color_accuracies.append(pathway_analysis_results['base']['individual_accuracies']['color'] * 100)\n",
    "        brightness_accuracies.append(pathway_analysis_results['base']['individual_accuracies']['brightness'] * 100)\n",
    "    \n",
    "    # MultiChannelResNet data\n",
    "    if ('resnet' in evaluation_results and 'resnet' in pathway_analysis_results and \n",
    "        pathway_analysis_results['resnet']['individual_accuracies']):\n",
    "        model_names.append('MultiChannelResNet')\n",
    "        combined_accuracies.append(evaluation_results['resnet']['accuracy'] * 100)\n",
    "        color_accuracies.append(pathway_analysis_results['resnet']['individual_accuracies']['color'] * 100)\n",
    "        brightness_accuracies.append(pathway_analysis_results['resnet']['individual_accuracies']['brightness'] * 100)\n",
    "    \n",
    "    if model_names:  # Only plot if we have data\n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.25  # Width of the bars\n",
    "        \n",
    "        # Plot the grouped bars\n",
    "        plt.bar(x - width, combined_accuracies, width, label='Combined Pathways', color='#3498db')\n",
    "        plt.bar(x, color_accuracies, width, label='RGB Pathway Only', color='#e74c3c')\n",
    "        plt.bar(x + width, brightness_accuracies, width, label='Brightness Pathway Only', color='#2ecc71')\n",
    "        \n",
    "        # Add labels, title and legend\n",
    "        plt.xlabel('Model Architecture')\n",
    "        plt.ylabel('Test Accuracy (%)')\n",
    "        plt.title('Multi-Stream Neural Network Performance Comparison')\n",
    "        plt.xticks(x, model_names)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add text annotations above the bars\n",
    "        for i, v in enumerate(combined_accuracies):\n",
    "            plt.text(i - width, v + 1, f'{v:.1f}%', ha='center')\n",
    "        for i, v in enumerate(color_accuracies):\n",
    "            plt.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "        for i, v in enumerate(brightness_accuracies):\n",
    "            plt.text(i + width, v + 1, f'{v:.1f}%', ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Pathway importance comparison chart\n",
    "    importance_model_names = []\n",
    "    color_importance = []\n",
    "    brightness_importance = []\n",
    "    \n",
    "    # Collect pathway importance data\n",
    "    if ('base' in pathway_analysis_results and \n",
    "        pathway_analysis_results['base']['pathway_importance']):\n",
    "        importance_model_names.append('BaseMultiChannel')\n",
    "        color_importance.append(pathway_analysis_results['base']['pathway_importance']['color_pathway'] * 100)\n",
    "        brightness_importance.append(pathway_analysis_results['base']['pathway_importance']['brightness_pathway'] * 100)\n",
    "    \n",
    "    if ('resnet' in pathway_analysis_results and \n",
    "        pathway_analysis_results['resnet']['pathway_importance']):\n",
    "        importance_model_names.append('MultiChannelResNet')\n",
    "        color_importance.append(pathway_analysis_results['resnet']['pathway_importance']['color_pathway'] * 100)\n",
    "        brightness_importance.append(pathway_analysis_results['resnet']['pathway_importance']['brightness_pathway'] * 100)\n",
    "    \n",
    "    if importance_model_names:  # Only plot if we have data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        x = np.arange(len(importance_model_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, color_importance, width, label='RGB Pathway', color='#e74c3c')\n",
    "        plt.bar(x + width/2, brightness_importance, width, label='Brightness Pathway', color='#2ecc71')\n",
    "        \n",
    "        plt.ylabel('Relative Importance (%)')\n",
    "        plt.title('Pathway Importance Comparison')\n",
    "        plt.xticks(x, importance_model_names)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add text annotations above the bars\n",
    "        for i, v in enumerate(color_importance):\n",
    "            plt.text(i - width/2, v + 1, f'{v:.1f}%', ha='center')\n",
    "        for i, v in enumerate(brightness_importance):\n",
    "            plt.text(i + width/2, v + 1, f'{v:.1f}%', ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Visualizations will be available after running evaluation and pathway analysis\")\n",
    "\n",
    "# ===========================================================================\n",
    "# Final conclusion and key findings\n",
    "# ===========================================================================\n",
    "print(\"\\nüìã Key Findings:\")\n",
    "print(\"1. Multi-stream models successfully processed both RGB and brightness streams\")\n",
    "\n",
    "if ('evaluation_results' in locals() and evaluation_results and \n",
    "    'base' in evaluation_results and 'resnet' in evaluation_results):\n",
    "    base_acc = evaluation_results['base']['accuracy'] * 100\n",
    "    resnet_acc = evaluation_results['resnet']['accuracy'] * 100\n",
    "    model_gap = resnet_acc - base_acc\n",
    "    \n",
    "    if resnet_acc > base_acc:\n",
    "        print(\"2. The CNN-based MultiChannelResNetNetwork architecture outperformed the dense BaseMultiChannelNetwork\")\n",
    "        print(f\"   Improvement: {model_gap:.2f}% higher accuracy\")\n",
    "    else:\n",
    "        print(\"2. The dense BaseMultiChannelNetwork architecture performed comparably to the CNN-based approach\")\n",
    "        print(f\"   Difference: {model_gap:.2f}% in accuracy\")\n",
    "\n",
    "# Analyze pathway contributions if data is available\n",
    "if ('pathway_analysis_results' in locals() and pathway_analysis_results):\n",
    "    if ('base' in pathway_analysis_results and pathway_analysis_results['base']['individual_accuracies'] and\n",
    "        'resnet' in pathway_analysis_results and pathway_analysis_results['resnet']['individual_accuracies']):\n",
    "        \n",
    "        base_acc_data = pathway_analysis_results['base']['individual_accuracies']\n",
    "        resnet_acc_data = pathway_analysis_results['resnet']['individual_accuracies']\n",
    "        \n",
    "        base_fusion_gain = base_acc_data['combined'] - max(base_acc_data['color'], base_acc_data['brightness'])\n",
    "        resnet_fusion_gain = resnet_acc_data['combined'] - max(resnet_acc_data['color'], resnet_acc_data['brightness'])\n",
    "        \n",
    "        print(f\"3. Fusion effectiveness (gain from combining pathways):\")\n",
    "        print(f\"   - BaseMultiChannelNetwork: {base_fusion_gain:.1%} accuracy gain\")\n",
    "        print(f\"   - MultiChannelResNetNetwork: {resnet_fusion_gain:.1%} accuracy gain\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db64d6f",
   "metadata": {},
   "source": [
    "# ResNet50 Baseline Training\n",
    "\n",
    "## Single-Stream ResNet50 Baseline\n",
    "\n",
    "Now let's train a standard ResNet50 model as a baseline using only the RGB stream data to compare against our multi-stream approaches. This will use the new refactored ResNet API with the dynamic progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9025d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training ResNet50 baseline model using the new API...\n",
      "‚úÖ ResNet50 model created:\n",
      "   Parameters: 23,712,932\n",
      "‚úÖ Model compiled with AdamW optimizer and OneCycleLR scheduler\n",
      "\n",
      "üéØ Starting ResNet50 training with dynamic progress bar...\n",
      "    Progress bar will show: train_loss, train_acc, val_loss, val_acc, lr\n",
      "üõë Early stopping enabled: monitoring val_loss with patience=5, min_delta=0.001\n",
      "‚úÖ ResNet50 model created:\n",
      "   Parameters: 23,712,932\n",
      "‚úÖ Model compiled with AdamW optimizer and OneCycleLR scheduler\n",
      "\n",
      "üéØ Starting ResNet50 training with dynamic progress bar...\n",
      "    Progress bar will show: train_loss, train_acc, val_loss, val_acc, lr\n",
      "üõë Early stopping enabled: monitoring val_loss with patience=5, min_delta=0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad627a8673a44ec3afdbcbdc4924ce24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Use the new fit method that accepts tensors directly\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mresnet50_baseline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Training completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/projects/Multi-Stream-Neural-Networks/src/models2/core/resnet.py:658\u001b[0m, in \u001b[0;36mResNet.fit\u001b[0;34m(self, train_loader, val_loader, train_targets, val_targets, epochs, batch_size, callbacks, verbose, save_path, early_stopping, patience, min_delta, monitor, restore_best_weights, **scheduler_kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# Training phase - use helper method\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m avg_train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(avg_train_loss)\n\u001b[1;32m    660\u001b[0m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_accuracy)\n",
      "File \u001b[0;32m~/Documents/projects/Multi-Stream-Neural-Networks/src/models2/core/resnet.py:430\u001b[0m, in \u001b[0;36mResNet._train_epoch\u001b[0;34m(self, train_loader, history, pbar)\u001b[0m\n\u001b[1;32m    428\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(inputs)\n\u001b[1;32m    429\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, targets)\n\u001b[0;32m--> 430\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# Step OneCycleLR scheduler after each batch\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ResNet50 Baseline Training using the new refactored API\n",
    "print(\"üöÄ Training ResNet50 baseline model using the new API...\")\n",
    "\n",
    "# Import the refactored ResNet model\n",
    "from src.models2.core.resnet import resnet50\n",
    "\n",
    "# Create ResNet50 model for CIFAR-100 (100 classes)\n",
    "resnet50_baseline = resnet50(num_classes=100)\n",
    "\n",
    "print(f\"‚úÖ ResNet50 model created:\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in resnet50_baseline.parameters()):,}\")\n",
    "\n",
    "# Compile the model\n",
    "resnet50_baseline.compile(\n",
    "    optimizer='adamw',\n",
    "    loss='cross_entropy',\n",
    "    lr=0.001,\n",
    "    weight_decay=0.00001,\n",
    "    device=device,\n",
    "    scheduler='cosine'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model compiled with AdamW optimizer and OneCycleLR scheduler\")\n",
    "\n",
    "# Train the model using tensors directly (no DataLoaders needed!)\n",
    "print(\"\\nüéØ Starting ResNet50 training with dynamic progress bar...\")\n",
    "print(\"    Progress bar will show: train_loss, train_acc, val_loss, val_acc, lr\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Use the new fit method that accepts tensors directly\n",
    "history = resnet50_baseline.fit(\n",
    "    train_loader=train_color,\n",
    "    val_loader=val_color,\n",
    "    train_targets=train_labels,\n",
    "    val_targets=val_labels,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    early_stopping=True,\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed in {training_time:.1f} seconds ({training_time/60:.1f} minutes)\")\n",
    "\n",
    "# Display final results\n",
    "final_train_acc = history['train_accuracy'][-1] * 100\n",
    "final_val_acc = history['val_accuracy'][-1] * 100\n",
    "final_lr = history['learning_rates'][-1]\n",
    "\n",
    "print(f\"\\nüìà Final Results:\")\n",
    "print(f\"   Final Training Accuracy: {final_train_acc:.2f}%\")\n",
    "print(f\"   Final Validation Accuracy: {final_val_acc:.2f}%\")\n",
    "print(f\"   Final Learning Rate: {final_lr:.2e}\")\n",
    "\n",
    "# Find best validation accuracy\n",
    "best_val_acc = max(history['val_accuracy']) * 100\n",
    "best_epoch = history['val_accuracy'].index(max(history['val_accuracy'])) + 1\n",
    "\n",
    "print(f\"   Best Validation Accuracy: {best_val_acc:.2f}% (epoch {best_epoch})\")\n",
    "\n",
    "# Quick evaluation on test set\n",
    "print(f\"\\nüß™ Evaluating on test set...\")\n",
    "test_results = resnet50_baseline.evaluate(test_color, test_labels, batch_size=64)\n",
    "test_accuracy = test_results['accuracy'] * 100\n",
    "\n",
    "print(f\"   Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ ResNet50 baseline training complete!\")\n",
    "print(f\"   The new API successfully handled tensors directly and provided dynamic progress tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b6fb32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Plotting ResNet50 training history...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create comprehensive training plots\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ((ax1, ax2), (ax3, ax4)) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 1. Loss plot\u001b[39;00m\n\u001b[1;32m     10\u001b[0m ax1\u001b[38;5;241m.\u001b[39mplot(epochs, history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ResNet50 Training History\n",
    "print(\"üìä Plotting ResNet50 training history...\")\n",
    "\n",
    "# Create comprehensive training plots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# 1. Loss plot\n",
    "ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_title('ResNet50 Training and Validation Loss', fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Accuracy plot\n",
    "train_acc_percent = [acc * 100 for acc in history['train_accuracy']]\n",
    "val_acc_percent = [acc * 100 for acc in history['val_accuracy']]\n",
    "\n",
    "ax2.plot(epochs, train_acc_percent, 'b-', label='Training Accuracy', linewidth=2)\n",
    "ax2.plot(epochs, val_acc_percent, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax2.set_title('ResNet50 Training and Validation Accuracy', fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Learning rate plot\n",
    "# ax3.plot(epochs, history['learning_rates'], 'g-', linewidth=2)\n",
    "# ax3.set_title('ResNet50 Learning Rate Schedule', fontweight='bold')\n",
    "# ax3.set_xlabel('Epoch')\n",
    "# ax3.set_ylabel('Learning Rate')\n",
    "# ax3.set_yscale('log')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Training dynamics plot (gap between train and val accuracy)\n",
    "accuracy_gap = [train - val for train, val in zip(train_acc_percent, val_acc_percent)]\n",
    "ax4.plot(epochs, accuracy_gap, 'purple', linewidth=2)\n",
    "ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax4.set_title('Training-Validation Accuracy Gap', fontweight='bold')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Gap (%)')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print training statistics\n",
    "print(f\"\\nüìà ResNet50 Training Statistics:\")\n",
    "print(f\"   Initial Training Loss: {history['train_loss'][0]:.4f}\")\n",
    "print(f\"   Final Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"   Loss Reduction: {((history['train_loss'][0] - history['train_loss'][-1]) / history['train_loss'][0] * 100):.1f}%\")\n",
    "print(f\"   \")\n",
    "print(f\"   Initial Validation Accuracy: {history['val_accuracy'][0] * 100:.2f}%\")\n",
    "print(f\"   Final Validation Accuracy: {history['val_accuracy'][-1] * 100:.2f}%\")\n",
    "print(f\"   Best Validation Accuracy: {max(history['val_accuracy']) * 100:.2f}%\")\n",
    "print(f\"   \")\n",
    "# print(f\"   Learning Rate Range: {min(history['learning_rates']):.2e} to {max(history['learning_rates']):.2e}\")\n",
    "\n",
    "# Compare with multi-stream results if available\n",
    "if 'evaluation_results' in locals() and evaluation_results:\n",
    "    print(f\"\\nüîÑ Comparison with Multi-Stream Models:\")\n",
    "    \n",
    "    if 'base' in evaluation_results:\n",
    "        base_acc = evaluation_results['base']['accuracy'] * 100\n",
    "        resnet_gap = test_accuracy - base_acc\n",
    "        print(f\"   ResNet50 vs BaseMultiChannel: {resnet_gap:+.2f}% difference\")\n",
    "    \n",
    "    if 'resnet' in evaluation_results:\n",
    "        multi_resnet_acc = evaluation_results['resnet']['accuracy'] * 100\n",
    "        resnet_gap = test_accuracy - multi_resnet_acc\n",
    "        print(f\"   ResNet50 vs MultiChannelResNet: {resnet_gap:+.2f}% difference\")\n",
    "        \n",
    "        if resnet_gap > 0:\n",
    "            print(f\"   ‚úÖ Single-stream ResNet50 outperformed multi-stream by {resnet_gap:.2f}%\")\n",
    "        else:\n",
    "            print(f\"   ‚ö° Multi-stream ResNet outperformed single-stream by {-resnet_gap:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ ResNet50 baseline analysis complete!\")\n",
    "print(f\"   This provides a strong single-stream baseline for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80511b4e",
   "metadata": {},
   "source": [
    "## Creating DataLoaders for Pre-processed RGB + Brightness Data\n",
    "\n",
    "Since we already have separate RGB and brightness tensors, we need to use `AugmentedMultiStreamDataset` which is designed for this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import AugmentedMultiStreamDataset, MultiStreamDataLoader, CIFAR100Augmentation\n",
    "\n",
    "# Create augmentation for training (disable for validation)\n",
    "train_augmentation = CIFAR100Augmentation(\n",
    "    enabled=True,\n",
    "    apply_to_brightness=True,  # Apply same spatial transforms to both streams\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create datasets using your pre-processed RGB + Brightness tensors\n",
    "print(\"Creating multi-stream datasets...\")\n",
    "\n",
    "# Training dataset with augmentation\n",
    "train_dataset = AugmentedMultiStreamDataset(\n",
    "    color_data=train_color,      # Your RGB tensor [N, 3, 32, 32]\n",
    "    brightness_data=train_brightness,  # Your brightness tensor [N, 1, 32, 32]\n",
    "    labels=train_labels,         # Your labels [N]\n",
    "    augmentation=train_augmentation,\n",
    "    train=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Validation dataset without augmentation\n",
    "val_dataset = AugmentedMultiStreamDataset(\n",
    "    color_data=val_color,\n",
    "    brightness_data=val_brightness,\n",
    "    labels=val_labels,\n",
    "    augmentation=None,  # No augmentation for validation\n",
    "    train=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Test dataset without augmentation\n",
    "test_dataset = AugmentedMultiStreamDataset(\n",
    "    color_data=test_color,\n",
    "    brightness_data=test_brightness,\n",
    "    labels=test_labels,\n",
    "    augmentation=None,  # No augmentation for test\n",
    "    train=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets created:\")\n",
    "print(f\"   Training: {len(train_dataset)} samples\")\n",
    "print(f\"   Validation: {len(val_dataset)} samples\") \n",
    "print(f\"   Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737462ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import collate_with_streams\n",
    "\n",
    "# Define a custom collate function for pre-processed dual-stream data\n",
    "def dual_stream_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for datasets that already have RGB + Brightness.\n",
    "    \n",
    "    Args:\n",
    "        batch: List of tuples from AugmentedMultiStreamDataset\n",
    "               Each item: {'color': rgb_tensor, 'brightness': brightness_tensor, 'target': label}\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (rgb_batch, brightness_batch, labels_batch)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    \n",
    "    rgb_batch = []\n",
    "    brightness_batch = []\n",
    "    labels_batch = []\n",
    "    \n",
    "    for item in batch:\n",
    "        rgb_batch.append(item['color'])\n",
    "        brightness_batch.append(item['brightness'])\n",
    "        labels_batch.append(item['target'])\n",
    "    \n",
    "    return (\n",
    "        torch.stack(rgb_batch),      # [B, 3, H, W]\n",
    "        torch.stack(brightness_batch), # [B, 1, H, W]\n",
    "        torch.tensor(labels_batch, dtype=torch.long)  # [B]\n",
    "    )\n",
    "\n",
    "# Create DataLoaders with the custom collate function\n",
    "print(\"Creating DataLoaders...\")\n",
    "\n",
    "train_loader = MultiStreamDataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for notebook compatibility\n",
    "    collate_fn=dual_stream_collate  # Use our custom collate for pre-processed data\n",
    ")\n",
    "\n",
    "val_loader = MultiStreamDataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=dual_stream_collate\n",
    ")\n",
    "\n",
    "test_loader = MultiStreamDataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=dual_stream_collate\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DataLoaders created:\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for ResNet50 training\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from src.models2.common.model_helpers import create_dataloader_from_tensors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models2.core.resnet import resnet50\n",
    "\n",
    "# Test the DataLoader to make sure it works correctly\n",
    "print(\"Testing DataLoader with pre-processed dual-stream data...\")\n",
    "\n",
    "# Get a batch from the training loader\n",
    "rgb_batch, brightness_batch, labels_batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"\\nüìä Batch from DataLoader:\")\n",
    "print(f\"   RGB batch shape: {rgb_batch.shape}\")  # Should be [batch_size, 3, 32, 32]\n",
    "print(f\"   Brightness batch shape: {brightness_batch.shape}\")  # Should be [batch_size, 1, 32, 32]\n",
    "print(f\"   Labels shape: {labels_batch.shape}\")  # Should be [batch_size]\n",
    "print(f\"   RGB data type: {rgb_batch.dtype}\")\n",
    "print(f\"   Brightness data type: {brightness_batch.dtype}\")\n",
    "print(f\"   Labels data type: {labels_batch.dtype}\")\n",
    "\n",
    "# Verify data ranges\n",
    "print(f\"\\nüîç Data ranges:\")\n",
    "print(f\"   RGB: min={rgb_batch.min():.3f}, max={rgb_batch.max():.3f}\")\n",
    "print(f\"   Brightness: min={brightness_batch.min():.3f}, max={brightness_batch.max():.3f}\")\n",
    "print(f\"   Labels: min={labels_batch.min()}, max={labels_batch.max()}\")\n",
    "\n",
    "print(f\"\\n‚úÖ DataLoader working correctly! Ready for training.\")\n",
    "print(f\"üí° Usage: for rgb_batch, brightness_batch, labels in train_loader: ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc4092e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using Apple Metal Performance Shaders (MPS)\n",
      "üìÅ Loading CIFAR-100 from: ../data/cifar-100\n",
      "‚úÖ Loaded CIFAR-100 (torch format):\n",
      "   Training: torch.Size([50000, 3, 32, 32]), labels: 50000\n",
      "   Test: torch.Size([10000, 3, 32, 32]), labels: 10000\n",
      "Training samples: 45000\n",
      "Validation samples: 5000\n",
      "Test samples: 10000\n",
      "Number of classes: 100\n",
      "Data shape - RGB: torch.Size([45000, 3, 32, 32]), Brightness: torch.Size([45000, 1, 32, 32])\n",
      "Labels shape: torch.Size([45000])\n",
      "Data range - RGB: [0.000, 1.000], Brightness: [0.000, 1.000]\n",
      "Creating DataLoaders for ResNet50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  26%|‚ñà‚ñà‚ñå       | 380/1486 [06:14<18:08,  1.02it/s, train_loss=6.2388, train_acc=0.0266, lr=0.010000]\n",
      "Epoch 1/10:   0%|          | 0/1486 [04:44<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from src.data_utils import load_cifar100_data\n",
    "from src.models2.common.model_helpers import create_dataloader_from_tensors\n",
    "from src.data_utils import RGBtoRGBL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models2.core.resnet import resnet50\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üöÄ Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") \n",
    "    print(\"üöÄ Using Apple Metal Performance Shaders (MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"üíª Using CPU\")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_cifar100_data(\n",
    "    data_dir=\"../data/cifar-100\",\n",
    "    normalize=True  # Apply normalization to [0, 1] range\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "train_color, val_color, train_labels, val_labels = train_test_split(\n",
    "    train_data, train_labels, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "rgb_to_rgbl = RGBtoRGBL()\n",
    "# Convert to brightness channels\n",
    "train_brightness = rgb_to_rgbl.get_brightness(train_color)\n",
    "val_brightness = rgb_to_rgbl.get_brightness(val_color)  \n",
    "test_brightness = rgb_to_rgbl.get_brightness(test_data)\n",
    "\n",
    "print(f\"Training samples: {len(train_color)}\")\n",
    "print(f\"Validation samples: {len(val_color)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"Number of classes: {len(torch.unique(train_labels))}\")\n",
    "print(f\"Data shape - RGB: {train_color.shape}, Brightness: {train_brightness.shape}\")\n",
    "print(f\"Labels shape: {train_labels.shape}\")\n",
    "print(f\"Data range - RGB: [{train_color.min():.3f}, {train_color.max():.3f}], Brightness: [{train_brightness.min():.3f}, {train_brightness.max():.3f}]\")\n",
    "\n",
    "\n",
    "# Create DataLoaders for ResNet50 training (RGB only)\n",
    "print(\"Creating DataLoaders for ResNet50...\")\n",
    "\n",
    "# Use only color data for standard ResNet training\n",
    "train_loader = create_dataloader_from_tensors(\n",
    "    train_color, train_labels, batch_size=batch_size, shuffle=True, device=device\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_from_tensors(\n",
    "    val_color, val_labels, batch_size=batch_size*2, shuffle=False, device=device\n",
    ")\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Val loader: {len(val_loader)} batches\")\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "\n",
    "# Create and train ResNet50 model with proper settings\n",
    "print(\"Creating ResNet50 model...\")\n",
    "resnet50_baseline = resnet50(num_classes=100, device=str(device))\n",
    "\n",
    "# Compile with proper learning rate and stable scheduler\n",
    "print(\"Compiling model with optimized settings...\")\n",
    "resnet50_baseline.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='cross_entropy',\n",
    "    learning_rate=0.01,  # Much lower learning rate\n",
    "    weight_decay=1e-4,   # Standard weight decay\n",
    "    scheduler='oneCycle',    # Stable step scheduler instead of onecycle\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "# Train with step scheduler parameters\n",
    "history = resnet50_baseline.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=20,\n",
    "    early_stopping=True,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation accuracy: {max(history['val_accuracy']):.4f}\")\n",
    "print(f\"Final train accuracy: {history['train_accuracy'][-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {history['val_accuracy'][-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
