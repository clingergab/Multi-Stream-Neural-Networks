{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCResNet Training on SUN RGB-D - Google Colab\n",
    "\n",
    "**Complete end-to-end training pipeline for Google Colab with GPU**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Checklist Before Running:\n",
    "\n",
    "- [ ] **Enable GPU:** Runtime â†’ Change runtime type â†’ Hardware accelerator: GPU\n",
    "- [ ] **Mount Google Drive:** Your code and preprocessed dataset will be stored on Drive\n",
    "- [ ] **Upload SUN RGB-D dataset to Drive:** `MyDrive/datasets/sunrgbd_15/` (preprocessed locally)\n",
    "- [ ] **Expected Runtime:** ~3-4 hours for 30 epochs\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ What This Notebook Does:\n",
    "\n",
    "1. âœ… Verify GPU is available\n",
    "2. âœ… Mount Google Drive\n",
    "3. âœ… Clone your repository to local disk (fast I/O)\n",
    "4. âœ… Copy SUN RGB-D dataset to local disk (10-20x faster than Drive)\n",
    "5. âœ… Install dependencies\n",
    "6. âœ… Train MCResNet on 15 scene categories\n",
    "7. âœ… Save checkpoints to Drive (persistent storage)\n",
    "8. âœ… Generate training analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset:** SUN RGB-D 15 categories (10,059 samples, 8.5x class balance)\n",
    "\n",
    "**Let's get started!** ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and specs\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Check GPU type\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    if 'A100' in gpu_name:\n",
    "        print(\"\\nâœ… A100 GPU detected - PERFECT for training!\")\n",
    "    elif 'V100' in gpu_name:\n",
    "        print(\"\\nâœ… V100 GPU detected - Good for training!\")\n",
    "    elif 'T4' in gpu_name:\n",
    "        print(\"\\nâœ… T4 GPU detected - Will work fine!\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… GPU: {gpu_name}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  NO GPU DETECTED - Training will be slow!\")\n",
    "    print(\"Please enable GPU: Runtime â†’ Change runtime type â†’ Hardware accelerator: GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed GPU info\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\nâœ… Google Drive mounted successfully!\")\n",
    "print(f\"\\nChecking for dataset...\")\n",
    "\n",
    "# Check if dataset exists on Drive\n",
    "dataset_path = Path('/content/drive/MyDrive/datasets/sunrgbd_15')\n",
    "if dataset_path.exists():\n",
    "    print(f\"âœ… Dataset found on Drive!\")\n",
    "    print(f\"   Path: {dataset_path}\")\n",
    "else:\n",
    "    print(f\"âŒ Dataset NOT found at: {dataset_path}\")\n",
    "    print(f\"\\nPlease upload the preprocessed dataset to:\")\n",
    "    print(f\"   Google Drive â†’ My Drive â†’ datasets â†’ sunrgbd_15/\")\n",
    "    print(f\"\\nExpected structure:\")\n",
    "    print(f\"   sunrgbd_15/\")\n",
    "    print(f\"     train/rgb/       (8,041 images)\")\n",
    "    print(f\"     train/depth/     (8,041 images)\")\n",
    "    print(f\"     train/labels.txt\")\n",
    "    print(f\"     val/rgb/         (2,018 images)\")\n",
    "    print(f\"     val/depth/       (2,018 images)\")\n",
    "    print(f\"     val/labels.txt\")\n",
    "    print(f\"     class_names.txt\")\n",
    "    print(f\"     dataset_info.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clone Repository to Local Disk (Fast I/O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "PROJECT_NAME = \"Multi-Stream-Neural-Networks\"\n",
    "GITHUB_REPO = \"https://github.com/clingergab/Multi-Stream-Neural-Networks.git\"  # UPDATE THIS\n",
    "LOCAL_REPO_PATH = f\"/content/{PROJECT_NAME}\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REPOSITORY SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "os.chdir('/content')\n",
    "\n",
    "# Check if repo already exists\n",
    "if Path(LOCAL_REPO_PATH).exists() and Path(f\"{LOCAL_REPO_PATH}/.git\").exists():\n",
    "    print(f\"\\nðŸ“ Repo already exists: {LOCAL_REPO_PATH}\")\n",
    "    print(f\"ðŸ”„ Pulling latest changes...\")\n",
    "    os.chdir(LOCAL_REPO_PATH)\n",
    "    !git pull\n",
    "    print(\"âœ… Repo updated\")\n",
    "else:\n",
    "    # Remove old incomplete copy if exists\n",
    "    if Path(LOCAL_REPO_PATH).exists():\n",
    "        !rm -rf {LOCAL_REPO_PATH}\n",
    "    \n",
    "    print(f\"\\nðŸ”„ Cloning from GitHub...\")\n",
    "    !git clone {GITHUB_REPO} {LOCAL_REPO_PATH}\n",
    "    os.chdir(LOCAL_REPO_PATH)\n",
    "    print(\"âœ… Repo cloned successfully\")\n",
    "\n",
    "print(f\"\\nâœ… Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Copy Dataset to Local Disk (CRITICAL for Speed!)\n",
    "\n",
    "**Performance:** Local disk I/O is ~10-20x faster than Drive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "DRIVE_DATASET_PATH = \"/content/drive/MyDrive/datasets/sunrgbd_15\"\n",
    "LOCAL_DATASET_PATH = \"/content/data/sunrgbd_15\"  # Local disk (FAST)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUN RGB-D DATASET SETUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if already on local disk\n",
    "if Path(LOCAL_DATASET_PATH).exists():\n",
    "    print(f\"\\nâœ… Dataset already on local disk: {LOCAL_DATASET_PATH}\")\n",
    "    \n",
    "    # Verify structure\n",
    "    train_rgb = len(list(Path(LOCAL_DATASET_PATH).glob(\"train/rgb/*.png\")))\n",
    "    val_rgb = len(list(Path(LOCAL_DATASET_PATH).glob(\"val/rgb/*.png\")))\n",
    "    \n",
    "    print(f\"   Train samples: {train_rgb}\")\n",
    "    print(f\"   Val samples: {val_rgb}\")\n",
    "    \n",
    "    if train_rgb == 8041 and val_rgb == 2018:\n",
    "        print(f\"   âœ… Dataset complete!\")\n",
    "    else:\n",
    "        print(f\"   âš  Dataset incomplete, will re-copy from Drive\")\n",
    "        shutil.rmtree(LOCAL_DATASET_PATH)\n",
    "\n",
    "# Copy from Drive to local disk\n",
    "if not Path(LOCAL_DATASET_PATH).exists():\n",
    "    if Path(DRIVE_DATASET_PATH).exists():\n",
    "        print(f\"\\nðŸ“ Found dataset on Drive: {DRIVE_DATASET_PATH}\")\n",
    "        print(f\"ðŸ“¥ Copying to local disk for 10-20x faster training...\")\n",
    "        print(f\"   This takes ~2-3 minutes but saves 60+ minutes during training!\")\n",
    "        print(f\"   Dataset size: ~4.3 GB\")\n",
    "        \n",
    "        # Create parent directory\n",
    "        Path(LOCAL_DATASET_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy (faster with shell command)\n",
    "        !cp -r {DRIVE_DATASET_PATH} /content/data/\n",
    "        \n",
    "        print(f\"\\nâœ… Dataset copied to local disk\")\n",
    "        \n",
    "        # Verify\n",
    "        train_rgb = len(list(Path(LOCAL_DATASET_PATH).glob(\"train/rgb/*.png\")))\n",
    "        val_rgb = len(list(Path(LOCAL_DATASET_PATH).glob(\"val/rgb/*.png\")))\n",
    "        \n",
    "        print(f\"   Train samples: {train_rgb}\")\n",
    "        print(f\"   Val samples: {val_rgb}\")\n",
    "        \n",
    "        if train_rgb == 8041 and val_rgb == 2018:\n",
    "            print(f\"   âœ… All samples verified!\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Dataset not found on Drive: {DRIVE_DATASET_PATH}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… Dataset ready at: {LOCAL_DATASET_PATH}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing dependencies...\")\n",
    "\n",
    "!pip install -q tqdm matplotlib seaborn\n",
    "\n",
    "print(\"âœ… All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Python Path & Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project to Python path\n",
    "project_root = '/content/Multi-Stream-Neural-Networks'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Import modules\n",
    "print(\"Importing modules...\")\n",
    "from src.models.multi_channel.mc_resnet import mc_resnet18, mc_resnet50\n",
    "from src.data_utils.sunrgbd_dataset import get_sunrgbd_dataloaders\n",
    "\n",
    "print(\"âœ… Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load SUN RGB-D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LOADING SUN RGB-D DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_CONFIG = {\n",
    "    'data_root': '/content/data/sunrgbd_15',\n",
    "    'batch_size': 64,  # Adjust based on GPU memory\n",
    "    'num_workers': 2,\n",
    "    'target_size': (224, 224),\n",
    "    'num_classes': 15  # SUN RGB-D 15 merged categories\n",
    "}\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "for key, value in DATASET_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = get_sunrgbd_dataloaders(\n",
    "    data_root=DATASET_CONFIG['data_root'],\n",
    "    batch_size=DATASET_CONFIG['batch_size'],\n",
    "    num_workers=DATASET_CONFIG['num_workers'],\n",
    "    target_size=DATASET_CONFIG['target_size'],\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Train samples: {len(train_loader.dataset)}\")\n",
    "print(f\"  Val samples: {len(val_loader.dataset)}\")\n",
    "\n",
    "# Test loading a batch\n",
    "rgb_batch, depth_batch, label_batch = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  RGB: {rgb_batch.shape}\")\n",
    "print(f\"  Depth: {depth_batch.shape}\")\n",
    "print(f\"  Labels: {label_batch.shape}\")\n",
    "print(f\"  Label range: [{label_batch.min()}, {label_batch.max()}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Get class names\n",
    "CLASS_NAMES = train_loader.dataset.CLASS_NAMES\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "\n",
    "for i in range(4):\n",
    "    rgb = rgb_batch[i].cpu()\n",
    "    depth = depth_batch[i].cpu()\n",
    "    label = label_batch[i].item()\n",
    "    \n",
    "    # Denormalize RGB\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    rgb_vis = rgb * std + mean\n",
    "    rgb_vis = torch.clamp(rgb_vis, 0, 1)\n",
    "    \n",
    "    # Plot RGB\n",
    "    axes[0, i].imshow(rgb_vis.permute(1, 2, 0))\n",
    "    axes[0, i].set_title(f\"RGB - {CLASS_NAMES[label]}\", fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot Depth\n",
    "    axes[1, i].imshow(depth.squeeze(), cmap='viridis')\n",
    "    axes[1, i].set_title(f\"Depth - {CLASS_NAMES[label]}\", fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('SUN RGB-D Sample Data (RGB + Depth)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Sample visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create MCResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODEL CREATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'architecture': 'resnet18',  # or 'resnet50' for better accuracy\n",
    "    'num_classes': 15,\n",
    "    'pretrained': False,  # Set True to use ImageNet pretrained weights\n",
    "}\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "for key, value in MODEL_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if MODEL_CONFIG['architecture'] == 'resnet18':\n",
    "    model = mc_resnet18(\n",
    "        num_classes=MODEL_CONFIG['num_classes'],\n",
    "        pretrained=MODEL_CONFIG['pretrained'],\n",
    "    )\n",
    "elif MODEL_CONFIG['architecture'] == 'resnet50':\n",
    "    model = mc_resnet50(\n",
    "        num_classes=MODEL_CONFIG['num_classes'],\n",
    "        pretrained=MODEL_CONFIG['pretrained'],\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nâœ… Model created successfully!\")\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Setup Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training configuration\n",
    "TRAIN_CONFIG = {\n",
    "    'epochs': 30,\n",
    "    'base_lr': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'scheduler': 'cosine',\n",
    "    \n",
    "    # Stream-specific optimization (optional)\n",
    "    'use_stream_specific': False,  # Set True if one stream is overfitting\n",
    "    'stream1_lr_mult': 1.0,   # RGB stream LR multiplier\n",
    "    'stream2_lr_mult': 1.5,   # Depth stream LR multiplier (boost if needed)\n",
    "    'stream1_wd_mult': 1.0,   # RGB weight decay multiplier\n",
    "    'stream2_wd_mult': 0.5,   # Depth weight decay multiplier\n",
    "}\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "for key, value in TRAIN_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create optimizer\n",
    "if TRAIN_CONFIG['use_stream_specific']:\n",
    "    print(f\"\\nâœ“ Using stream-specific optimization\")\n",
    "    \n",
    "    # Separate parameters\n",
    "    stream1_params = []\n",
    "    stream2_params = []\n",
    "    other_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'stream1' in name:\n",
    "            stream1_params.append(param)\n",
    "        elif 'stream2' in name:\n",
    "            stream2_params.append(param)\n",
    "        else:\n",
    "            other_params.append(param)\n",
    "    \n",
    "    optimizer = optim.Adam([\n",
    "        {\n",
    "            'params': stream1_params,\n",
    "            'lr': TRAIN_CONFIG['base_lr'] * TRAIN_CONFIG['stream1_lr_mult'],\n",
    "            'weight_decay': TRAIN_CONFIG['weight_decay'] * TRAIN_CONFIG['stream1_wd_mult']\n",
    "        },\n",
    "        {\n",
    "            'params': stream2_params,\n",
    "            'lr': TRAIN_CONFIG['base_lr'] * TRAIN_CONFIG['stream2_lr_mult'],\n",
    "            'weight_decay': TRAIN_CONFIG['weight_decay'] * TRAIN_CONFIG['stream2_wd_mult']\n",
    "        },\n",
    "        {\n",
    "            'params': other_params,\n",
    "            'lr': TRAIN_CONFIG['base_lr'],\n",
    "            'weight_decay': TRAIN_CONFIG['weight_decay']\n",
    "        }\n",
    "    ])\n",
    "    \n",
    "    print(f\"  Stream1 (RGB) LR: {TRAIN_CONFIG['base_lr'] * TRAIN_CONFIG['stream1_lr_mult']:.6f}\")\n",
    "    print(f\"  Stream2 (Depth) LR: {TRAIN_CONFIG['base_lr'] * TRAIN_CONFIG['stream2_lr_mult']:.6f}\")\n",
    "else:\n",
    "    print(f\"\\nâœ“ Using standard optimization\")\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=TRAIN_CONFIG['base_lr'],\n",
    "        weight_decay=TRAIN_CONFIG['weight_decay']\n",
    "    )\n",
    "\n",
    "# Loss and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=TRAIN_CONFIG['epochs'])\n",
    "\n",
    "# Checkpoint directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint_dir = f\"/content/drive/MyDrive/mcresnet_checkpoints/sunrgbd_{timestamp}\"\n",
    "!mkdir -p {checkpoint_dir}\n",
    "\n",
    "print(f\"\\nâœ… Training setup complete!\")\n",
    "print(f\"\\nCheckpoint directory: {checkpoint_dir}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "}\n",
    "\n",
    "for epoch in range(TRAIN_CONFIG['epochs']):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{TRAIN_CONFIG['epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for rgb, depth, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        rgb, depth, labels = rgb.to(device), depth.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb, depth)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rgb, depth, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            rgb, depth, labels = rgb.to(device), depth.to(device), labels.to(device)\n",
    "            outputs = model(rgb, depth)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nEpoch {epoch + 1} Results:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}   | Val Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        print(f\"\\nðŸ’¾ New best validation accuracy: {val_acc*100:.2f}% - Saving...\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'config': MODEL_CONFIG\n",
    "        }, f\"{checkpoint_dir}/best_model.pth\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸŽ‰ TRAINING COMPLETE!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save history\n",
    "with open(f\"{checkpoint_dir}/training_history.json\", 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Results saved to: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot([acc*100 for acc in history['train_acc']], label='Train Acc', linewidth=2)\n",
    "axes[1].plot([acc*100 for acc in history['val_acc']], label='Val Acc', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{checkpoint_dir}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Training curves saved to: {checkpoint_dir}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nâœ… Training Complete!\")\n",
    "print(f\"\\nDataset: SUN RGB-D (15 categories)\")\n",
    "print(f\"  Train samples: {len(train_loader.dataset)}\")\n",
    "print(f\"  Val samples: {len(val_loader.dataset)}\")\n",
    "\n",
    "print(f\"\\nModel: MCResNet-{MODEL_CONFIG['architecture'].upper()}\")\n",
    "print(f\"  Parameters: {total_params:,}\")\n",
    "\n",
    "print(f\"\\nTraining Results:\")\n",
    "print(f\"  Epochs trained: {len(history['train_loss'])}\")\n",
    "print(f\"  Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "print(f\"  Final train accuracy: {history['train_acc'][-1]*100:.2f}%\")\n",
    "print(f\"  Final val accuracy: {history['val_acc'][-1]*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nCheckpoints saved to:\")\n",
    "print(f\"  {checkpoint_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸŽ‰ All done! Check Google Drive for saved models.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
