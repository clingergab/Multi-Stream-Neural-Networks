{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33445e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "# Enable cuDNN autotuner for fixed input sizes (can improve throughput)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# Configure DataLoader workers and prefetch\n",
    "num_workers = max(1, os.cpu_count() - 1)\n",
    "prefetch_factor = 2\n",
    "print(f\"Using {num_workers} num_workers and prefetch_factor={prefetch_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Reset peak memory stats and grab one mini-batch\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "rgb_batch, bright_batch, _ = next(iter(train_loader))\n",
    "# Move to device and forward/backward to measure memory\n",
    "resnet50_mc_streaming = mc_resnet50(num_classes=num_classes, device=str(device), use_amp=True, groups=2)\n",
    "with torch.cuda.device(device):\n",
    "    _ = resnet50_mc_streaming(rgb_batch.to(device), bright_batch.to(device))\n",
    "    # If using amp & need backward, wrap loss/backward here\n",
    "print(f\"Peak GPU usage: {torch.cuda.max_memory_allocated()/1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9118ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure GPU memory usage including backward pass and optimizer step\n",
    "import torch.optim as optim\n",
    "optimizer = optim.AdamW(resnet50_mc_streaming.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# Reset and run forward+backward+step\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "rgb, bright, labels = rgb_batch.to(device), bright_batch.to(device), labels.to(device)\n",
    "outputs = resnet50_mc_streaming(rgb, bright)\n",
    "loss = loss_fn(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(f\"Peak GPU usage (forward+backward): {torch.cuda.max_memory_allocated()/1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceebf5c",
   "metadata": {},
   "source": [
    "Based on the peak‚Äêmemory measurement (~32 GB for a batch size of 128), you don‚Äôt have enough headroom to double the batch to 256 without risking an OOM. \n",
    "\n",
    "To effectively train with an *effective* batch of 256:\n",
    "- Keep your DataLoader at `batch_size=128` and use `gradient_accumulation_steps=2` in `fit()`.\n",
    "- Alternatively, incrementally test intermediate sizes (e.g., 160, 192) and re‚Äêmeasure before going higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9272130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc_resnet50 with streaming dual-channel data\n",
    "\n",
    "import traceback\n",
    "\n",
    "# Test mc_resnet50 with StreamingDualChannelDataset for ImageNet\n",
    "print(\"üöÄ TESTING MC-RESNET50 WITH STREAMING DUAL-CHANNEL IMAGENET DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"üßπ Clearing GPU cache...\")\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory before training: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "from src.data_utils.streaming_dual_channel_dataset import (\n",
    "    StreamingDualChannelDataset,\n",
    "    create_imagenet_dual_channel_train_val_dataloaders,\n",
    "    create_imagenet_dual_channel_test_dataloader,\n",
    "    create_default_imagenet_transforms\n",
    ")\n",
    "from src.models2.multi_channel.mc_resnet import mc_resnet50\n",
    "\n",
    "# Set up device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üöÄ Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"üöÄ Using Apple Metal Performance Shaders (MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"üíª Using CPU\")\n",
    "\n",
    "# Configuration\n",
    "batch_size = 128  # this is the max possible batch_size currently\n",
    "image_size = (224, 224)\n",
    "num_epochs = 1  # Smaller number for demonstration\n",
    "\n",
    "TRAIN_FOLDERS = [\n",
    "    \"data/ImageNet-1K/train_images_0\"\n",
    "    # \"../data/ImageNet/train_images_1\",  # Add more if you have split training data\n",
    "]\n",
    "VAL_FOLDER = \"data/ImageNet-1K/val_images\"\n",
    "TEST_FOLDER = \"data/ImageNet-1K/test_images\"\n",
    "TRUTH_FILE = \"data/ImageNet-1K/ILSVRC2013_devkit/data/ILSVRC2013_clsloc_validation_ground_truth.txt\"\n",
    "\n",
    "print(f\"\\nüìÇ Dataset Configuration:\")\n",
    "print(f\"Training folders: {TRAIN_FOLDERS}\")\n",
    "print(f\"Validation folder: {VAL_FOLDER}\")\n",
    "print(f\"Truth file: {TRUTH_FILE}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Image size: {image_size}\")\n",
    "print(f\"Training epochs: {num_epochs}\")\n",
    "\n",
    "# Create DataLoaders using our streaming dataset\n",
    "print(f\"\\nüìä Creating Streaming Dual-Channel DataLoaders...\")\n",
    "try:\n",
    "    train_loader, val_loader = create_imagenet_dual_channel_train_val_dataloaders(\n",
    "        train_folders=TRAIN_FOLDERS,\n",
    "        val_folder=VAL_FOLDER,\n",
    "        truth_file=TRUTH_FILE,\n",
    "        # train_transform=train_transform,\n",
    "        # val_transform=val_transform,\n",
    "        batch_size=batch_size,\n",
    "        val_batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        num_workers=num_workers,  # Reduce for notebook stability\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=prefetch_factor\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Train loader: {len(train_loader)} batches\")\n",
    "    print(f\"‚úÖ Val loader: {len(val_loader)} batches\")\n",
    "    print(\"‚úÖ DataLoaders created successfully!\")\n",
    "\n",
    "    # Determine number of classes from the dataset\n",
    "    if hasattr(train_loader.dataset, 'class_to_idx') and train_loader.dataset.class_to_idx:\n",
    "        num_classes = len(train_loader.dataset.class_to_idx)\n",
    "        print(f\"‚úÖ Number of classes detected: {num_classes}\")\n",
    "    else:\n",
    "        num_classes = 1000  # Default ImageNet classes\n",
    "        print(f\"‚ö†Ô∏è  Using default ImageNet classes: {num_classes}\")\n",
    "\n",
    "    # Create and train MC-ResNet50 model\n",
    "    print(f\"\\nüèóÔ∏è  Creating MC-ResNet50 model...\")\n",
    "    resnet50_mc_streaming = mc_resnet50(num_classes=num_classes, device=str(device), use_amp=True)\n",
    "\n",
    "    # Compile with optimized settings for ImageNet\n",
    "    print(f\"‚öôÔ∏è  Compiling model with optimized settings...\")\n",
    "    resnet50_mc_streaming.compile(\n",
    "        optimizer='adamw',\n",
    "        loss='cross_entropy',\n",
    "        learning_rate=0.1,\n",
    "        weight_decay=1e-5,      # Standard ImageNet weight decay\n",
    "        scheduler='onecycle',\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüéØ Starting training...\")\n",
    "    print(f\"Training with {len(train_loader)} train batches and {len(val_loader)} val batches\")\n",
    "\n",
    "    # Clear GPU memory before training\n",
    "    print(\"üßπ Clearing GPU cache before training...\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Optional: Print memory stats\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU memory before training: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history_mc_streaming = resnet50_mc_streaming.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        early_stopping=False,\n",
    "        verbose=True,\n",
    "        gradient_accumulation_steps=2\n",
    "        )\n",
    "\n",
    "    print(f\"\\nüéâ Training completed!\")\n",
    "    print(f\"Best validation accuracy: {max(history_mc_streaming['val_accuracy']):.4f}\")\n",
    "    print(f\"Final train accuracy: {history_mc_streaming['train_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final validation accuracy: {history_mc_streaming['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "    # Evaluate on validation set (since we don't have test set in this example)\n",
    "    print(f\"\\nüìä Final evaluation...\")\n",
    "    evaluate_mc_streaming = resnet50_mc_streaming.evaluate(val_loader)\n",
    "    print(f\"Validation loss: {evaluate_mc_streaming['loss']:.4f}\")\n",
    "    print(f\"Validation accuracy: {evaluate_mc_streaming['accuracy']:.4f}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n‚úÖ StreamingDualChannelDataset test completed successfully!\")\n",
    "    print(f\"üéä The model trained on ImageNet data using on-demand loading!\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Dataset not found: {e}\")\n",
    "    print(f\"\\nüí° To run this test, you need to:\")\n",
    "    print(f\"1. Download ImageNet dataset\")\n",
    "    print(f\"2. Update the paths above to point to your ImageNet data:\")\n",
    "    print(f\"   - TRAIN_FOLDERS: path(s) to training images\")\n",
    "    print(f\"   - VAL_FOLDER: path to validation images\")\n",
    "    print(f\"   - TRUTH_FILE: path to validation ground truth file\")\n",
    "    print(f\"3. Ensure the data is in the expected ImageNet format\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during training: {e}\")\n",
    "    print(f\"This might be due to missing data or configuration issues.\")\n",
    "    print(f\"Please check the dataset paths and ensure ImageNet data is available.\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"üèÅ StreamingDualChannelDataset Demo Complete!\")\n",
    "#/content/drive/MyDrive/Multi-Stream-Neural-Networks/data/ImageNet-1K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a single batch from our ImageNet train_loader\n",
    "rgb_batch, bright_batch, labels = next(iter(train_loader))\n",
    "print(f\"RGB batch shape: {rgb_batch.shape}\\nBrightness batch shape: {bright_batch.shape}\\nLabels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5019b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a single batch from our ImageNet train_loader\n",
    "rgb_batch, bright_batch, labels = next(iter(train_loader))\n",
    "print(f\"RGB batch shape: {rgb_batch.shape}\\nBrightness batch shape: {bright_batch.shape}\\nLabels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743de90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb73e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
