{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# MCResNet Training on NYU Depth V2 - Google Colab\n",
    "\n",
    "**Complete end-to-end training pipeline for Google Colab with A100 GPU**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Checklist Before Running:\n",
    "\n",
    "- [ ] **Enable A100 GPU:** Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU ‚Üí GPU type: A100\n",
    "- [ ] **Mount Google Drive:** Your code and dataset will be stored on Drive\n",
    "- [ ] **Upload dataset to Drive:** `MyDrive/datasets/nyu_depth_v2_labeled.mat` (or we'll download it)\n",
    "- [ ] **Expected Runtime:** ~2-3 hours for 90 epochs\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What This Notebook Does:\n",
    "\n",
    "1. ‚úÖ Verify A100 GPU is available\n",
    "2. ‚úÖ Mount Google Drive\n",
    "3. ‚úÖ Clone your repository to local disk (fast I/O)\n",
    "4. ‚úÖ Download/copy NYU Depth V2 to local disk (10-20x faster than Drive)\n",
    "5. ‚úÖ Install dependencies\n",
    "6. ‚úÖ Train MCResNet with all optimizations\n",
    "7. ‚úÖ Save checkpoints to Drive (persistent storage)\n",
    "8. ‚úÖ Generate training curves and analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Let's get started!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-1"
   },
   "source": [
    "## 1. Environment Setup & GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability and specs\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Check if it's A100\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    if 'A100' in gpu_name:\n",
    "        print(\"\\n‚úÖ A100 GPU detected - PERFECT for training!\")\n",
    "    elif 'V100' in gpu_name:\n",
    "        print(\"\\n‚úÖ V100 GPU detected - Good for training (slower than A100)\")\n",
    "    elif 'T4' in gpu_name:\n",
    "        print(\"\\n‚ö†Ô∏è  T4 GPU detected - Will be slower, consider upgrading to A100\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  GPU: {gpu_name} - Consider using A100 for best performance\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NO GPU DETECTED!\")\n",
    "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU\")\n",
    "    raise RuntimeError(\"GPU is required for training\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvidia-smi"
   },
   "outputs": [],
   "source": [
    "# Detailed GPU info\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-2"
   },
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n‚úÖ Google Drive mounted successfully!\")\n",
    "print(f\"\\nDrive contents:\")\n",
    "!ls -la /content/drive/MyDrive/ | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-3"
   },
   "source": [
    "## 3. Clone Repository to Local Disk (Fast I/O)\n",
    "\n",
    "**Important:** We clone to `/content/` (local SSD) instead of Drive for 10-20x faster I/O\n",
    "\n",
    "**Default:** Clone from GitHub (recommended - always gets latest code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "PROJECT_NAME = \"Multi-Stream-Neural-Networks\"\n",
    "GITHUB_REPO = \"https://github.com/clingergab/Multi-Stream-Neural-Networks.git\"  # UPDATE THIS\n",
    "LOCAL_REPO_PATH = f\"/content/{PROJECT_NAME}\"  # Local copy for fast I/O\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REPOSITORY SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ensure we're in a valid directory\n",
    "os.chdir('/content')\n",
    "print(f\"Starting in: {os.getcwd()}\")\n",
    "\n",
    "# Check if repo already exists (same session, rerunning cell)\n",
    "if Path(LOCAL_REPO_PATH).exists() and Path(f\"{LOCAL_REPO_PATH}/.git\").exists():\n",
    "    print(f\"\\nüìÅ Repo already exists: {LOCAL_REPO_PATH}\")\n",
    "    print(f\"üîÑ Pulling latest changes...\")\n",
    "    \n",
    "    os.chdir(LOCAL_REPO_PATH)\n",
    "    !git pull\n",
    "    print(\"‚úÖ Repo updated\")\n",
    "\n",
    "# Clone from GitHub (first run)\n",
    "else:\n",
    "    # Remove old incomplete copy if exists\n",
    "    if Path(LOCAL_REPO_PATH).exists():\n",
    "        print(f\"\\nüóëÔ∏è  Removing incomplete repo copy...\")\n",
    "        !rm -rf {LOCAL_REPO_PATH}\n",
    "    \n",
    "    print(f\"\\nüîÑ Cloning from GitHub...\")\n",
    "    print(f\"   Repo: {GITHUB_REPO}\")\n",
    "    print(f\"   Destination: {LOCAL_REPO_PATH}\")\n",
    "    \n",
    "    !git clone {GITHUB_REPO} {LOCAL_REPO_PATH}\n",
    "    \n",
    "    # Verify clone succeeded\n",
    "    if not Path(LOCAL_REPO_PATH).exists():\n",
    "        raise RuntimeError(f\"Failed to clone repository to {LOCAL_REPO_PATH}\")\n",
    "    \n",
    "    print(\"‚úÖ Repo cloned successfully\")\n",
    "    os.chdir(LOCAL_REPO_PATH)\n",
    "\n",
    "# Verify repo structure\n",
    "print(f\"\\nüìÇ Repository structure:\")\n",
    "!ls -la {LOCAL_REPO_PATH}\n",
    "\n",
    "print(f\"\\n‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-4"
   },
   "source": [
    "## 4. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing dependencies...\")\n",
    "\n",
    "!pip install -q h5py tqdm matplotlib seaborn\n",
    "\n",
    "# Verify installations\n",
    "import h5py\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import seaborn\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")\n",
    "print(f\"   h5py: {h5py.__version__}\")\n",
    "print(f\"   matplotlib: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-5"
   },
   "source": [
    "## 5. Download NYU Depth V2 Dataset to Local Disk\n",
    "\n",
    "**Performance Note:** Local disk I/O is ~10-20x faster than Drive!\n",
    "\n",
    "**Options:**\n",
    "- **Option A:** Download directly to local disk (~2.8 GB, takes 2-3 min)\n",
    "- **Option B:** Copy from Drive if you already have it there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-dataset"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "DRIVE_DATASET_PATH = \"/content/drive/MyDrive/datasets/nyu_depth_v2_labeled.mat\"\n",
    "LOCAL_DATASET_PATH = \"/content/nyu_depth_v2_labeled.mat\"  # Local disk (FAST)\n",
    "DATASET_URL = \"http://horatio.cs.nyu.edu/mit/silberman/nyu_depth_v2/nyu_depth_v2_labeled.mat\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NYU DEPTH V2 DATASET SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if already on local disk\n",
    "if Path(LOCAL_DATASET_PATH).exists():\n",
    "    print(f\"‚úÖ Dataset already on local disk: {LOCAL_DATASET_PATH}\")\n",
    "    print(f\"   Size: {Path(LOCAL_DATASET_PATH).stat().st_size / 1024**3:.2f} GB\")\n",
    "\n",
    "# Option A: Copy from Drive (if available)\n",
    "elif Path(DRIVE_DATASET_PATH).exists():\n",
    "    print(f\"üìÅ Found dataset on Drive: {DRIVE_DATASET_PATH}\")\n",
    "    print(f\"üì• Copying to local disk for 10-20x faster training...\")\n",
    "    print(f\"   This takes ~2-3 minutes but saves 60+ minutes during training!\")\n",
    "    \n",
    "    !cp {DRIVE_DATASET_PATH} {LOCAL_DATASET_PATH}\n",
    "    \n",
    "    print(f\"‚úÖ Dataset copied to local disk\")\n",
    "    print(f\"   Size: {Path(LOCAL_DATASET_PATH).stat().st_size / 1024**3:.2f} GB\")\n",
    "\n",
    "# Option B: Download from internet\n",
    "else:\n",
    "    print(f\"üì• Downloading NYU Depth V2 dataset (~2.8 GB)...\")\n",
    "    print(f\"   URL: {DATASET_URL}\")\n",
    "    print(f\"   Destination: {LOCAL_DATASET_PATH}\")\n",
    "    print(f\"   This will take ~2-3 minutes\")\n",
    "    \n",
    "    # Download with progress bar\n",
    "    class DownloadProgressBar(tqdm):\n",
    "        def update_to(self, b=1, bsize=1, tsize=None):\n",
    "            if tsize is not None:\n",
    "                self.total = tsize\n",
    "            self.update(b * bsize - self.n)\n",
    "    \n",
    "    with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc='NYU Depth V2') as t:\n",
    "        urllib.request.urlretrieve(DATASET_URL, LOCAL_DATASET_PATH, reporthook=t.update_to)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Download complete!\")\n",
    "    print(f\"   Size: {Path(LOCAL_DATASET_PATH).stat().st_size / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Optionally save to Drive for future use\n",
    "    save_to_drive = input(\"\\nSave dataset to Drive for future sessions? (y/N): \")\n",
    "    if save_to_drive.lower() == 'y':\n",
    "        print(\"Saving to Drive...\")\n",
    "        !mkdir -p /content/drive/MyDrive/datasets/\n",
    "        !cp {LOCAL_DATASET_PATH} {DRIVE_DATASET_PATH}\n",
    "        print(\"‚úÖ Saved to Drive\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Dataset ready at: {LOCAL_DATASET_PATH}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-6"
   },
   "source": [
    "## 6. Setup Python Path & Import MCResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-imports"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Remove cached modules\n",
    "modules_to_reload = [k for k in sys.modules.keys() if k.startswith('src.')]\n",
    "for module in modules_to_reload:\n",
    "    del sys.modules[module]\n",
    "    \n",
    "# Add project to Python path\n",
    "project_root = '/content/Multi-Stream-Neural-Networks'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Verify project structure\n",
    "print(\"Project structure:\")\n",
    "!ls -la {project_root}/src/models/\n",
    "\n",
    "# Import MCResNet\n",
    "print(\"\\nImporting MCResNet...\")\n",
    "from src.models.multi_channel.mc_resnet import mc_resnet18, mc_resnet50\n",
    "from src.data_utils.nyu_depth_dataset import create_nyu_dataloaders\n",
    "\n",
    "print(\"‚úÖ MCResNet imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-7"
   },
   "source": [
    "## 7. Load NYU Depth V2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Check actual HDF5 structure\n",
    "import h5py\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DEBUG: NYU DEPTH V2 DATASET STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with h5py.File('/content/nyu_depth_v2_labeled.mat', 'r') as f:\n",
    "    print(\"\\nAvailable keys:\")\n",
    "    for key in f.keys():\n",
    "        print(f\"  {key}\")\n",
    "    \n",
    "    print(\"\\nDataset shapes:\")\n",
    "    print(f\"  images: {f['images'].shape}\")\n",
    "    print(f\"  depths: {f['depths'].shape}\")\n",
    "    print(f\"  labels: {f['labels'].shape}\")\n",
    "    \n",
    "    # Check if scenes exists\n",
    "    if 'scenes' in f:\n",
    "        print(f\"  scenes: {f['scenes'].shape}\")\n",
    "    \n",
    "    # Sample first image to check format\n",
    "    print(\"\\nSample data inspection:\")\n",
    "    print(f\"  images[0:3, 0:10, 0:10, 0] shape: {f['images'][0:3, 0:10, 0:10, 0].shape}\")\n",
    "    print(f\"  images dtype: {f['images'].dtype}\")\n",
    "    print(f\"  depths dtype: {f['depths'].dtype}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-dataset"
   },
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"LOADING NYU DEPTH V2 DATASET\")\nprint(\"=\" * 60)\n\n# Dataset configuration\nDATASET_CONFIG = {\n    'dataset_path': '/content/nyu_depth_v2_labeled.mat',\n    'batch_size': 128,  # A100 can handle this with AMP\n    'num_workers': 2,\n    'target_size': (224, 224),\n    'num_classes': 27   # NYU Depth V2 has 27 scene types (labels 0-26)\n}\n\nprint(f\"Configuration:\")\nfor key, value in DATASET_CONFIG.items():\n    print(f\"  {key}: {value}\")\n\nprint(f\"\\nLoading dataset from: {DATASET_CONFIG['dataset_path']}\")\n\n# Create dataloaders\ntrain_loader, val_loader = create_nyu_dataloaders(\n    h5_file_path=DATASET_CONFIG['dataset_path'],\n    batch_size=DATASET_CONFIG['batch_size'],\n    num_workers=DATASET_CONFIG['num_workers'],\n    target_size=DATASET_CONFIG['target_size'],\n    num_classes=DATASET_CONFIG['num_classes']\n)\n\nprint(f\"\\n‚úÖ Dataset loaded successfully!\")\nprint(f\"\\nDataset Statistics:\")\nprint(f\"  Train batches: {len(train_loader)}\")\nprint(f\"  Val batches: {len(val_loader)}\")\nprint(f\"  Train samples: {len(train_loader.dataset)}\")\nprint(f\"  Val samples: {len(val_loader.dataset)}\")\nprint(f\"  Batch size: {DATASET_CONFIG['batch_size']}\")\n\n# Test loading a batch\nprint(f\"\\nTesting batch loading...\")\nrgb_batch, depth_batch, label_batch = next(iter(train_loader))\nprint(f\"  RGB shape: {rgb_batch.shape}\")\nprint(f\"  Depth shape: {depth_batch.shape}\")\nprint(f\"  Labels shape: {label_batch.shape}\")\nprint(f\"  Labels min: {label_batch.min().item()}, max: {label_batch.max().item()}\")\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-8"
   },
   "source": [
    "## 8. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-data"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "\n",
    "for i in range(4):\n",
    "    rgb = rgb_batch[i].cpu()\n",
    "    depth = depth_batch[i].cpu()\n",
    "    label = label_batch[i].item()\n",
    "    \n",
    "    # Denormalize for visualization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    rgb_vis = rgb * std + mean\n",
    "    rgb_vis = torch.clamp(rgb_vis, 0, 1)\n",
    "    \n",
    "    # Plot RGB\n",
    "    axes[0, i].imshow(rgb_vis.permute(1, 2, 0))\n",
    "    axes[0, i].set_title(f\"RGB - Class {label}\", fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot Depth\n",
    "    axes[1, i].imshow(depth.squeeze(), cmap='viridis')\n",
    "    axes[1, i].set_title(f\"Depth - Class {label}\", fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('NYU Depth V2 Sample Data (RGB + Depth)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-9"
   },
   "source": [
    "## 9. Create & Compile MCResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-model"
   },
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"MODEL CREATION\")\nprint(\"=\" * 60)\n\n# Model configuration with stream-specific optimization\nMODEL_CONFIG = {\n    'architecture': 'resnet18',  # or 'resnet50' for better accuracy\n    'num_classes': 27,  # NYU Depth V2 has 27 scene types (labels 0-26)\n    'stream1_channels': 3,  # RGB\n    'stream2_channels': 1,  # Depth\n    'fusion_type': 'weighted',  # 'concat', 'weighted', or 'gated'\n    'dropout_p': 0.3,  # Dropout for regularization\n    'device': 'cuda',\n    'use_amp': True  # Automatic Mixed Precision (2x faster on A100)\n}\n\nprint(f\"Configuration:\")\nfor key, value in MODEL_CONFIG.items():\n    print(f\"  {key}: {value}\")\n\n# Create model\nprint(f\"\\nCreating MCResNet-{MODEL_CONFIG['architecture'].upper()}...\")\n\nif MODEL_CONFIG['architecture'] == 'resnet18':\n    model = mc_resnet18(\n        num_classes=MODEL_CONFIG['num_classes'],\n        stream1_input_channels=MODEL_CONFIG['stream1_channels'],\n        stream2_input_channels=MODEL_CONFIG['stream2_channels'],\n        fusion_type=MODEL_CONFIG['fusion_type'],\n        dropout_p=MODEL_CONFIG['dropout_p'],\n        device=MODEL_CONFIG['device'],\n        use_amp=MODEL_CONFIG['use_amp']\n    )\nelif MODEL_CONFIG['architecture'] == 'resnet50':\n    model = mc_resnet50(\n        num_classes=MODEL_CONFIG['num_classes'],\n        stream1_input_channels=MODEL_CONFIG['stream1_channels'],\n        stream2_input_channels=MODEL_CONFIG['stream2_channels'],\n        fusion_type=MODEL_CONFIG['fusion_type'],\n        dropout_p=MODEL_CONFIG['dropout_p'],\n        device=MODEL_CONFIG['device'],\n        use_amp=MODEL_CONFIG['use_amp']\n    )\n\n# Count parameters\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nfusion_params = sum(p.numel() for p in model.fusion.parameters())\n\nprint(f\"\\n‚úÖ Model created successfully!\")\nprint(f\"\\nModel Statistics:\")\nprint(f\"  Total parameters: {total_params:,}\")\nprint(f\"  Trainable parameters: {trainable_params:,}\")\nprint(f\"  Fusion parameters: {fusion_params:,}\")\nprint(f\"  Model size: {total_params * 4 / 1024**2:.2f} MB (FP32)\")\nprint(f\"  Fusion strategy: {model.fusion_strategy}\")\nprint(f\"  Device: {MODEL_CONFIG['device']}\")\nprint(f\"  AMP enabled: {MODEL_CONFIG['use_amp']}\")\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compile-model"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'optimizer': 'sgd',\n",
    "    'learning_rate': 0.1,  # Standard for ImageNet-style training\n",
    "    'weight_decay': 1e-4,\n",
    "    'momentum': 0.9,\n",
    "    'loss': 'cross_entropy',\n",
    "    'scheduler': 'cosine'\n",
    "}\n",
    "\n",
    "print(\"Compiling model...\")\n",
    "print(f\"\\nTraining configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=TRAINING_CONFIG['optimizer'],\n",
    "    learning_rate=TRAINING_CONFIG['learning_rate'],\n",
    "    weight_decay=TRAINING_CONFIG['weight_decay'],\n",
    "    momentum=TRAINING_CONFIG['momentum'],\n",
    "    loss=TRAINING_CONFIG['loss'],\n",
    "    scheduler=TRAINING_CONFIG['scheduler']\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with stream-specific optimization (optional but recommended)\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPILATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 1: Standard optimization (same LR/WD for all parameters)\n",
    "# Use this if you don't know which stream needs different treatment yet\n",
    "\n",
    "STANDARD_CONFIG = {\n",
    "    'optimizer': 'adamw',\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 2e-2,\n",
    "    'loss': 'cross_entropy',\n",
    "    'scheduler': 'cosine'\n",
    "}\n",
    "\n",
    "# Option 2: Stream-specific optimization (RECOMMENDED for addressing pathway imbalance)\n",
    "# Use this if monitoring shows one stream is overfitting or not learning\n",
    "\n",
    "STREAM_SPECIFIC_CONFIG = {\n",
    "    'optimizer': 'adamw',\n",
    "    'learning_rate': 1e-4,      # Base LR for shared params\n",
    "    'weight_decay': 2e-2,        # Base weight decay\n",
    "    # Stream-specific settings (uncomment and adjust based on monitoring)\n",
    "    # 'stream1_lr': 5e-4,         # 5x higher LR if RGB not learning\n",
    "    # 'stream1_weight_decay': 1e-3,  # Lighter regularization if RGB underfitting\n",
    "    # 'stream2_lr': 5e-5,         # Lower LR if Depth overfitting\n",
    "    # 'stream2_weight_decay': 5e-2,  # Heavier regularization if Depth overfitting\n",
    "    'loss': 'cross_entropy',\n",
    "    'scheduler': 'cosine'\n",
    "}\n",
    "\n",
    "# Choose which config to use\n",
    "USE_STREAM_SPECIFIC = False  # Set to True after first training run if needed\n",
    "config = STREAM_SPECIFIC_CONFIG if USE_STREAM_SPECIFIC else STANDARD_CONFIG\n",
    "\n",
    "print(f\"Optimization strategy: {'Stream-Specific' if USE_STREAM_SPECIFIC else 'Standard'}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "for key, value in config.items():\n",
    "    if value is not None and not key.startswith('_'):\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Compile\n",
    "model.compile(**config)\n",
    "\n",
    "print(\"\\n‚úÖ Model compiled successfully!\")\n",
    "\n",
    "# Show parameter groups if using stream-specific optimization\n",
    "if USE_STREAM_SPECIFIC and hasattr(model.optimizer, 'param_groups'):\n",
    "    print(f\"\\nParameter groups created: {len(model.optimizer.param_groups)}\")\n",
    "    for i, group in enumerate(model.optimizer.param_groups):\n",
    "        print(f\"  Group {i}: LR={group['lr']:.2e}, WD={group['weight_decay']:.2e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import stream monitoring utilities\nfrom src.models.utils import StreamMonitor\n\nprint(\"=\" * 60)\nprint(\"STREAM MONITORING SETUP\")\nprint(\"=\" * 60)\n\n# Create stream monitor\nmonitor = StreamMonitor(model)\n\nprint(f\"\\n‚úÖ Stream monitor created!\")\nprint(f\"\\nMonitoring capabilities:\")\nprint(f\"  ‚Ä¢ Gradient tracking per stream\")\nprint(f\"  ‚Ä¢ Overfitting detection per stream\")\nprint(f\"  ‚Ä¢ Weight evolution tracking\")\nprint(f\"  ‚Ä¢ Automatic hyperparameter recommendations\")\n\n# Count stream parameters by examining model structure\nstream1_count = 0\nstream2_count = 0\nshared_count = 0\n\nfor name, param in model.named_parameters():\n    if 'stream1' in name:\n        stream1_count += 1\n    elif 'stream2' in name:\n        stream2_count += 1\n    else:\n        shared_count += 1\n\nprint(f\"\\nStream parameter counts:\")\nprint(f\"  Stream1 (RGB): {stream1_count} parameter tensors\")\nprint(f\"  Stream2 (Depth): {stream2_count} parameter tensors\")\nprint(f\"  Shared: {shared_count} parameter tensors\")\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10a. Setup Stream Monitoring üîç\n",
    "\n",
    "**Stream monitoring helps you:**\n",
    "- Track which stream (RGB vs Depth) is learning better\n",
    "- Detect which stream is overfitting more\n",
    "- Get automatic recommendations for hyperparameter adjustments\n",
    "- Monitor gradient flow and weight evolution per stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-10"
   },
   "source": [
    "## 10. Test Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-forward"
   },
   "outputs": [],
   "source": [
    "# Test forward pass with detailed debugging\n",
    "print(\"Testing forward pass with CUDA_LAUNCH_BLOCKING for better error messages...\")\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Synchronous CUDA for better error messages\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    rgb_test, depth_test, labels_test = next(iter(train_loader))\n",
    "    \n",
    "    print(f\"\\nInput validation:\")\n",
    "    print(f\"  RGB shape: {rgb_test.shape}, dtype: {rgb_test.dtype}\")\n",
    "    print(f\"  RGB min: {rgb_test.min():.4f}, max: {rgb_test.max():.4f}\")\n",
    "    print(f\"  RGB has NaN: {torch.isnan(rgb_test).any()}\")\n",
    "    print(f\"  RGB has Inf: {torch.isinf(rgb_test).any()}\")\n",
    "    \n",
    "    print(f\"\\n  Depth shape: {depth_test.shape}, dtype: {depth_test.dtype}\")\n",
    "    print(f\"  Depth min: {depth_test.min():.4f}, max: {depth_test.max():.4f}\")\n",
    "    print(f\"  Depth has NaN: {torch.isnan(depth_test).any()}\")\n",
    "    print(f\"  Depth has Inf: {torch.isinf(depth_test).any()}\")\n",
    "    \n",
    "    print(f\"\\n  Labels shape: {labels_test.shape}, dtype: {labels_test.dtype}\")\n",
    "    print(f\"  Labels min: {labels_test.min()}, max: {labels_test.max()}\")\n",
    "    print(f\"  Labels unique: {torch.unique(labels_test).tolist()}\")\n",
    "    \n",
    "    print(\"\\nRunning forward pass...\")\n",
    "    rgb_cuda = rgb_test.to('cuda')\n",
    "    depth_cuda = depth_test.to('cuda')\n",
    "    \n",
    "    try:\n",
    "        outputs = model(rgb_cuda, depth_cuda)\n",
    "        print(f\"  ‚úÖ Forward pass successful!\")\n",
    "        print(f\"  Output shape: {outputs.shape}\")\n",
    "        print(f\"  Output min: {outputs.min():.4f}, max: {outputs.max():.4f}\")\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        print(f\"\\nSample predictions: {predictions.cpu().numpy()[:10]}\")\n",
    "        print(f\"Ground truth: {labels_test.numpy()[:10]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Forward pass failed!\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"\\nThis is likely a model architecture issue, not a data issue.\")\n",
    "        print(f\"Possible causes:\")\n",
    "        print(f\"  1. BatchNorm running stats issue\")\n",
    "        print(f\"  2. Invalid tensor operations in model\")\n",
    "        print(f\"  3. Memory corruption\")\n",
    "        raise\n",
    "\n",
    "print(\"\\n‚úÖ Forward pass test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-11"
   },
   "source": [
    "## 11. Setup Checkpoint Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-checkpoints"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING WITH COMPREHENSIVE STREAM MONITORING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training configuration\n",
    "TRAIN_CONFIG = {\n",
    "    'epochs': 100,\n",
    "    'grad_clip_norm': 5.0,\n",
    "    'early_stopping': True,\n",
    "    'patience': 15,\n",
    "    'min_delta': 0.001,\n",
    "    'monitor': 'val_accuracy',\n",
    "    'restore_best_weights': True,\n",
    "    'save_path': f\"{checkpoint_dir}/best_model.pt\",\n",
    "    # Monitoring settings\n",
    "    'monitor_gradients_every': 1,  # Check gradients every N epochs\n",
    "    'monitor_overfitting_every': 1,  # Check overfitting every N epochs\n",
    "    'display_recommendations': True  # Show automatic recommendations\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "for key, value in TRAIN_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Initialize monitoring storage\n",
    "monitoring_history = {\n",
    "    'stream1_grad_norms': [],\n",
    "    'stream2_grad_norms': [],\n",
    "    'stream1_overfitting_scores': [],\n",
    "    'stream2_overfitting_scores': [],\n",
    "    'stream1_weight_norms': [],\n",
    "    'stream2_weight_norms': [],\n",
    "    'recommendations': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Training will take approximately 2-3 hours on A100\")\n",
    "print(f\"Stream monitoring active - you'll see detailed metrics each epoch\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Custom training loop with integrated monitoring\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(TRAIN_CONFIG['epochs']):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{TRAIN_CONFIG['epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ===== TRAINING PHASE =====\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    # Track gradients on first batch\n",
    "    first_batch_gradients = None\n",
    "    \n",
    "    for batch_idx, (rgb, depth, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        rgb, depth, labels = rgb.cuda(), depth.cuda(), labels.cuda()\n",
    "        \n",
    "        # Forward\n",
    "        model.optimizer.zero_grad()\n",
    "        outputs = model(rgb, depth)\n",
    "        loss = model.criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Monitor gradients on first batch\n",
    "        if batch_idx == 0 and (epoch % TRAIN_CONFIG['monitor_gradients_every'] == 0):\n",
    "            first_batch_gradients = monitor.compute_stream_gradients()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        if TRAIN_CONFIG['grad_clip_norm'] is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), TRAIN_CONFIG['grad_clip_norm'])\n",
    "        \n",
    "        model.optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # Compute training metrics\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # ===== VALIDATION PHASE =====\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rgb, depth, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            rgb, depth, labels = rgb.cuda(), depth.cuda(), labels.cuda()\n",
    "            outputs = model(rgb, depth)\n",
    "            loss = model.criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    # ===== STREAM MONITORING =====\n",
    "    print(f\"\\nüìä Epoch {epoch + 1} Results:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}   | Val Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Monitor gradients\n",
    "    if first_batch_gradients is not None:\n",
    "        monitoring_history['stream1_grad_norms'].append(first_batch_gradients['stream1_grad_norm'])\n",
    "        monitoring_history['stream2_grad_norms'].append(first_batch_gradients['stream2_grad_norm'])\n",
    "        \n",
    "        print(f\"\\nüîç Gradient Monitoring:\")\n",
    "        print(f\"  Stream1 (RGB) grad norm: {first_batch_gradients['stream1_grad_norm']:.6f}\")\n",
    "        print(f\"  Stream2 (Depth) grad norm: {first_batch_gradients['stream2_grad_norm']:.6f}\")\n",
    "        print(f\"  Stream1/Stream2 ratio: {first_batch_gradients['stream1_to_stream2_ratio']:.4f}\")\n",
    "        \n",
    "        # Check for gradient issues\n",
    "        if first_batch_gradients['stream1_grad_norm'] < 1e-6:\n",
    "            print(f\"  ‚ö†Ô∏è  Stream1 gradients very small - may not be learning!\")\n",
    "        if first_batch_gradients['stream2_grad_norm'] < 1e-6:\n",
    "            print(f\"  ‚ö†Ô∏è  Stream2 gradients very small - may not be learning!\")\n",
    "    \n",
    "    # Monitor overfitting every N epochs\n",
    "    if epoch % TRAIN_CONFIG['monitor_overfitting_every'] == 0:\n",
    "        print(f\"\\nüîç Overfitting Detection:\")\n",
    "        overfitting_stats = monitor.compute_stream_overfitting_indicators(\n",
    "            train_loss, val_loss, train_acc, val_acc,\n",
    "            train_loader, val_loader\n",
    "        )\n",
    "        \n",
    "        monitoring_history['stream1_overfitting_scores'].append(\n",
    "            overfitting_stats['stream1_overfitting_score']\n",
    "        )\n",
    "        monitoring_history['stream2_overfitting_scores'].append(\n",
    "            overfitting_stats['stream2_overfitting_score']\n",
    "        )\n",
    "        \n",
    "        print(f\"  Stream1 (RGB):\")\n",
    "        print(f\"    Train acc: {overfitting_stats['stream1_train_acc']*100:.2f}% | Val acc: {overfitting_stats['stream1_val_acc']*100:.2f}%\")\n",
    "        print(f\"    Overfitting score: {overfitting_stats['stream1_overfitting_score']:.4f}\")\n",
    "        \n",
    "        print(f\"  Stream2 (Depth):\")\n",
    "        print(f\"    Train acc: {overfitting_stats['stream2_train_acc']*100:.2f}% | Val acc: {overfitting_stats['stream2_val_acc']*100:.2f}%\")\n",
    "        print(f\"    Overfitting score: {overfitting_stats['stream2_overfitting_score']:.4f}\")\n",
    "        \n",
    "        # Determine which stream is overfitting more\n",
    "        if overfitting_stats['stream1_overfitting_score'] > overfitting_stats['stream2_overfitting_score'] * 1.5:\n",
    "            print(f\"  ‚ö†Ô∏è  Stream1 (RGB) is overfitting MORE than Stream2\")\n",
    "        elif overfitting_stats['stream2_overfitting_score'] > overfitting_stats['stream1_overfitting_score'] * 1.5:\n",
    "            print(f\"  ‚ö†Ô∏è  Stream2 (Depth) is overfitting MORE than Stream1\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Streams are relatively balanced\")\n",
    "        \n",
    "        # Get automatic recommendations\n",
    "        if TRAIN_CONFIG['display_recommendations']:\n",
    "            monitor.log_metrics(epoch, {\n",
    "                **first_batch_gradients if first_batch_gradients else {},\n",
    "                **overfitting_stats\n",
    "            })\n",
    "            recommendations = monitor.get_recommendations()\n",
    "            \n",
    "            if recommendations:\n",
    "                print(f\"\\nüí° Recommendations:\")\n",
    "                for rec in recommendations:\n",
    "                    print(f\"  ‚Ä¢ {rec}\")\n",
    "                monitoring_history['recommendations'].append({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'recommendations': recommendations\n",
    "                })\n",
    "    \n",
    "    # Monitor weight norms\n",
    "    weight_stats = monitor.compute_stream_weights()\n",
    "    monitoring_history['stream1_weight_norms'].append(weight_stats['stream1_weight_norm'])\n",
    "    monitoring_history['stream2_weight_norms'].append(weight_stats['stream2_weight_norm'])\n",
    "    \n",
    "    # ===== EARLY STOPPING & CHECKPOINTING =====\n",
    "    if val_acc > best_val_acc + TRAIN_CONFIG['min_delta']:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        print(f\"\\nüíæ New best validation accuracy: {val_acc*100:.2f}% - Saving checkpoint...\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': model.optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'monitoring_history': monitoring_history\n",
    "        }, TRAIN_CONFIG['save_path'])\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= TRAIN_CONFIG['patience']:\n",
    "            print(f\"\\n‚èπÔ∏è  Early stopping triggered at epoch {epoch + 1}\")\n",
    "            print(f\"   Best val accuracy: {best_val_acc*100:.2f}%\")\n",
    "            break\n",
    "    \n",
    "    # Update learning rate scheduler\n",
    "    if hasattr(model, 'scheduler') and model.scheduler is not None:\n",
    "        model.scheduler.step()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best weights\n",
    "print(f\"\\nüì• Loading best model weights...\")\n",
    "checkpoint = torch.load(TRAIN_CONFIG['save_path'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úÖ Best model loaded (Epoch {checkpoint['epoch']}, Val Acc: {checkpoint['val_acc']*100:.2f}%)\")\n",
    "\n",
    "# Save monitoring history\n",
    "import json\n",
    "monitoring_path = f\"{checkpoint_dir}/monitoring_history.json\"\n",
    "with open(monitoring_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'stream1_grad_norms': [float(x) for x in monitoring_history['stream1_grad_norms']],\n",
    "        'stream2_grad_norms': [float(x) for x in monitoring_history['stream2_grad_norms']],\n",
    "        'stream1_overfitting_scores': [float(x) for x in monitoring_history['stream1_overfitting_scores']],\n",
    "        'stream2_overfitting_scores': [float(x) for x in monitoring_history['stream2_overfitting_scores']],\n",
    "        'stream1_weight_norms': [float(x) for x in monitoring_history['stream1_weight_norms']],\n",
    "        'stream2_weight_norms': [float(x) for x in monitoring_history['stream2_weight_norms']],\n",
    "        'recommendations': monitoring_history['recommendations']\n",
    "    }, f, indent=2)\n",
    "print(f\"‚úÖ Monitoring history saved to: {monitoring_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-12"
   },
   "source": [
    "## 12. Pre-Training Diagnostics (Crash Prevention)\n",
    "\n",
    "**IMPORTANT:** Run this cell BEFORE training to diagnose potential kernel crash issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-model"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PRE-TRAINING DIAGNOSTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# FIX 1: Disable tqdm notebook widgets (prevents kernel crash on Colab)\n",
    "print(\"\\n1. Disabling tqdm notebook widgets...\")\n",
    "os.environ['TQDM_DISABLE'] = '0'  # Keep tqdm enabled, but force text mode\n",
    "print(\"   ‚úÖ tqdm will use text mode (not notebook widgets)\")\n",
    "\n",
    "# TEST 2: CUDA initialization\n",
    "print(\"\\n2. Testing CUDA initialization...\")\n",
    "try:\n",
    "    test_cuda = torch.randn(100, 100).cuda()\n",
    "    print(f\"   ‚úÖ CUDA works: {test_cuda.device}\")\n",
    "    print(f\"   ‚úÖ CUDA memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    del test_cuda\n",
    "    torch.cuda.empty_cache()\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå CUDA initialization failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# TEST 3: DataLoader batch loading and label range\n",
    "print(\"\\n3. Testing DataLoader and checking label range...\")\n",
    "try:\n",
    "    rgb, depth, labels = next(iter(train_loader))\n",
    "    print(f\"   ‚úÖ DataLoader works: {rgb.shape}\")\n",
    "    print(f\"   ‚úÖ Labels shape: {labels.shape}\")\n",
    "    print(f\"   ‚úÖ Labels min: {labels.min().item()}, max: {labels.max().item()}\")\n",
    "    \n",
    "    # CRITICAL CHECK: Labels must be in [0, num_classes-1]\n",
    "    if labels.min() < 0 or labels.max() >= 13:\n",
    "        raise ValueError(f\"Labels out of range! Expected [0, 12], got [{labels.min()}, {labels.max()}]\")\n",
    "    print(f\"   ‚úÖ Labels are in valid range [0, 12]\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå DataLoader or label check failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# TEST 4: Model forward pass\n",
    "print(\"\\n4. Testing model forward pass...\")\n",
    "try:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        rgb, depth, labels = next(iter(train_loader))\n",
    "        out = model(rgb.cuda(), depth.cuda())\n",
    "        print(f\"   ‚úÖ Forward pass works: {out.shape}\")\n",
    "        del rgb, depth, labels, out\n",
    "        torch.cuda.empty_cache()\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Forward pass failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# TEST 5: Backward pass and optimizer (CRITICAL - this was failing before)\n",
    "print(\"\\n5. Testing backward pass and optimizer...\")\n",
    "try:\n",
    "    model.train()\n",
    "    rgb, depth, labels = next(iter(train_loader))\n",
    "    rgb, depth, labels = rgb.cuda(), depth.cuda(), labels.cuda()\n",
    "    \n",
    "    # Forward\n",
    "    outputs = model(rgb, depth)\n",
    "    loss = model.criterion(outputs, labels)\n",
    "    \n",
    "    # Backward (this will fail if labels are out of range)\n",
    "    model.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Optimizer step\n",
    "    model.optimizer.step()\n",
    "    \n",
    "    print(f\"   ‚úÖ Backward pass works: loss={loss.item():.4f}\")\n",
    "    print(f\"   ‚úÖ Optimizer step works\")\n",
    "    \n",
    "    del rgb, depth, labels, outputs, loss\n",
    "    torch.cuda.empty_cache()\n",
    "except RuntimeError as e:\n",
    "    if \"device-side assert triggered\" in str(e):\n",
    "        print(f\"   ‚ùå CUDA assertion failed - likely label indexing issue!\")\n",
    "        print(f\"   ‚ùå This means labels are out of valid range [0, num_classes-1]\")\n",
    "        print(f\"   ‚ùå Make sure you've pulled the latest code with the label fix!\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Backward/optimizer failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# TEST 6: tqdm progress bar\n",
    "print(\"\\n6. Testing tqdm progress bar...\")\n",
    "try:\n",
    "    for i in tqdm(range(10), desc=\"Test\"):\n",
    "        pass\n",
    "    print(f\"   ‚úÖ tqdm works\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå tqdm failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# TEST 7: DataLoader iteration\n",
    "print(\"\\n7. Testing DataLoader multi-batch iteration...\")\n",
    "try:\n",
    "    batch_count = 0\n",
    "    for rgb, depth, labels in train_loader:\n",
    "        batch_count += 1\n",
    "        if batch_count >= 3:  # Test first 3 batches\n",
    "            break\n",
    "    print(f\"   ‚úÖ DataLoader iteration works ({batch_count} batches tested)\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå DataLoader iteration failed: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ALL DIAGNOSTICS PASSED - Ready to train!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nIf training still crashes after this, try:\")\n",
    "print(\"  1. Run with verbose=False in model.fit()\")\n",
    "print(\"  2. Restart runtime and rerun all cells\")\n",
    "print(\"  3. Check the crash log for new error messages\")\n",
    "print(\"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training configuration\n",
    "TRAIN_CONFIG = {\n",
    "    'epochs': 90,  # Standard for ImageNet-style training\n",
    "    'grad_clip_norm': 5.0,  # Gradient clipping for stability\n",
    "    'early_stopping': True,\n",
    "    'patience': 15,\n",
    "    'min_delta': 0.001,\n",
    "    'monitor': 'val_accuracy',\n",
    "    'restore_best_weights': True,\n",
    "    'save_path': f\"{checkpoint_dir}/best_model.pt\"\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "for key, value in TRAIN_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Training will take approximately 2-3 hours on A100\")\n",
    "print(f\"Progress will be shown below...\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Train!\n",
    "history = model.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=TRAIN_CONFIG['epochs'],\n",
    "    verbose=True,\n",
    "    save_path=TRAIN_CONFIG['save_path'],\n",
    "    early_stopping=TRAIN_CONFIG['early_stopping'],\n",
    "    patience=TRAIN_CONFIG['patience'],\n",
    "    min_delta=TRAIN_CONFIG['min_delta'],\n",
    "    monitor=TRAIN_CONFIG['monitor'],\n",
    "    restore_best_weights=TRAIN_CONFIG['restore_best_weights'],\n",
    "    grad_clip_norm=TRAIN_CONFIG['grad_clip_norm']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Train the Model üöÄ\n",
    "\n",
    "**Expected time:** ~2-3 hours for 90 epochs on A100\n",
    "\n",
    "**All optimizations enabled:**\n",
    "- ‚úÖ Automatic Mixed Precision (2x faster)\n",
    "- ‚úÖ Gradient Clipping (stability)\n",
    "- ‚úÖ Cosine Annealing LR\n",
    "- ‚úÖ Early Stopping\n",
    "- ‚úÖ Best Model Checkpointing\n",
    "- ‚úÖ Local disk I/O (10-20x faster than Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MONITORING INTERPRETATION GUIDE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze monitoring results and provide actionable recommendations\n",
    "print(\"\\nüìä Analysis of Stream Behavior:\\n\")\n",
    "\n",
    "# 1. Gradient Analysis\n",
    "if len(monitoring_history['stream1_grad_norms']) > 0:\n",
    "    s1_grads = monitoring_history['stream1_grad_norms']\n",
    "    s2_grads = monitoring_history['stream2_grad_norms']\n",
    "    \n",
    "    avg_s1_grad = np.mean(s1_grads)\n",
    "    avg_s2_grad = np.mean(s2_grads)\n",
    "    grad_ratio = avg_s1_grad / max(avg_s2_grad, 1e-10)\n",
    "    \n",
    "    print(\"1Ô∏è‚É£ GRADIENT FLOW:\")\n",
    "    print(f\"   RGB avg gradient: {avg_s1_grad:.6f}\")\n",
    "    print(f\"   Depth avg gradient: {avg_s2_grad:.6f}\")\n",
    "    print(f\"   RGB/Depth ratio: {grad_ratio:.2f}\")\n",
    "    \n",
    "    if grad_ratio < 0.3:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  RGB gradients much smaller - RGB stream learning slowly\")\n",
    "        print(f\"   üí° ACTION: Increase stream1_lr (try 5x base LR)\")\n",
    "    elif grad_ratio > 3.0:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Depth gradients much smaller - Depth stream learning slowly\")\n",
    "        print(f\"   üí° ACTION: Increase stream2_lr (try 5x base LR)\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚úÖ Gradients relatively balanced - good!\")\n",
    "\n",
    "# 2. Overfitting Analysis\n",
    "if len(monitoring_history['stream1_overfitting_scores']) > 0:\n",
    "    s1_overfit = monitoring_history['stream1_overfitting_scores'][-1]\n",
    "    s2_overfit = monitoring_history['stream2_overfitting_scores'][-1]\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ OVERFITTING DETECTION:\")\n",
    "    print(f\"   RGB overfitting score: {s1_overfit:.3f}\")\n",
    "    print(f\"   Depth overfitting score: {s2_overfit:.3f}\")\n",
    "    \n",
    "    if s1_overfit > s2_overfit * 1.5:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  RGB stream overfitting MORE than Depth\")\n",
    "        print(f\"   üí° ACTIONS:\")\n",
    "        print(f\"      ‚Ä¢ Increase stream1_weight_decay (try 5e-2)\")\n",
    "        print(f\"      ‚Ä¢ Or decrease stream1_lr (try 0.5x base LR)\")\n",
    "        print(f\"      ‚Ä¢ Or increase dropout_p in model config\")\n",
    "    elif s2_overfit > s1_overfit * 1.5:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Depth stream overfitting MORE than RGB\")\n",
    "        print(f\"   üí° ACTIONS:\")\n",
    "        print(f\"      ‚Ä¢ Increase stream2_weight_decay (try 5e-2)\")\n",
    "        print(f\"      ‚Ä¢ Or decrease stream2_lr (try 0.5x base LR)\")\n",
    "        print(f\"      ‚Ä¢ Or increase dropout_p in model config\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚úÖ Overfitting relatively balanced\")\n",
    "\n",
    "# 3. Weight Magnitude Analysis\n",
    "if len(monitoring_history['stream1_weight_norms']) > 0:\n",
    "    s1_weights = monitoring_history['stream1_weight_norms']\n",
    "    s2_weights = monitoring_history['stream2_weight_norms']\n",
    "    \n",
    "    final_s1_weight = s1_weights[-1]\n",
    "    final_s2_weight = s2_weights[-1]\n",
    "    weight_ratio = final_s1_weight / max(final_s2_weight, 1e-10)\n",
    "    \n",
    "    print(f\"\\n3Ô∏è‚É£ WEIGHT MAGNITUDES:\")\n",
    "    print(f\"   RGB final weight norm: {final_s1_weight:.4f}\")\n",
    "    print(f\"   Depth final weight norm: {final_s2_weight:.4f}\")\n",
    "    print(f\"   RGB/Depth ratio: {weight_ratio:.2f}\")\n",
    "    \n",
    "    if weight_ratio < 0.5:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  RGB weights much smaller - may indicate underfitting\")\n",
    "        print(f\"   üí° This often correlates with low gradients\")\n",
    "    elif weight_ratio > 2.0:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Depth weights much smaller - may indicate underfitting\")\n",
    "        print(f\"   üí° This often correlates with low gradients\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚úÖ Weight magnitudes relatively balanced\")\n",
    "\n",
    "# 4. Generate specific config recommendations\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üí° RECOMMENDED NEXT STEPS:\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "needs_adjustment = False\n",
    "\n",
    "if len(monitoring_history['stream1_overfitting_scores']) > 0:\n",
    "    s1_overfit = monitoring_history['stream1_overfitting_scores'][-1]\n",
    "    s2_overfit = monitoring_history['stream2_overfitting_scores'][-1]\n",
    "    \n",
    "    if s1_overfit > s2_overfit * 1.5 or s2_overfit > s1_overfit * 1.5:\n",
    "        needs_adjustment = True\n",
    "        print(\"üîß RERUN WITH STREAM-SPECIFIC OPTIMIZATION:\\n\")\n",
    "        print(\"Go back to cell 'MODEL COMPILATION' and:\")\n",
    "        print(\"  1. Set USE_STREAM_SPECIFIC = True\")\n",
    "        print(\"  2. Uncomment and adjust these lines in STREAM_SPECIFIC_CONFIG:\\n\")\n",
    "        \n",
    "        if s1_overfit > s2_overfit * 1.5:\n",
    "            print(\"     # RGB is overfitting - regularize it more:\")\n",
    "            print(\"     'stream1_lr': 5e-5,           # Lower LR for RGB\")\n",
    "            print(\"     'stream1_weight_decay': 5e-2, # Higher WD for RGB\")\n",
    "            print(\"     'stream2_lr': 2e-4,           # Keep Depth learning\")\n",
    "            print(\"     'stream2_weight_decay': 1e-3, # Lighter WD for Depth\")\n",
    "        else:\n",
    "            print(\"     # Depth is overfitting - regularize it more:\")\n",
    "            print(\"     'stream1_lr': 2e-4,           # Keep RGB learning\")\n",
    "            print(\"     'stream1_weight_decay': 1e-3, # Lighter WD for RGB\")\n",
    "            print(\"     'stream2_lr': 5e-5,           # Lower LR for Depth\")\n",
    "            print(\"     'stream2_weight_decay': 5e-2, # Higher WD for Depth\")\n",
    "        \n",
    "        print(\"\\n  3. Rerun training from that cell onwards\")\n",
    "\n",
    "if len(monitoring_history['stream1_grad_norms']) > 0:\n",
    "    grad_ratio = np.mean(s1_grads) / max(np.mean(s2_grads), 1e-10)\n",
    "    \n",
    "    if grad_ratio < 0.3 or grad_ratio > 3.0:\n",
    "        if not needs_adjustment:\n",
    "            needs_adjustment = True\n",
    "            print(\"üîß RERUN WITH STREAM-SPECIFIC OPTIMIZATION:\\n\")\n",
    "            print(\"Go back to cell 'MODEL COMPILATION' and:\")\n",
    "            print(\"  1. Set USE_STREAM_SPECIFIC = True\")\n",
    "            print(\"  2. Uncomment and adjust these lines in STREAM_SPECIFIC_CONFIG:\\n\")\n",
    "        \n",
    "        if grad_ratio < 0.3:\n",
    "            print(\"     # RGB gradients too small - boost RGB learning:\")\n",
    "            print(\"     'stream1_lr': 5e-4,           # 5x higher LR for RGB\")\n",
    "            print(\"     'stream1_weight_decay': 1e-3, # Lighter WD for RGB\")\n",
    "        else:\n",
    "            print(\"     # Depth gradients too small - boost Depth learning:\")\n",
    "            print(\"     'stream2_lr': 5e-4,           # 5x higher LR for Depth\")\n",
    "            print(\"     'stream2_weight_decay': 1e-3, # Lighter WD for Depth\")\n",
    "\n",
    "if not needs_adjustment:\n",
    "    print(\"‚úÖ Training appears balanced - no major adjustments needed!\\n\")\n",
    "    print(\"If validation accuracy is still low, consider:\")\n",
    "    print(\"  ‚Ä¢ Training for more epochs\")\n",
    "    print(\"  ‚Ä¢ Using ResNet50 instead of ResNet18 (more capacity)\")\n",
    "    print(\"  ‚Ä¢ Adjusting fusion_type (try 'weighted' or 'gated')\")\n",
    "    print(\"  ‚Ä¢ Increasing dropout_p for more regularization\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14b. Monitoring Interpretation & Decision Guide üí°\n",
    "\n",
    "**How to use monitoring results to improve your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STREAM MONITORING VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comprehensive monitoring plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. Gradient Norms Over Time\n",
    "if len(monitoring_history['stream1_grad_norms']) > 0:\n",
    "    epochs = range(1, len(monitoring_history['stream1_grad_norms']) + 1)\n",
    "    axes[0, 0].plot(epochs, monitoring_history['stream1_grad_norms'], \n",
    "                    label='Stream1 (RGB)', linewidth=2, color='blue', marker='o', markersize=3)\n",
    "    axes[0, 0].plot(epochs, monitoring_history['stream2_grad_norms'], \n",
    "                    label='Stream2 (Depth)', linewidth=2, color='orange', marker='s', markersize=3)\n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('Gradient Norm', fontsize=11)\n",
    "    axes[0, 0].set_title('Stream Gradient Magnitudes', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].legend(fontsize=10)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_yscale('log')\n",
    "\n",
    "# 2. Gradient Ratio Over Time\n",
    "if len(monitoring_history['stream1_grad_norms']) > 0:\n",
    "    grad_ratios = [s1/max(s2, 1e-10) for s1, s2 in zip(\n",
    "        monitoring_history['stream1_grad_norms'], \n",
    "        monitoring_history['stream2_grad_norms']\n",
    "    )]\n",
    "    axes[0, 1].plot(epochs, grad_ratios, linewidth=2, color='green', marker='d', markersize=3)\n",
    "    axes[0, 1].axhline(y=1.0, color='red', linestyle='--', linewidth=1.5, label='Perfect Balance')\n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('Gradient Ratio (RGB/Depth)', fontsize=11)\n",
    "    axes[0, 1].set_title('Gradient Balance Between Streams', fontsize=13, fontweight='bold')\n",
    "    axes[0, 1].legend(fontsize=10)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_yscale('log')\n",
    "\n",
    "# 3. Overfitting Scores Comparison\n",
    "if len(monitoring_history['stream1_overfitting_scores']) > 0:\n",
    "    overfit_epochs = range(1, len(monitoring_history['stream1_overfitting_scores']) + 1)\n",
    "    axes[0, 2].plot(overfit_epochs, monitoring_history['stream1_overfitting_scores'], \n",
    "                    label='Stream1 (RGB)', linewidth=2.5, color='blue', marker='o', markersize=4)\n",
    "    axes[0, 2].plot(overfit_epochs, monitoring_history['stream2_overfitting_scores'], \n",
    "                    label='Stream2 (Depth)', linewidth=2.5, color='orange', marker='s', markersize=4)\n",
    "    axes[0, 2].axhline(y=0, color='gray', linestyle='-', linewidth=1, alpha=0.5)\n",
    "    axes[0, 2].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[0, 2].set_ylabel('Overfitting Score', fontsize=11)\n",
    "    axes[0, 2].set_title('Stream-Specific Overfitting Detection', fontsize=13, fontweight='bold')\n",
    "    axes[0, 2].legend(fontsize=10)\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Annotate which stream is overfitting more\n",
    "    final_s1 = monitoring_history['stream1_overfitting_scores'][-1]\n",
    "    final_s2 = monitoring_history['stream2_overfitting_scores'][-1]\n",
    "    if final_s1 > final_s2 * 1.5:\n",
    "        axes[0, 2].text(0.5, 0.95, '‚ö†Ô∏è RGB overfitting more', \n",
    "                       transform=axes[0, 2].transAxes, ha='center', va='top',\n",
    "                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7), fontsize=10)\n",
    "    elif final_s2 > final_s1 * 1.5:\n",
    "        axes[0, 2].text(0.5, 0.95, '‚ö†Ô∏è Depth overfitting more', \n",
    "                       transform=axes[0, 2].transAxes, ha='center', va='top',\n",
    "                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7), fontsize=10)\n",
    "\n",
    "# 4. Weight Norms Over Time\n",
    "if len(monitoring_history['stream1_weight_norms']) > 0:\n",
    "    weight_epochs = range(1, len(monitoring_history['stream1_weight_norms']) + 1)\n",
    "    axes[1, 0].plot(weight_epochs, monitoring_history['stream1_weight_norms'], \n",
    "                    label='Stream1 (RGB)', linewidth=2, color='blue', marker='o', markersize=3)\n",
    "    axes[1, 0].plot(weight_epochs, monitoring_history['stream2_weight_norms'], \n",
    "                    label='Stream2 (Depth)', linewidth=2, color='orange', marker='s', markersize=3)\n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('Weight Norm', fontsize=11)\n",
    "    axes[1, 0].set_title('Stream Weight Magnitudes', fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].legend(fontsize=10)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Weight Ratio Over Time\n",
    "if len(monitoring_history['stream1_weight_norms']) > 0:\n",
    "    weight_ratios = [s1/max(s2, 1e-10) for s1, s2 in zip(\n",
    "        monitoring_history['stream1_weight_norms'], \n",
    "        monitoring_history['stream2_weight_norms']\n",
    "    )]\n",
    "    axes[1, 1].plot(weight_epochs, weight_ratios, linewidth=2, color='purple', marker='d', markersize=3)\n",
    "    axes[1, 1].axhline(y=1.0, color='red', linestyle='--', linewidth=1.5, label='Perfect Balance')\n",
    "    axes[1, 1].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Weight Ratio (RGB/Depth)', fontsize=11)\n",
    "    axes[1, 1].set_title('Weight Balance Between Streams', fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].legend(fontsize=10)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Summary Statistics (Text)\n",
    "axes[1, 2].axis('off')\n",
    "summary_text = \"üìä MONITORING SUMMARY\\\\n\\\\n\"\n",
    "\n",
    "if len(monitoring_history['stream1_grad_norms']) > 0:\n",
    "    avg_grad_ratio = np.mean([s1/max(s2, 1e-10) for s1, s2 in zip(\n",
    "        monitoring_history['stream1_grad_norms'], \n",
    "        monitoring_history['stream2_grad_norms']\n",
    "    )])\n",
    "    summary_text += f\"Gradient Balance:\\\\n\"\n",
    "    summary_text += f\"  RGB/Depth ratio: {avg_grad_ratio:.2f}\\\\n\"\n",
    "    summary_text += f\"  {'‚úÖ Balanced' if 0.5 <= avg_grad_ratio <= 2.0 else '‚ö†Ô∏è Imbalanced'}\\\\n\\\\n\"\n",
    "\n",
    "if len(monitoring_history['stream1_overfitting_scores']) > 0:\n",
    "    final_s1_overfit = monitoring_history['stream1_overfitting_scores'][-1]\n",
    "    final_s2_overfit = monitoring_history['stream2_overfitting_scores'][-1]\n",
    "    summary_text += f\"Final Overfitting:\\\\n\"\n",
    "    summary_text += f\"  RGB score: {final_s1_overfit:.3f}\\\\n\"\n",
    "    summary_text += f\"  Depth score: {final_s2_overfit:.3f}\\\\n\"\n",
    "    if final_s1_overfit > final_s2_overfit * 1.5:\n",
    "        summary_text += f\"  ‚ö†Ô∏è RGB overfitting more\\\\n\\\\n\"\n",
    "    elif final_s2_overfit > final_s1_overfit * 1.5:\n",
    "        summary_text += f\"  ‚ö†Ô∏è Depth overfitting more\\\\n\\\\n\"\n",
    "    else:\n",
    "        summary_text += f\"  ‚úÖ Relatively balanced\\\\n\\\\n\"\n",
    "\n",
    "if len(monitoring_history['recommendations']) > 0:\n",
    "    summary_text += f\"Recommendations Given:\\\\n\"\n",
    "    summary_text += f\"  {len(monitoring_history['recommendations'])} times\\\\n\\\\n\"\n",
    "    \n",
    "    # Show most recent recommendations\n",
    "    if monitoring_history['recommendations']:\n",
    "        recent = monitoring_history['recommendations'][-1]\n",
    "        summary_text += f\"Latest (Epoch {recent['epoch']}):\\\\n\"\n",
    "        for rec in recent['recommendations'][:3]:  # Show first 3\n",
    "            summary_text += f\"  ‚Ä¢ {rec[:40]}...\\\\n\"\n",
    "\n",
    "axes[1, 2].text(0.1, 0.9, summary_text, transform=axes[1, 2].transAxes, \n",
    "               fontsize=10, verticalalignment='top', family='monospace',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.3))\n",
    "\n",
    "plt.suptitle('Stream Monitoring Analysis - MCResNet Training', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{checkpoint_dir}/stream_monitoring_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Stream monitoring visualization saved to:\")\n",
    "print(f\"   {checkpoint_dir}/stream_monitoring_analysis.png\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14a. Visualize Stream Monitoring Results üîç\n",
    "\n",
    "**Comprehensive analysis of stream-specific behavior during training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-13"
   },
   "source": [
    "## 13. Evaluate Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-model"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluate on validation set\n",
    "results = model.evaluate(data_loader=val_loader)\n",
    "\n",
    "print(f\"\\nFinal Validation Results:\")\n",
    "print(f\"  Loss: {results['loss']:.4f}\")\n",
    "print(f\"  Accuracy: {results['accuracy']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Initial train loss: {history['train_loss'][0]:.4f}\")\n",
    "print(f\"  Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Best val loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"  Initial train acc: {history['train_accuracy'][0]*100:.2f}%\")\n",
    "print(f\"  Final train acc: {history['train_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  Best val acc: {max(history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"  Total epochs: {len(history['train_loss'])}\")\n",
    "\n",
    "if 'early_stopping' in history:\n",
    "    print(f\"\\nEarly Stopping Info:\")\n",
    "    print(f\"  Stopped early: {history['early_stopping']['stopped_early']}\")\n",
    "    print(f\"  Best epoch: {history['early_stopping']['best_epoch']}\")\n",
    "    print(f\"  Best {history['early_stopping']['monitor']}: {history['early_stopping']['best_metric']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-14"
   },
   "source": [
    "## 14. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-curves"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot([acc*100 for acc in history['train_accuracy']], label='Train Acc', linewidth=2)\n",
    "axes[1].plot([acc*100 for acc in history['val_accuracy']], label='Val Acc', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate curve\n",
    "if len(history['learning_rates']) > 0:\n",
    "    # Sample learning rates (they're recorded per step, not per epoch)\n",
    "    sampled_lrs = history['learning_rates'][::max(1, len(history['learning_rates'])//100)]\n",
    "    axes[2].plot(sampled_lrs, linewidth=2, color='green')\n",
    "    axes[2].set_xlabel('Training Step (sampled)', fontsize=12)\n",
    "    axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{checkpoint_dir}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Training curves saved to: {checkpoint_dir}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-15"
   },
   "source": [
    "## 15. Pathway Analysis (RGB vs Depth Contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pathway-analysis"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PATHWAY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nAnalyzing RGB and Depth pathway contributions...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Analyze pathways\n",
    "pathway_analysis = model.analyze_pathways(\n",
    "    data_loader=val_loader,\n",
    "    num_samples=len(val_loader.dataset)  # Use all validation samples\n",
    ")\n",
    "\n",
    "print(\"\\nAccuracy Metrics:\")\n",
    "print(f\"  Full model (RGB+Depth): {pathway_analysis['accuracy']['full_model']*100:.2f}%\")\n",
    "print(f\"  RGB only: {pathway_analysis['accuracy']['color_only']*100:.2f}%\")\n",
    "print(f\"  Depth only: {pathway_analysis['accuracy']['brightness_only']*100:.2f}%\")\n",
    "print(f\"\\n  RGB contribution: {pathway_analysis['accuracy']['color_contribution']*100:.2f}%\")\n",
    "print(f\"  Depth contribution: {pathway_analysis['accuracy']['brightness_contribution']*100:.2f}%\")\n",
    "\n",
    "print(\"\\nLoss Metrics:\")\n",
    "print(f\"  Full model: {pathway_analysis['loss']['full_model']:.4f}\")\n",
    "print(f\"  RGB only: {pathway_analysis['loss']['color_only']:.4f}\")\n",
    "print(f\"  Depth only: {pathway_analysis['loss']['brightness_only']:.4f}\")\n",
    "\n",
    "print(\"\\nFeature Norm Statistics:\")\n",
    "print(f\"  RGB mean: {pathway_analysis['feature_norms']['color_mean']:.4f}\")\n",
    "print(f\"  RGB std: {pathway_analysis['feature_norms']['color_std']:.4f}\")\n",
    "print(f\"  Depth mean: {pathway_analysis['feature_norms']['brightness_mean']:.4f}\")\n",
    "print(f\"  Depth std: {pathway_analysis['feature_norms']['brightness_std']:.4f}\")\n",
    "print(f\"  RGB/Depth ratio: {pathway_analysis['feature_norms']['color_to_brightness_ratio']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Pathway analysis complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualize pathway contributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "pathways = ['Full Model\\n(RGB+Depth)', 'RGB Only', 'Depth Only']\n",
    "accuracies = [\n",
    "    pathway_analysis['accuracy']['full_model'] * 100,\n",
    "    pathway_analysis['accuracy']['color_only'] * 100,\n",
    "    pathway_analysis['accuracy']['brightness_only'] * 100\n",
    "]\n",
    "colors = ['green', 'blue', 'orange']\n",
    "\n",
    "axes[0].bar(pathways, accuracies, color=colors, alpha=0.7)\n",
    "axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[0].set_title('Pathway Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(accuracies):\n",
    "    axes[0].text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Feature norm comparison\n",
    "norms = ['RGB Features', 'Depth Features']\n",
    "norm_values = [\n",
    "    pathway_analysis['feature_norms']['color_mean'],\n",
    "    pathway_analysis['feature_norms']['brightness_mean']\n",
    "]\n",
    "axes[1].bar(norms, norm_values, color=['blue', 'orange'], alpha=0.7)\n",
    "axes[1].set_ylabel('Feature Norm (Mean)', fontsize=12)\n",
    "axes[1].set_title('Feature Magnitude Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(norm_values):\n",
    "    axes[1].text(i, v + 0.1, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{checkpoint_dir}/pathway_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Pathway analysis plot saved to: {checkpoint_dir}/pathway_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-16"
   },
   "source": [
    "## 16. Save Results & Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-results"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save training history as JSON\n",
    "history_path = f\"{checkpoint_dir}/training_history.json\"\n",
    "with open(history_path, 'w') as f:\n",
    "    json_history = {\n",
    "        'train_loss': [float(x) for x in history['train_loss']],\n",
    "        'val_loss': [float(x) for x in history['val_loss']],\n",
    "        'train_accuracy': [float(x) for x in history['train_accuracy']],\n",
    "        'val_accuracy': [float(x) for x in history['val_accuracy']],\n",
    "        'learning_rates': [float(x) for x in history['learning_rates']],\n",
    "        'model_config': MODEL_CONFIG,\n",
    "        'dataset_config': DATASET_CONFIG,\n",
    "        'training_config': TRAINING_CONFIG,\n",
    "        'final_results': {\n",
    "            'val_loss': float(results['loss']),\n",
    "            'val_accuracy': float(results['accuracy'])\n",
    "        },\n",
    "        'pathway_analysis': {\n",
    "            'full_model_accuracy': float(pathway_analysis['accuracy']['full_model']),\n",
    "            'rgb_only_accuracy': float(pathway_analysis['accuracy']['color_only']),\n",
    "            'depth_only_accuracy': float(pathway_analysis['accuracy']['brightness_only'])\n",
    "        }\n",
    "    }\n",
    "    if 'early_stopping' in history:\n",
    "        json_history['early_stopping'] = history['early_stopping']\n",
    "    \n",
    "    json.dump(json_history, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Training history saved: {history_path}\")\n",
    "\n",
    "# Save final model (in addition to best model)\n",
    "final_model_path = f\"{checkpoint_dir}/final_model.pt\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': model.optimizer.state_dict(),\n",
    "    'config': MODEL_CONFIG,\n",
    "    'history': history,\n",
    "    'val_accuracy': results['accuracy']\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"‚úÖ Final model saved: {final_model_path}\")\n",
    "\n",
    "# Save summary report\n",
    "summary_path = f\"{checkpoint_dir}/summary.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(\"MCResNet Training Summary - NYU Depth V2\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Model: MCResNet-{MODEL_CONFIG['architecture'].upper()}\\n\")\n",
    "    f.write(f\"Dataset: NYU Depth V2 (Scene Classification)\\n\")\n",
    "    f.write(f\"Training Samples: {len(train_loader.dataset)}\\n\")\n",
    "    f.write(f\"Validation Samples: {len(val_loader.dataset)}\\n\")\n",
    "    f.write(f\"Total Parameters: {total_params:,}\\n\")\n",
    "    f.write(f\"\\nTraining Configuration:\\n\")\n",
    "    f.write(f\"  Epochs: {len(history['train_loss'])}\\n\")\n",
    "    f.write(f\"  Batch Size: {DATASET_CONFIG['batch_size']}\\n\")\n",
    "    f.write(f\"  Learning Rate: {TRAINING_CONFIG['learning_rate']}\\n\")\n",
    "    f.write(f\"  Optimizer: {TRAINING_CONFIG['optimizer']}\\n\")\n",
    "    f.write(f\"  Scheduler: {TRAINING_CONFIG['scheduler']}\\n\")\n",
    "    f.write(f\"  AMP: {MODEL_CONFIG['use_amp']}\\n\")\n",
    "    f.write(f\"  Gradient Clipping: {TRAIN_CONFIG['grad_clip_norm']}\\n\")\n",
    "    f.write(f\"\\nFinal Results:\\n\")\n",
    "    f.write(f\"  Val Loss: {results['loss']:.4f}\\n\")\n",
    "    f.write(f\"  Val Accuracy: {results['accuracy']*100:.2f}%\\n\")\n",
    "    f.write(f\"  Best Val Accuracy: {max(history['val_accuracy'])*100:.2f}%\\n\")\n",
    "    f.write(f\"\\nPathway Analysis:\\n\")\n",
    "    f.write(f\"  Full Model: {pathway_analysis['accuracy']['full_model']*100:.2f}%\\n\")\n",
    "    f.write(f\"  RGB Only: {pathway_analysis['accuracy']['color_only']*100:.2f}%\\n\")\n",
    "    f.write(f\"  Depth Only: {pathway_analysis['accuracy']['brightness_only']*100:.2f}%\\n\")\n",
    "\n",
    "print(f\"‚úÖ Summary report saved: {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"All results saved to: {checkpoint_dir}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# List saved files\n",
    "print(\"\\nSaved files:\")\n",
    "!ls -lh {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-17"
   },
   "source": "## 17. Summary & Next Steps\n\n### üéâ Training Complete!\n\n**What we accomplished:**\n- ‚úÖ Trained MCResNet on NYU Depth V2 dataset\n- ‚úÖ Used A100 GPU with AMP (2x speedup)\n- ‚úÖ Saved all checkpoints to Google Drive\n- ‚úÖ Analyzed RGB and Depth pathway contributions\n- ‚úÖ Generated training curves and visualizations\n- ‚úÖ Comprehensive stream monitoring with overfitting detection\n\n**Results are saved to:** Check the output above for the checkpoint directory path\n\n### üìä Expected Performance:\n\nFor **NYU Depth V2 Scene Classification (27 classes)**:\n- **Good:** 60-70% validation accuracy\n- **Very Good:** 70-75% validation accuracy  \n- **Excellent:** 75-80% validation accuracy\n\n### üîç Next Steps:\n\n1. **Review Results:**\n   - Check training curves above\n   - Review pathway analysis\n   - Compare RGB vs Depth contributions\n   - Analyze stream monitoring plots\n\n2. **Download Results:**\n   - All files are saved to your Google Drive\n   - Download checkpoints for local inference\n\n3. **Experiment:**\n   - Try ResNet50 for better accuracy (change `architecture` in Model Config)\n   - Use stream-specific optimization if monitoring shows imbalance\n   - Adjust fusion_type (try 'weighted' or 'gated')\n   - Train longer if early stopping triggered\n\n4. **Deploy:**\n   - Use the best model for inference\n   - Test on new RGB-D images\n   - Integrate into your application\n\n---\n\n**Questions or issues?** Check the training summary and pathway analysis above!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final-summary"
   },
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚úÖ Training Complete!\")\n",
    "print(f\"\\nFinal Validation Accuracy: {results['accuracy']*100:.2f}%\")\n",
    "print(f\"Best Validation Accuracy: {max(history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"\\nRGB Pathway: {pathway_analysis['accuracy']['color_only']*100:.2f}%\")\n",
    "print(f\"Depth Pathway: {pathway_analysis['accuracy']['brightness_only']*100:.2f}%\")\n",
    "print(f\"Combined (RGB+Depth): {pathway_analysis['accuracy']['full_model']*100:.2f}%\")\n",
    "print(f\"\\nTotal Training Epochs: {len(history['train_loss'])}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"\\nCheckpoints saved to: {checkpoint_dir}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ All done! Check Google Drive for saved models and results.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}