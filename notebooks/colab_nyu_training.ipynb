{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# MCResNet Training on NYU Depth V2 - Google Colab\n",
    "\n",
    "**Complete end-to-end training pipeline for Google Colab with A100 GPU**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Checklist Before Running:\n",
    "\n",
    "- [ ] **Enable A100 GPU:** Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU ‚Üí GPU type: A100\n",
    "- [ ] **Mount Google Drive:** Your code and dataset will be stored on Drive\n",
    "- [ ] **Upload dataset to Drive:** `MyDrive/datasets/nyu_depth_v2_labeled.mat` (or we'll download it)\n",
    "- [ ] **Expected Runtime:** ~2-3 hours for 90 epochs\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What This Notebook Does:\n",
    "\n",
    "1. ‚úÖ Verify A100 GPU is available\n",
    "2. ‚úÖ Mount Google Drive\n",
    "3. ‚úÖ Clone your repository to local disk (fast I/O)\n",
    "4. ‚úÖ Download/copy NYU Depth V2 to local disk (10-20x faster than Drive)\n",
    "5. ‚úÖ Install dependencies\n",
    "6. ‚úÖ Train MCResNet with all optimizations\n",
    "7. ‚úÖ Save checkpoints to Drive (persistent storage)\n",
    "8. ‚úÖ Generate training curves and analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Let's get started!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-1"
   },
   "source": [
    "## 1. Environment Setup & GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability and specs\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Check if it's A100\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    if 'A100' in gpu_name:\n",
    "        print(\"\\n‚úÖ A100 GPU detected - PERFECT for training!\")\n",
    "    elif 'V100' in gpu_name:\n",
    "        print(\"\\n‚úÖ V100 GPU detected - Good for training (slower than A100)\")\n",
    "    elif 'T4' in gpu_name:\n",
    "        print(\"\\n‚ö†Ô∏è  T4 GPU detected - Will be slower, consider upgrading to A100\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  GPU: {gpu_name} - Consider using A100 for best performance\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NO GPU DETECTED!\")\n",
    "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU\")\n",
    "    raise RuntimeError(\"GPU is required for training\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvidia-smi"
   },
   "outputs": [],
   "source": [
    "# Detailed GPU info\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-2"
   },
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n‚úÖ Google Drive mounted successfully!\")\n",
    "print(f\"\\nDrive contents:\")\n",
    "!ls -la /content/drive/MyDrive/ | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-3"
   },
   "source": [
    "## 3. Clone Repository to Local Disk (Fast I/O)\n",
    "\n",
    "**Important:** We clone to `/content/` (local SSD) instead of Drive for 10-20x faster I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "PROJECT_NAME = \"Multi-Stream-Neural-Networks\"\n",
    "DRIVE_REPO_PATH = f\"/content/drive/MyDrive/{PROJECT_NAME}\"  # Your repo on Drive\n",
    "LOCAL_REPO_PATH = f\"/content/{PROJECT_NAME}\"  # Local copy for fast I/O\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REPOSITORY SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 1: Copy from Drive (if repo is on Drive)\n",
    "if Path(DRIVE_REPO_PATH).exists():\n",
    "    print(f\"üìÅ Found repo on Drive: {DRIVE_REPO_PATH}\")\n",
    "    print(f\"üì• Copying to local disk for fast I/O...\")\n",
    "    \n",
    "    # Remove old local copy if exists\n",
    "    if Path(LOCAL_REPO_PATH).exists():\n",
    "        !rm -rf {LOCAL_REPO_PATH}\n",
    "    \n",
    "    # Copy from Drive to local disk\n",
    "    !cp -r {DRIVE_REPO_PATH} {LOCAL_REPO_PATH}\n",
    "    print(\"‚úÖ Repo copied to local disk\")\n",
    "\n",
    "# Option 2: Clone from GitHub (if you prefer fresh clone)\n",
    "else:\n",
    "    print(\"üìÅ Repo not found on Drive\")\n",
    "    print(\"üîÑ Cloning from GitHub instead...\")\n",
    "    \n",
    "    # UPDATE THIS with your GitHub repo URL\n",
    "    GITHUB_REPO = \"https://github.com/YOUR_USERNAME/Multi-Stream-Neural-Networks.git\"\n",
    "    \n",
    "    # Remove old local copy if exists\n",
    "    if Path(LOCAL_REPO_PATH).exists():\n",
    "        !rm -rf {LOCAL_REPO_PATH}\n",
    "    \n",
    "    # Clone from GitHub\n",
    "    !git clone {GITHUB_REPO} {LOCAL_REPO_PATH}\n",
    "    print(\"‚úÖ Repo cloned from GitHub\")\n",
    "\n",
    "# Verify repo structure\n",
    "print(f\"\\nüìÇ Repository structure:\")\n",
    "!ls -la {LOCAL_REPO_PATH}\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(LOCAL_REPO_PATH)\n",
    "print(f\"\\n‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-4"
   },
   "source": [
    "## 4. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing dependencies...\")\n",
    "\n",
    "!pip install -q h5py tqdm matplotlib seaborn\n",
    "\n",
    "# Verify installations\n",
    "import h5py\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import seaborn\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")\n",
    "print(f\"   h5py: {h5py.__version__}\")\n",
    "print(f\"   matplotlib: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-5"
   },
   "source": [
    "## 5. Download NYU Depth V2 Dataset to Local Disk\n",
    "\n",
    "**Performance Note:** Local disk I/O is ~10-20x faster than Drive!\n",
    "\n",
    "**Options:**\n",
    "- **Option A:** Download directly to local disk (~2.8 GB, takes 2-3 min)\n",
    "- **Option B:** Copy from Drive if you already have it there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-dataset"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "DRIVE_DATASET_PATH = \"/content/drive/MyDrive/datasets/nyu_depth_v2_labeled.mat\"\n",
    "LOCAL_DATASET_PATH = \"/content/nyu_depth_v2_labeled.mat\"  # Local disk (FAST)\n",
    "DATASET_URL = \"http://horatio.cs.nyu.edu/mit/silberman/nyu_depth_v2/nyu_depth_v2_labeled.mat\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NYU DEPTH V2 DATASET SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if already on local disk\n",
    "if Path(LOCAL_DATASET_PATH).exists():\n",
    "    print(f\"‚úÖ Dataset already on local disk: {LOCAL_DATASET_PATH}\")\n",
    "    print(f\"   Size: {Path(LOCAL_DATASET_PATH).stat().st_size / 1024**3:.2f} GB\")\n",
    "\n",
    "# Option A: Copy from Drive (if available)\n",
    "elif Path(DRIVE_DATASET_PATH).exists():\n",
    "    print(f\"üìÅ Found dataset on Drive: {DRIVE_DATASET_PATH}\")\n",
    "    print(f\"üì• Copying to local disk for 10-20x faster training...\")\n",
    "    print(f\"   This takes ~2-3 minutes but saves 60+ minutes during training!\")\n",
    "    \n",
    "    !cp {DRIVE_DATASET_PATH} {LOCAL_DATASET_PATH}\n",
    "    \n",
    "    print(f\"‚úÖ Dataset copied to local disk\")\n",
    "    print(f\"   Size: {Path(LOCAL_DATASET_PATH).stat().st_size / 1024**3:.2f} GB\")\n",
    "\n",
    "# Option B: Download from internet\n",
    "else:\n",
    "    print(f\"üì• Downloading NYU Depth V2 dataset (~2.8 GB)...\")\n",
    "    print(f\"   URL: {DATASET_URL}\")\n",
    "    print(f\"   Destination: {LOCAL_DATASET_PATH}\")\n",
    "    print(f\"   This will take ~2-3 minutes\")\n",
    "    \n",
    "    # Download with progress bar\n",
    "    class DownloadProgressBar(tqdm):\n",
    "        def update_to(self, b=1, bsize=1, tsize=None):\n",
    "            if tsize is not None:\n",
    "                self.total = tsize\n",
    "            self.update(b * bsize - self.n)\n",
    "    \n",
    "    with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc='NYU Depth V2') as t:\n",
    "        urllib.request.urlretrieve(DATASET_URL, LOCAL_DATASET_PATH, reporthook=t.update_to)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Download complete!\")\n",
    "    print(f\"   Size: {Path(LOCAL_DATASET_PATH).stat().st_size / 1024**3:.2f} GB\")\n",
    "    \n",
    "    # Optionally save to Drive for future use\n",
    "    save_to_drive = input(\"\\nSave dataset to Drive for future sessions? (y/N): \")\n",
    "    if save_to_drive.lower() == 'y':\n",
    "        print(\"Saving to Drive...\")\n",
    "        !mkdir -p /content/drive/MyDrive/datasets/\n",
    "        !cp {LOCAL_DATASET_PATH} {DRIVE_DATASET_PATH}\n",
    "        print(\"‚úÖ Saved to Drive\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Dataset ready at: {LOCAL_DATASET_PATH}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-6"
   },
   "source": [
    "## 6. Setup Python Path & Import MCResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-imports"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project to Python path\n",
    "project_root = '/content/Multi-Stream-Neural-Networks'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Verify project structure\n",
    "print(\"Project structure:\")\n",
    "!ls -la {project_root}/src/models/\n",
    "\n",
    "# Import MCResNet\n",
    "print(\"\\nImporting MCResNet...\")\n",
    "from src.models.multi_channel.mc_resnet import mc_resnet18, mc_resnet50\n",
    "from src.data_utils.nyu_depth_dataset import create_nyu_dataloaders\n",
    "\n",
    "print(\"‚úÖ MCResNet imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-7"
   },
   "source": [
    "## 7. Load NYU Depth V2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-dataset"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LOADING NYU DEPTH V2 DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_CONFIG = {\n",
    "    'dataset_path': '/content/nyu_depth_v2_labeled.mat',\n",
    "    'batch_size': 128,  # A100 can handle this with AMP\n",
    "    'num_workers': 4,   # Colab has limited CPU cores\n",
    "    'target_size': (224, 224),\n",
    "    'num_classes': 13   # Scene classification\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "for key, value in DATASET_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nLoading dataset from: {DATASET_CONFIG['dataset_path']}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = create_nyu_dataloaders(\n",
    "    h5_file_path=DATASET_CONFIG['dataset_path'],\n",
    "    batch_size=DATASET_CONFIG['batch_size'],\n",
    "    num_workers=DATASET_CONFIG['num_workers'],\n",
    "    target_size=DATASET_CONFIG['target_size'],\n",
    "    num_classes=DATASET_CONFIG['num_classes']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Train samples: {len(train_loader.dataset)}\")\n",
    "print(f\"  Val samples: {len(val_loader.dataset)}\")\n",
    "print(f\"  Batch size: {DATASET_CONFIG['batch_size']}\")\n",
    "\n",
    "# Test loading a batch\n",
    "print(f\"\\nTesting batch loading...\")\n",
    "rgb_batch, depth_batch, label_batch = next(iter(train_loader))\n",
    "print(f\"  RGB shape: {rgb_batch.shape}\")\n",
    "print(f\"  Depth shape: {depth_batch.shape}\")\n",
    "print(f\"  Labels shape: {label_batch.shape}\")\n",
    "print(f\"  Labels range: {label_batch.min().item()} - {label_batch.max().item()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-8"
   },
   "source": [
    "## 8. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-data"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "\n",
    "for i in range(4):\n",
    "    rgb = rgb_batch[i].cpu()\n",
    "    depth = depth_batch[i].cpu()\n",
    "    label = label_batch[i].item()\n",
    "    \n",
    "    # Denormalize for visualization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    rgb_vis = rgb * std + mean\n",
    "    rgb_vis = torch.clamp(rgb_vis, 0, 1)\n",
    "    \n",
    "    # Plot RGB\n",
    "    axes[0, i].imshow(rgb_vis.permute(1, 2, 0))\n",
    "    axes[0, i].set_title(f\"RGB - Class {label}\", fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot Depth\n",
    "    axes[1, i].imshow(depth.squeeze(), cmap='viridis')\n",
    "    axes[1, i].set_title(f\"Depth - Class {label}\", fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('NYU Depth V2 Sample Data (RGB + Depth)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-9"
   },
   "source": [
    "## 9. Create & Compile MCResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-model"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODEL CREATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'architecture': 'resnet18',  # or 'resnet50' for better accuracy\n",
    "    'num_classes': 13,\n",
    "    'stream1_channels': 3,  # RGB\n",
    "    'stream2_channels': 1,  # Depth\n",
    "    'device': 'cuda',\n",
    "    'use_amp': True  # Automatic Mixed Precision (2x faster on A100)\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "for key, value in MODEL_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create model\n",
    "print(f\"\\nCreating MCResNet-{MODEL_CONFIG['architecture'].upper()}...\")\n",
    "\n",
    "if MODEL_CONFIG['architecture'] == 'resnet18':\n",
    "    model = mc_resnet18(\n",
    "        num_classes=MODEL_CONFIG['num_classes'],\n",
    "        stream1_channels=MODEL_CONFIG['stream1_channels'],\n",
    "        stream2_channels=MODEL_CONFIG['stream2_channels'],\n",
    "        device=MODEL_CONFIG['device'],\n",
    "        use_amp=MODEL_CONFIG['use_amp']\n",
    "    )\n",
    "elif MODEL_CONFIG['architecture'] == 'resnet50':\n",
    "    model = mc_resnet50(\n",
    "        num_classes=MODEL_CONFIG['num_classes'],\n",
    "        stream1_channels=MODEL_CONFIG['stream1_channels'],\n",
    "        stream2_channels=MODEL_CONFIG['stream2_channels'],\n",
    "        device=MODEL_CONFIG['device'],\n",
    "        use_amp=MODEL_CONFIG['use_amp']\n",
    "    )\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model created successfully!\")\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: {total_params * 4 / 1024**2:.2f} MB (FP32)\")\n",
    "print(f\"  Device: {MODEL_CONFIG['device']}\")\n",
    "print(f\"  AMP enabled: {MODEL_CONFIG['use_amp']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compile-model"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'optimizer': 'sgd',\n",
    "    'learning_rate': 0.1,  # Standard for ImageNet-style training\n",
    "    'weight_decay': 1e-4,\n",
    "    'momentum': 0.9,\n",
    "    'loss': 'cross_entropy',\n",
    "    'scheduler': 'cosine'\n",
    "}\n",
    "\n",
    "print(\"Compiling model...\")\n",
    "print(f\"\\nTraining configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=TRAINING_CONFIG['optimizer'],\n",
    "    learning_rate=TRAINING_CONFIG['learning_rate'],\n",
    "    weight_decay=TRAINING_CONFIG['weight_decay'],\n",
    "    momentum=TRAINING_CONFIG['momentum'],\n",
    "    loss=TRAINING_CONFIG['loss'],\n",
    "    scheduler=TRAINING_CONFIG['scheduler']\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-10"
   },
   "source": [
    "## 10. Test Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-forward"
   },
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "print(\"Testing forward pass...\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    rgb_test, depth_test, labels_test = next(iter(train_loader))\n",
    "    outputs = model(rgb_test.to('cuda'), depth_test.to('cuda'))\n",
    "    \n",
    "    print(f\"\\nInput shapes:\")\n",
    "    print(f\"  RGB: {rgb_test.shape}\")\n",
    "    print(f\"  Depth: {depth_test.shape}\")\n",
    "    print(f\"  Labels: {labels_test.shape}\")\n",
    "    \n",
    "    print(f\"\\nOutput shape: {outputs.shape}\")\n",
    "    print(f\"Expected: ({DATASET_CONFIG['batch_size']}, {DATASET_CONFIG['num_classes']})\")\n",
    "    \n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    print(f\"\\nSample predictions: {predictions.cpu().numpy()[:10]}\")\n",
    "    print(f\"Ground truth: {labels_test.numpy()[:10]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-11"
   },
   "source": [
    "## 11. Setup Checkpoint Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-checkpoints"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Create checkpoint directory on Drive (persistent storage)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint_dir = f\"/content/drive/MyDrive/MCResNet_checkpoints/nyu_depth_v2_{timestamp}\"\n",
    "Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Checkpoint directory: {checkpoint_dir}\")\n",
    "print(f\"\\nCheckpoints will be saved to Google Drive for persistence\")\n",
    "print(\"‚úÖ Directory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-12"
   },
   "source": [
    "## 12. Train the Model üöÄ\n",
    "\n",
    "**Expected time:** ~2-3 hours for 90 epochs on A100\n",
    "\n",
    "**All optimizations enabled:**\n",
    "- ‚úÖ Automatic Mixed Precision (2x faster)\n",
    "- ‚úÖ Gradient Clipping (stability)\n",
    "- ‚úÖ Cosine Annealing LR\n",
    "- ‚úÖ Early Stopping\n",
    "- ‚úÖ Best Model Checkpointing\n",
    "- ‚úÖ Local disk I/O (10-20x faster than Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-model"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training configuration\n",
    "TRAIN_CONFIG = {\n",
    "    'epochs': 90,  # Standard for ImageNet-style training\n",
    "    'grad_clip_norm': 5.0,  # Gradient clipping for stability\n",
    "    'early_stopping': True,\n",
    "    'patience': 15,\n",
    "    'min_delta': 0.001,\n",
    "    'monitor': 'val_accuracy',\n",
    "    'restore_best_weights': True,\n",
    "    'save_path': f\"{checkpoint_dir}/best_model.pt\"\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "for key, value in TRAIN_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Training will take approximately 2-3 hours on A100\")\n",
    "print(f\"Progress will be shown below...\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Train!\n",
    "history = model.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=TRAIN_CONFIG['epochs'],\n",
    "    verbose=True,\n",
    "    save_path=TRAIN_CONFIG['save_path'],\n",
    "    early_stopping=TRAIN_CONFIG['early_stopping'],\n",
    "    patience=TRAIN_CONFIG['patience'],\n",
    "    min_delta=TRAIN_CONFIG['min_delta'],\n",
    "    monitor=TRAIN_CONFIG['monitor'],\n",
    "    restore_best_weights=TRAIN_CONFIG['restore_best_weights'],\n",
    "    grad_clip_norm=TRAIN_CONFIG['grad_clip_norm']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-13"
   },
   "source": [
    "## 13. Evaluate Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-model"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluate on validation set\n",
    "results = model.evaluate(data_loader=val_loader)\n",
    "\n",
    "print(f\"\\nFinal Validation Results:\")\n",
    "print(f\"  Loss: {results['loss']:.4f}\")\n",
    "print(f\"  Accuracy: {results['accuracy']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Initial train loss: {history['train_loss'][0]:.4f}\")\n",
    "print(f\"  Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Best val loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"  Initial train acc: {history['train_accuracy'][0]*100:.2f}%\")\n",
    "print(f\"  Final train acc: {history['train_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  Best val acc: {max(history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"  Total epochs: {len(history['train_loss'])}\")\n",
    "\n",
    "if 'early_stopping' in history:\n",
    "    print(f\"\\nEarly Stopping Info:\")\n",
    "    print(f\"  Stopped early: {history['early_stopping']['stopped_early']}\")\n",
    "    print(f\"  Best epoch: {history['early_stopping']['best_epoch']}\")\n",
    "    print(f\"  Best {history['early_stopping']['monitor']}: {history['early_stopping']['best_metric']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-14"
   },
   "source": [
    "## 14. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-curves"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot([acc*100 for acc in history['train_accuracy']], label='Train Acc', linewidth=2)\n",
    "axes[1].plot([acc*100 for acc in history['val_accuracy']], label='Val Acc', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate curve\n",
    "if len(history['learning_rates']) > 0:\n",
    "    # Sample learning rates (they're recorded per step, not per epoch)\n",
    "    sampled_lrs = history['learning_rates'][::max(1, len(history['learning_rates'])//100)]\n",
    "    axes[2].plot(sampled_lrs, linewidth=2, color='green')\n",
    "    axes[2].set_xlabel('Training Step (sampled)', fontsize=12)\n",
    "    axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{checkpoint_dir}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Training curves saved to: {checkpoint_dir}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-15"
   },
   "source": [
    "## 15. Pathway Analysis (RGB vs Depth Contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pathway-analysis"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PATHWAY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nAnalyzing RGB and Depth pathway contributions...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Analyze pathways\n",
    "pathway_analysis = model.analyze_pathways(\n",
    "    data_loader=val_loader,\n",
    "    num_samples=len(val_loader.dataset)  # Use all validation samples\n",
    ")\n",
    "\n",
    "print(\"\\nAccuracy Metrics:\")\n",
    "print(f\"  Full model (RGB+Depth): {pathway_analysis['accuracy']['full_model']*100:.2f}%\")\n",
    "print(f\"  RGB only: {pathway_analysis['accuracy']['color_only']*100:.2f}%\")\n",
    "print(f\"  Depth only: {pathway_analysis['accuracy']['brightness_only']*100:.2f}%\")\n",
    "print(f\"\\n  RGB contribution: {pathway_analysis['accuracy']['color_contribution']*100:.2f}%\")\n",
    "print(f\"  Depth contribution: {pathway_analysis['accuracy']['brightness_contribution']*100:.2f}%\")\n",
    "\n",
    "print(\"\\nLoss Metrics:\")\n",
    "print(f\"  Full model: {pathway_analysis['loss']['full_model']:.4f}\")\n",
    "print(f\"  RGB only: {pathway_analysis['loss']['color_only']:.4f}\")\n",
    "print(f\"  Depth only: {pathway_analysis['loss']['brightness_only']:.4f}\")\n",
    "\n",
    "print(\"\\nFeature Norm Statistics:\")\n",
    "print(f\"  RGB mean: {pathway_analysis['feature_norms']['color_mean']:.4f}\")\n",
    "print(f\"  RGB std: {pathway_analysis['feature_norms']['color_std']:.4f}\")\n",
    "print(f\"  Depth mean: {pathway_analysis['feature_norms']['brightness_mean']:.4f}\")\n",
    "print(f\"  Depth std: {pathway_analysis['feature_norms']['brightness_std']:.4f}\")\n",
    "print(f\"  RGB/Depth ratio: {pathway_analysis['feature_norms']['color_to_brightness_ratio']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Pathway analysis complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualize pathway contributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "pathways = ['Full Model\\n(RGB+Depth)', 'RGB Only', 'Depth Only']\n",
    "accuracies = [\n",
    "    pathway_analysis['accuracy']['full_model'] * 100,\n",
    "    pathway_analysis['accuracy']['color_only'] * 100,\n",
    "    pathway_analysis['accuracy']['brightness_only'] * 100\n",
    "]\n",
    "colors = ['green', 'blue', 'orange']\n",
    "\n",
    "axes[0].bar(pathways, accuracies, color=colors, alpha=0.7)\n",
    "axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[0].set_title('Pathway Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(accuracies):\n",
    "    axes[0].text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Feature norm comparison\n",
    "norms = ['RGB Features', 'Depth Features']\n",
    "norm_values = [\n",
    "    pathway_analysis['feature_norms']['color_mean'],\n",
    "    pathway_analysis['feature_norms']['brightness_mean']\n",
    "]\n",
    "axes[1].bar(norms, norm_values, color=['blue', 'orange'], alpha=0.7)\n",
    "axes[1].set_ylabel('Feature Norm (Mean)', fontsize=12)\n",
    "axes[1].set_title('Feature Magnitude Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(norm_values):\n",
    "    axes[1].text(i, v + 0.1, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{checkpoint_dir}/pathway_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Pathway analysis plot saved to: {checkpoint_dir}/pathway_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-16"
   },
   "source": [
    "## 16. Save Results & Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-results"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save training history as JSON\n",
    "history_path = f\"{checkpoint_dir}/training_history.json\"\n",
    "with open(history_path, 'w') as f:\n",
    "    json_history = {\n",
    "        'train_loss': [float(x) for x in history['train_loss']],\n",
    "        'val_loss': [float(x) for x in history['val_loss']],\n",
    "        'train_accuracy': [float(x) for x in history['train_accuracy']],\n",
    "        'val_accuracy': [float(x) for x in history['val_accuracy']],\n",
    "        'learning_rates': [float(x) for x in history['learning_rates']],\n",
    "        'model_config': MODEL_CONFIG,\n",
    "        'dataset_config': DATASET_CONFIG,\n",
    "        'training_config': TRAINING_CONFIG,\n",
    "        'final_results': {\n",
    "            'val_loss': float(results['loss']),\n",
    "            'val_accuracy': float(results['accuracy'])\n",
    "        },\n",
    "        'pathway_analysis': {\n",
    "            'full_model_accuracy': float(pathway_analysis['accuracy']['full_model']),\n",
    "            'rgb_only_accuracy': float(pathway_analysis['accuracy']['color_only']),\n",
    "            'depth_only_accuracy': float(pathway_analysis['accuracy']['brightness_only'])\n",
    "        }\n",
    "    }\n",
    "    if 'early_stopping' in history:\n",
    "        json_history['early_stopping'] = history['early_stopping']\n",
    "    \n",
    "    json.dump(json_history, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Training history saved: {history_path}\")\n",
    "\n",
    "# Save final model (in addition to best model)\n",
    "final_model_path = f\"{checkpoint_dir}/final_model.pt\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': model.optimizer.state_dict(),\n",
    "    'config': MODEL_CONFIG,\n",
    "    'history': history,\n",
    "    'val_accuracy': results['accuracy']\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"‚úÖ Final model saved: {final_model_path}\")\n",
    "\n",
    "# Save summary report\n",
    "summary_path = f\"{checkpoint_dir}/summary.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(\"MCResNet Training Summary - NYU Depth V2\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Model: MCResNet-{MODEL_CONFIG['architecture'].upper()}\\n\")\n",
    "    f.write(f\"Dataset: NYU Depth V2 (Scene Classification)\\n\")\n",
    "    f.write(f\"Training Samples: {len(train_loader.dataset)}\\n\")\n",
    "    f.write(f\"Validation Samples: {len(val_loader.dataset)}\\n\")\n",
    "    f.write(f\"Total Parameters: {total_params:,}\\n\")\n",
    "    f.write(f\"\\nTraining Configuration:\\n\")\n",
    "    f.write(f\"  Epochs: {len(history['train_loss'])}\\n\")\n",
    "    f.write(f\"  Batch Size: {DATASET_CONFIG['batch_size']}\\n\")\n",
    "    f.write(f\"  Learning Rate: {TRAINING_CONFIG['learning_rate']}\\n\")\n",
    "    f.write(f\"  Optimizer: {TRAINING_CONFIG['optimizer']}\\n\")\n",
    "    f.write(f\"  Scheduler: {TRAINING_CONFIG['scheduler']}\\n\")\n",
    "    f.write(f\"  AMP: {MODEL_CONFIG['use_amp']}\\n\")\n",
    "    f.write(f\"  Gradient Clipping: {TRAIN_CONFIG['grad_clip_norm']}\\n\")\n",
    "    f.write(f\"\\nFinal Results:\\n\")\n",
    "    f.write(f\"  Val Loss: {results['loss']:.4f}\\n\")\n",
    "    f.write(f\"  Val Accuracy: {results['accuracy']*100:.2f}%\\n\")\n",
    "    f.write(f\"  Best Val Accuracy: {max(history['val_accuracy'])*100:.2f}%\\n\")\n",
    "    f.write(f\"\\nPathway Analysis:\\n\")\n",
    "    f.write(f\"  Full Model: {pathway_analysis['accuracy']['full_model']*100:.2f}%\\n\")\n",
    "    f.write(f\"  RGB Only: {pathway_analysis['accuracy']['color_only']*100:.2f}%\\n\")\n",
    "    f.write(f\"  Depth Only: {pathway_analysis['accuracy']['brightness_only']*100:.2f}%\\n\")\n",
    "\n",
    "print(f\"‚úÖ Summary report saved: {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"All results saved to: {checkpoint_dir}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# List saved files\n",
    "print(\"\\nSaved files:\")\n",
    "!ls -lh {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section-17"
   },
   "source": [
    "## 17. Summary & Next Steps\n",
    "\n",
    "### üéâ Training Complete!\n",
    "\n",
    "**What we accomplished:**\n",
    "- ‚úÖ Trained MCResNet on NYU Depth V2 dataset\n",
    "- ‚úÖ Used A100 GPU with AMP (2x speedup)\n",
    "- ‚úÖ Saved all checkpoints to Google Drive\n",
    "- ‚úÖ Analyzed RGB and Depth pathway contributions\n",
    "- ‚úÖ Generated training curves and visualizations\n",
    "\n",
    "**Results are saved to:** Check the output above for the checkpoint directory path\n",
    "\n",
    "### üìä Expected Performance:\n",
    "\n",
    "For **NYU Depth V2 Scene Classification (13 classes)**:\n",
    "- **Good:** 65-75% validation accuracy\n",
    "- **Very Good:** 75-80% validation accuracy  \n",
    "- **Excellent:** 80-85% validation accuracy\n",
    "\n",
    "### üîç Next Steps:\n",
    "\n",
    "1. **Review Results:**\n",
    "   - Check training curves above\n",
    "   - Review pathway analysis\n",
    "   - Compare RGB vs Depth contributions\n",
    "\n",
    "2. **Download Results:**\n",
    "   - All files are saved to your Google Drive\n",
    "   - Download checkpoints for local inference\n",
    "\n",
    "3. **Experiment:**\n",
    "   - Try ResNet50 for better accuracy (change `architecture` in Model Config)\n",
    "   - Adjust hyperparameters (learning rate, batch size)\n",
    "   - Train longer if early stopping triggered\n",
    "\n",
    "4. **Deploy:**\n",
    "   - Use the best model for inference\n",
    "   - Test on new RGB-D images\n",
    "   - Integrate into your application\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Check the training summary and pathway analysis above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final-summary"
   },
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚úÖ Training Complete!\")\n",
    "print(f\"\\nFinal Validation Accuracy: {results['accuracy']*100:.2f}%\")\n",
    "print(f\"Best Validation Accuracy: {max(history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"\\nRGB Pathway: {pathway_analysis['accuracy']['color_only']*100:.2f}%\")\n",
    "print(f\"Depth Pathway: {pathway_analysis['accuracy']['brightness_only']*100:.2f}%\")\n",
    "print(f\"Combined (RGB+Depth): {pathway_analysis['accuracy']['full_model']*100:.2f}%\")\n",
    "print(f\"\\nTotal Training Epochs: {len(history['train_loss'])}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"\\nCheckpoints saved to: {checkpoint_dir}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ All done! Check Google Drive for saved models and results.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
