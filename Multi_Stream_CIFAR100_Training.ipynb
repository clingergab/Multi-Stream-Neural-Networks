{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0aae91",
   "metadata": {
    "id": "4f0aae91"
   },
   "source": [
    "# Multi-Stream Neural Networks: CIFAR-100 Training\n",
    "\n",
    "This notebook demonstrates the full pipeline for training multi-stream neural networks on CIFAR-100 data:\n",
    "\n",
    "ðŸš€ **Features:**\n",
    "- Automatic GPU detection and optimization\n",
    "- RGB to RGBL preprocessing with visualizations\n",
    "- BaseMultiChannelNetwork (Dense) and MultiChannelResNetNetwork (CNN) models\n",
    "- Dynamic progress bars during training\n",
    "- Comprehensive evaluation and analysis\n",
    "\n",
    "**Hardware Requirements:**\n",
    "- Google Colab with GPU runtime (A100/V100 recommended)\n",
    "- Sufficient memory for CIFAR-100 dataset processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051aee4",
   "metadata": {
    "id": "7051aee4"
   },
   "source": [
    "## 1. Setup: Mount Drive and Navigate to Project\n",
    "\n",
    "Mount Google Drive and navigate to the existing Multi-Stream Neural Networks project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "-A29FzCJ5c4R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-A29FzCJ5c4R",
    "outputId": "9c45fe68-d922-4e02-978d-38efd4c4061d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xo3JWyNVEGMZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xo3JWyNVEGMZ",
    "outputId": "34f5af2f-a23c-4e75-848f-94bbf88fffb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Multi-Stream-Neural-Networks'...\n",
      "remote: Enumerating objects: 228, done.\u001b[K\n",
      "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
      "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
      "remote: Total 228 (delta 33), reused 221 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (228/228), 258.62 KiB | 2.94 MiB/s, done.\n",
      "Resolving deltas: 100% (33/33), done.\n"
     ]
    }
   ],
   "source": [
    "# Navigate to Drive and project directory\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive')\n",
    "\n",
    "# Navigate to the existing project (assuming it's already cloned)\n",
    "project_path = '/content/drive/MyDrive/Multi-Stream-Neural-Networks'\n",
    "if os.path.exists(project_path):\n",
    "    os.chdir(project_path)\n",
    "    print(f\"âœ… Found project at: {project_path}\")\n",
    "else:\n",
    "    print(f\"âŒ Project not found at: {project_path}\")\n",
    "    print(\"ðŸ’¡ Please clone the repository first:\")\n",
    "    print(\"   !git clone https://github.com/clingergab/Multi-Stream-Neural-Networks.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955bd1d",
   "metadata": {},
   "source": [
    "## 2. Update Repository\n",
    "\n",
    "Pull the latest changes from the repository to ensure you have the most up-to-date code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update repository with latest changes\n",
    "print(\"ðŸ”„ Pulling latest changes from repository...\")\n",
    "\n",
    "# Make sure we're in the right directory\n",
    "os.chdir('/content/drive/MyDrive/Multi-Stream-Neural-Networks')\n",
    "print(f\"ðŸ“ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Pull latest changes\n",
    "!git pull origin main\n",
    "\n",
    "# Show latest commit info\n",
    "print(\"\\nðŸ“‹ Latest commit:\")\n",
    "!git log --oneline -1\n",
    "\n",
    "# Check status\n",
    "print(\"\\nðŸ“Š Repository status:\")\n",
    "!git status --short\n",
    "\n",
    "print(\"\\nâœ… Repository update complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac36a39",
   "metadata": {
    "id": "3ac36a39"
   },
   "source": [
    "## 2. Install and Import Required Libraries\n",
    "\n",
    "Install any missing dependencies and import all necessary libraries for the multi-stream neural network training.\n",
    "\n",
    "## 3. Install Dependencies and Import Libraries\n",
    "\n",
    "Install compatible PyTorch/NumPy versions and import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c193f97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0c193f97",
    "outputId": "1786d6e3-0a7e-4e72-8267-b9b469dbcf78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=12.4. Please reinstall the torchvision that matches your PyTorch install.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-6-2174902703.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Don't re-order these, we need to load the _C extension (done when importing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0m_check_cuda_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m_check_cuda_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mt_minor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_version\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_major\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtv_major\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;34m\"Detected that PyTorch and torchvision were compiled with different CUDA major versions. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;34mf\"PyTorch has CUDA Version={t_major}.{t_minor} and torchvision has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=12.4. Please reinstall the torchvision that matches your PyTorch install."
     ]
    }
   ],
   "source": [
    "# Install compatible PyTorch, NumPy, and dependencies\n",
    "print(\"ðŸ”§ Installing compatible PyTorch, NumPy, and dependencies...\")\n",
    "\n",
    "# Check current environment\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Install compatible versions (optimized for no restart)\n",
    "print(\"ðŸ“¦ Installing packages...\")\n",
    "!pip install -q numpy==1.24.3\n",
    "!pip install -q torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q tqdm matplotlib seaborn scikit-learn\n",
    "\n",
    "print(\"âœ… Installation complete!\")\n",
    "\n",
    "# Import all required libraries\n",
    "print(\"\\nðŸ“¦ Importing libraries...\")\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project to Python path\n",
    "sys.path.append('/content/drive/MyDrive/Multi-Stream-Neural-Networks')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Data and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from typing import Tuple, Dict, List\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Verify installations\n",
    "print(\"ðŸ” Verifying installations...\")\n",
    "print(f\"   NumPy: {np.__version__}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   Torchvision: {torchvision.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Import project modules\n",
    "print(\"\\nðŸ“ Importing project modules...\")\n",
    "try:\n",
    "    from src.models.basic_multi_channel.base_multi_channel_network import BaseMultiChannelNetwork\n",
    "    from src.models.basic_multi_channel.multi_channel_resnet_network import MultiChannelResNetNetwork\n",
    "    from src.transforms.rgb_to_rgbl import RGBtoRGBL\n",
    "    from src.utils.colab_utils import load_cifar10\n",
    "    from src.utils.cifar100_loader import get_cifar100_datasets, CIFAR100_FINE_LABELS, SimpleDataset\n",
    "    print(\"âœ… All imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Import warning: {e}\")\n",
    "    print(\"   Make sure you've updated the repository in the previous step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abf9ff",
   "metadata": {
    "id": "d4abf9ff"
   },
   "source": [
    "## 4. Load CIFAR-100 Dataset\n",
    "\n",
    "Load the CIFAR-100 dataset and verify its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0884a06",
   "metadata": {
    "id": "a0884a06"
   },
   "outputs": [],
   "source": [
    "# Import our CIFAR-100 data loading utilities\n",
    "print(\"ðŸ“ Setting up CIFAR-100 dataset loading...\")\n",
    "\n",
    "# Import the CIFAR-100 loader utilities\n",
    "try:\n",
    "    from src.utils.cifar100_loader import get_cifar100_datasets, CIFAR100_FINE_LABELS\n",
    "    print(\"âœ… CIFAR-100 loader utilities imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Failed to import CIFAR-100 utilities: {e}\")\n",
    "    print(\"ðŸ’¡ Make sure you're in the correct directory and have run git pull\")\n",
    "    raise\n",
    "\n",
    "# Check if data folder exists\n",
    "data_path = Path(\"data/cifar-100\")\n",
    "if data_path.exists():\n",
    "    print(f\"âœ… Data folder found at: {data_path}\")\n",
    "else:\n",
    "    print(f\"ðŸ“ Creating data structure at: {data_path}\")\n",
    "    data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the datasets using our utility\n",
    "print(\"ðŸ“Š Loading CIFAR-100 datasets...\")\n",
    "train_dataset, test_dataset, cifar100_fine_labels = get_cifar100_datasets()\n",
    "\n",
    "# Get raw data for backward compatibility with existing code\n",
    "train_data = train_dataset.data\n",
    "train_labels = train_dataset.labels\n",
    "test_data = test_dataset.data\n",
    "test_labels = test_dataset.labels\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Info:\")\n",
    "print(f\"   Training samples: {len(train_data)}\")\n",
    "print(f\"   Test samples: {len(test_data)}\")\n",
    "print(f\"   Image shape: {train_data[0].shape}\")\n",
    "print(f\"   Number of classes: {len(cifar100_fine_labels)}\")\n",
    "print(f\"   Label format: Single integer (fine labels 0-99)\")\n",
    "print(f\"   Data range: [{train_data.min():.3f}, {train_data.max():.3f}]\")\n",
    "\n",
    "print(\"âœ… CIFAR-100 datasets ready for processing!\")\n",
    "print(\"ðŸ’¡ No torchvision naming conventions needed - loaded directly from pickle files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ae3dd",
   "metadata": {
    "id": "1a6ae3dd"
   },
   "source": [
    "## 5. Process Data: RGB to Multi-Stream Format\n",
    "\n",
    "Convert RGB images to both RGB and brightness (luminance) channels to create multi-stream data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c9ead",
   "metadata": {
    "id": "945c9ead"
   },
   "outputs": [],
   "source": [
    "# RGB to RGBL Data Processing with caching support\n",
    "print(\"ðŸ”„ Starting RGB to RGBL data processing...\")\n",
    "\n",
    "# Import the transformation (should work if previous cells succeeded)\n",
    "try:\n",
    "    from src.transforms.rgb_to_rgbl import RGBtoRGBL\n",
    "    print(\"âœ… RGBtoRGBL transform imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Failed to import RGBtoRGBL: {e}\")\n",
    "    print(\"ðŸ’¡ Make sure you're in the correct directory and have run git pull\")\n",
    "    raise\n",
    "\n",
    "def convert_dataset_to_multi_stream(dataset, max_samples=None, cache_file=None, force_reprocess=False):\n",
    "    \"\"\"\n",
    "    Convert a CIFAR-100 dataset to multi-stream format (RGB + Brightness).\n",
    "    Supports caching to avoid reprocessing if interrupted.\n",
    "\n",
    "    Args:\n",
    "        dataset: CIFAR-100 dataset\n",
    "        max_samples: Maximum number of samples to process (for faster testing)\n",
    "        cache_file: Path to cache file for resuming processing\n",
    "        force_reprocess: Force reprocessing even if cache exists\n",
    "\n",
    "    Returns:\n",
    "        rgb_data: RGB channel data [N, 3, 32, 32]\n",
    "        brightness_data: Brightness channel data [N, 1, 32, 32]\n",
    "        labels: Class labels [N]\n",
    "    \"\"\"\n",
    "    # Check for cached results first\n",
    "    if cache_file and Path(cache_file).exists() and not force_reprocess:\n",
    "        print(f\"âœ… Loading cached data from {cache_file}\")\n",
    "        try:\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                cached_data = pickle.load(f)\n",
    "            print(f\"   Loaded {len(cached_data['labels'])} samples from cache\")\n",
    "            return cached_data['rgb_data'], cached_data['brightness_data'], cached_data['labels']\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to load cache: {e}. Reprocessing...\")\n",
    "\n",
    "    print(f\"ðŸ”„ Converting dataset to multi-stream format...\")\n",
    "\n",
    "    # Initialize RGB to RGBL transform\n",
    "    rgb_to_rgbl = RGBtoRGBL()\n",
    "    print(\"âœ… RGB to RGBL transform initialized\")\n",
    "\n",
    "    # Determine number of samples to process\n",
    "    num_samples = len(dataset) if max_samples is None else min(max_samples, len(dataset))\n",
    "    print(f\"   Processing {num_samples} samples...\")\n",
    "\n",
    "    # Initialize arrays\n",
    "    rgb_data = []\n",
    "    brightness_data = []\n",
    "    labels = []\n",
    "\n",
    "    # Process samples with progress bar and checkpoint saving\n",
    "    try:\n",
    "        with tqdm(range(num_samples), desc=\"Processing images\") as pbar:\n",
    "            for i in pbar:\n",
    "                try:\n",
    "                    # Get image and label - CIFAR-100 returns (image, single_integer_label)\n",
    "                    image, label = dataset[i]\n",
    "                    \n",
    "                    # Convert label to int if it's a tensor\n",
    "                    if hasattr(label, 'item'):\n",
    "                        label = label.item()\n",
    "                    \n",
    "                    # Convert to RGBL\n",
    "                    rgbl_image = rgb_to_rgbl(image)\n",
    "\n",
    "                    # Split RGB and brightness channels\n",
    "                    rgb_channels = rgbl_image[:3]  # First 3 channels (RGB)\n",
    "                    brightness_channel = rgbl_image[3:4]  # Last channel (Brightness)\n",
    "\n",
    "                    rgb_data.append(rgb_channels)\n",
    "                    brightness_data.append(brightness_channel)\n",
    "                    labels.append(label)\n",
    "\n",
    "                    # Update progress bar\n",
    "                    pbar.set_postfix({'processed': len(labels)})\n",
    "\n",
    "                    # Save checkpoint every 1000 samples\n",
    "                    if cache_file and (i + 1) % 1000 == 0:\n",
    "                        checkpoint_data = {\n",
    "                            'rgb_data': torch.stack(rgb_data).numpy(),\n",
    "                            'brightness_data': torch.stack(brightness_data).numpy(),\n",
    "                            'labels': np.array(labels),\n",
    "                            'processed': i + 1\n",
    "                        }\n",
    "                        with open(f\"{cache_file}.checkpoint\", 'wb') as f:\n",
    "                            pickle.dump(checkpoint_data, f)\n",
    "                        print(f\"   Checkpoint saved at sample {i + 1}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Error processing sample {i}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nâš ï¸ Processing interrupted at sample {len(labels)}\")\n",
    "        if len(labels) > 0:\n",
    "            print(\"ðŸ’¾ Saving partial results...\")\n",
    "            # Return what we have so far\n",
    "            rgb_data = torch.stack(rgb_data).numpy()\n",
    "            brightness_data = torch.stack(brightness_data).numpy()\n",
    "            labels = np.array(labels)\n",
    "            \n",
    "            if cache_file:\n",
    "                partial_data = {\n",
    "                    'rgb_data': rgb_data,\n",
    "                    'brightness_data': brightness_data,\n",
    "                    'labels': labels,\n",
    "                    'processed': len(labels)\n",
    "                }\n",
    "                with open(f\"{cache_file}.partial\", 'wb') as f:\n",
    "                    pickle.dump(partial_data, f)\n",
    "                print(f\"   Partial results saved to {cache_file}.partial\")\n",
    "            \n",
    "            return rgb_data, brightness_data, labels\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    if len(rgb_data) == 0:\n",
    "        raise ValueError(\"No data was processed successfully\")\n",
    "        \n",
    "    rgb_data = torch.stack(rgb_data).numpy()\n",
    "    brightness_data = torch.stack(brightness_data).numpy()\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Save to cache if specified\n",
    "    if cache_file:\n",
    "        final_data = {\n",
    "            'rgb_data': rgb_data,\n",
    "            'brightness_data': brightness_data,\n",
    "            'labels': labels\n",
    "        }\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            pickle.dump(final_data, f)\n",
    "        print(f\"ðŸ’¾ Results cached to {cache_file}\")\n",
    "\n",
    "    print(f\"âœ… Conversion complete!\")\n",
    "    print(f\"   RGB data shape: {rgb_data.shape}\")\n",
    "    print(f\"   Brightness data shape: {brightness_data.shape}\")\n",
    "    print(f\"   Labels shape: {labels.shape}\")\n",
    "\n",
    "    return rgb_data, brightness_data, labels\n",
    "\n",
    "# Process training data\n",
    "print(\"\\nðŸš€ Processing training data...\")\n",
    "train_rgb, train_brightness, train_labels = convert_dataset_to_multi_stream(\n",
    "    train_dataset, \n",
    "    max_samples=5000,  # Reduce for faster demo\n",
    "    cache_file=\"train_processed.pkl\"\n",
    ")\n",
    "\n",
    "# Process test data\n",
    "print(\"\\nðŸ§ª Processing test data...\")\n",
    "test_rgb, test_brightness, test_labels = convert_dataset_to_multi_stream(\n",
    "    test_dataset, \n",
    "    max_samples=1000,  # Reduce for faster demo\n",
    "    cache_file=\"test_processed.pkl\"\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Dataset Shapes:\")\n",
    "print(f\"   Training RGB: {train_rgb.shape}\")\n",
    "print(f\"   Training Brightness: {train_brightness.shape}\")\n",
    "print(f\"   Training Labels: {train_labels.shape}\")\n",
    "print(f\"   Test RGB: {test_rgb.shape}\")\n",
    "print(f\"   Test Brightness: {test_brightness.shape}\")\n",
    "print(f\"   Test Labels: {test_labels.shape}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: Processed data is cached. To reprocess, set force_reprocess=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c64ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify CIFAR-100 data structure\n",
    "print(\"ðŸ” Verifying CIFAR-100 data structure...\")\n",
    "\n",
    "# Check a few samples\n",
    "sample = train_dataset[0]\n",
    "image, target = sample\n",
    "print(f\"âœ… Sample structure: (image_tensor, integer_label)\")\n",
    "print(f\"   Image shape: {image.shape}\")\n",
    "print(f\"   Label: {target} ({cifar100_fine_labels[target]})\")\n",
    "print(f\"   Label type: {type(target)}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset summary:\")\n",
    "print(f\"   Training samples: {len(train_dataset)}\")\n",
    "print(f\"   Test samples: {len(test_dataset)}\")\n",
    "print(f\"   Classes: 100 (fine labels 0-99)\")\n",
    "print(\"âœ… Ready for multi-stream processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528859b2",
   "metadata": {},
   "source": [
    "### ðŸ”„ Recovery from Interruptions\n",
    "\n",
    "If the processing was interrupted, you can check for and load partial results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation: Verify processed data structure\n",
    "print(\"ðŸ” Validating processed data structure...\")\n",
    "\n",
    "def validate_processed_data(rgb_data, brightness_data, labels, dataset_name=\"dataset\"):\n",
    "    \"\"\"Validate the structure and contents of processed data.\"\"\"\n",
    "    \n",
    "    print(f\"\\nðŸ“Š {dataset_name} Validation:\")\n",
    "    \n",
    "    # Check shapes\n",
    "    print(f\"   RGB data shape: {rgb_data.shape}\")\n",
    "    print(f\"   Brightness data shape: {brightness_data.shape}\")\n",
    "    print(f\"   Labels shape: {labels.shape}\")\n",
    "    \n",
    "    # Check data types\n",
    "    print(f\"   RGB data type: {rgb_data.dtype}\")\n",
    "    print(f\"   Brightness data type: {brightness_data.dtype}\")\n",
    "    print(f\"   Labels data type: {labels.dtype}\")\n",
    "    \n",
    "    # Check value ranges\n",
    "    print(f\"   RGB range: [{rgb_data.min():.3f}, {rgb_data.max():.3f}]\")\n",
    "    print(f\"   Brightness range: [{brightness_data.min():.3f}, {brightness_data.max():.3f}]\")\n",
    "    print(f\"   Label range: [{labels.min()}, {labels.max()}]\")\n",
    "    \n",
    "    # Check for NaN or infinite values\n",
    "    rgb_issues = np.isnan(rgb_data).sum() + np.isinf(rgb_data).sum()\n",
    "    brightness_issues = np.isnan(brightness_data).sum() + np.isinf(brightness_data).sum()\n",
    "    label_issues = np.isnan(labels).sum() + np.isinf(labels).sum()\n",
    "    \n",
    "    print(f\"   RGB issues (NaN/Inf): {rgb_issues}\")\n",
    "    print(f\"   Brightness issues (NaN/Inf): {brightness_issues}\")\n",
    "    print(f\"   Label issues (NaN/Inf): {label_issues}\")\n",
    "    \n",
    "    # Verify dimensions match\n",
    "    n_samples = rgb_data.shape[0]\n",
    "    assert brightness_data.shape[0] == n_samples, f\"Brightness samples mismatch: {brightness_data.shape[0]} != {n_samples}\"\n",
    "    assert labels.shape[0] == n_samples, f\"Label samples mismatch: {labels.shape[0]} != {n_samples}\"\n",
    "    \n",
    "    # Verify channel dimensions\n",
    "    assert rgb_data.shape[1] == 3, f\"RGB should have 3 channels, got {rgb_data.shape[1]}\"\n",
    "    assert brightness_data.shape[1] == 1, f\"Brightness should have 1 channel, got {brightness_data.shape[1]}\"\n",
    "    \n",
    "    # Verify image dimensions (32x32 for CIFAR-100)\n",
    "    assert rgb_data.shape[2:] == (32, 32), f\"RGB image size should be 32x32, got {rgb_data.shape[2:]}\"\n",
    "    assert brightness_data.shape[2:] == (32, 32), f\"Brightness image size should be 32x32, got {brightness_data.shape[2:]}\"\n",
    "    \n",
    "    # Verify label range (0-99 for CIFAR-100)\n",
    "    assert labels.min() >= 0 and labels.max() <= 99, f\"Labels should be in range [0, 99], got [{labels.min()}, {labels.max()}]\"\n",
    "    \n",
    "    print(f\"   âœ… {dataset_name} validation passed!\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Only validate if data has been processed\n",
    "try:\n",
    "    if 'train_rgb' in locals() and 'train_brightness' in locals() and 'train_labels' in locals():\n",
    "        validate_processed_data(train_rgb, train_brightness, train_labels, \"Training\")\n",
    "    \n",
    "    if 'test_rgb' in locals() and 'test_brightness' in locals() and 'test_labels' in locals():\n",
    "        validate_processed_data(test_rgb, test_brightness, test_labels, \"Test\")\n",
    "    \n",
    "    print(\"\\nâœ… All data validation checks passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Data validation failed: {e}\")\n",
    "    print(\"ðŸ’¡ This might indicate an issue with the data processing step\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"â„¹ï¸ No processed data found. Run the data processing cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acff7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recovery: Check for and load partial processing results\n",
    "def check_and_load_partial_results():\n",
    "    \"\"\"Check for partial processing results and load them.\"\"\"\n",
    "    \n",
    "    partial_files = {\n",
    "        'train': 'train_processed.pkl.partial',\n",
    "        'test': 'test_processed.pkl.partial',\n",
    "        'train_checkpoint': 'train_processed.pkl.checkpoint',\n",
    "        'test_checkpoint': 'test_processed.pkl.checkpoint'\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, filepath in partial_files.items():\n",
    "        if Path(filepath).exists():\n",
    "            try:\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                results[name] = data\n",
    "                print(f\"âœ… Found {name} partial results: {data['processed']} samples\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Failed to load {name}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Check for any partial results\n",
    "print(\"ðŸ” Checking for partial processing results...\")\n",
    "partial_results = check_and_load_partial_results()\n",
    "\n",
    "if partial_results:\n",
    "    print(\"\\nðŸ’¡ Recovery options:\")\n",
    "    print(\"1. Continue processing from where you left off\")\n",
    "    print(\"2. Use partial results for faster testing\")\n",
    "    print(\"3. Clear cache and start fresh\")\n",
    "    \n",
    "    # Example: Load partial training data if available\n",
    "    if 'train' in partial_results:\n",
    "        print(f\"\\nðŸ“Š Partial training data available:\")\n",
    "        data = partial_results['train']\n",
    "        print(f\"   RGB shape: {data['rgb_data'].shape}\")\n",
    "        print(f\"   Brightness shape: {data['brightness_data'].shape}\")\n",
    "        print(f\"   Labels shape: {data['labels'].shape}\")\n",
    "        \n",
    "        # Uncomment to use partial data:\n",
    "        # train_rgb = data['rgb_data']\n",
    "        # train_brightness = data['brightness_data'] \n",
    "        # train_labels = data['labels']\n",
    "else:\n",
    "    print(\"â„¹ï¸ No partial results found. Processing will start from beginning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e3a1b",
   "metadata": {
    "id": "e73e3a1b"
   },
   "source": [
    "## 6. Visualize Sample Images: RGB and Brightness Side by Side\n",
    "\n",
    "Display sample images showing the original RGB and extracted brightness channels to understand the multi-stream transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68afa3b1",
   "metadata": {
    "id": "68afa3b1"
   },
   "outputs": [],
   "source": [
    "def visualize_rgb_brightness_samples(rgb_data, brightness_data, labels, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize RGB and brightness images side by side.\n",
    "\n",
    "    Args:\n",
    "        rgb_data: RGB image data [N, 3, H, W]\n",
    "        brightness_data: Brightness image data [N, 1, H, W]\n",
    "        labels: Image labels\n",
    "        num_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(8, 2.5 * num_samples))\n",
    "    fig.suptitle('RGB vs Brightness Channel Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Get RGB image (convert from CHW to HWC for matplotlib)\n",
    "        rgb_img = np.transpose(rgb_data[i], (1, 2, 0))\n",
    "\n",
    "        # Get brightness image (squeeze channel dimension)\n",
    "        brightness_img = brightness_data[i, 0]  # Remove channel dimension\n",
    "\n",
    "        # Get class name\n",
    "        class_name = cifar100_fine_labels[labels[i]]\n",
    "\n",
    "        # Plot RGB image\n",
    "        axes[i, 0].imshow(rgb_img)\n",
    "        axes[i, 0].set_title(f'RGB - {class_name}', fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Plot brightness image\n",
    "        axes[i, 1].imshow(brightness_img, cmap='gray')\n",
    "        axes[i, 1].set_title(f'Brightness - {class_name}', fontweight='bold')\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample images\n",
    "print(\"ðŸ–¼ï¸ Sample RGB vs Brightness Images:\")\n",
    "visualize_rgb_brightness_samples(train_rgb, train_brightness, train_labels, num_samples=5)\n",
    "\n",
    "# Show data statistics\n",
    "def show_data_statistics(rgb_data, brightness_data, labels):\n",
    "    \"\"\"Show basic statistics about the data.\"\"\"\n",
    "    print(f\"\\nðŸ“Š Data Statistics:\")\n",
    "    print(f\"   RGB data range: [{rgb_data.min():.3f}, {rgb_data.max():.3f}]\")\n",
    "    print(f\"   Brightness data range: [{brightness_data.min():.3f}, {brightness_data.max():.3f}]\")\n",
    "    print(f\"   Number of unique classes: {len(np.unique(labels))}\")\n",
    "\n",
    "    # Class distribution\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"   Samples per class: {counts.min()} - {counts.max()}\")\n",
    "    print(f\"   Average samples per class: {counts.mean():.1f}\")\n",
    "\n",
    "show_data_statistics(train_rgb, train_brightness, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a90244",
   "metadata": {
    "id": "c4a90244"
   },
   "source": [
    "## 7. Additional Data Visualizations\n",
    "\n",
    "Explore the data with helpful visualizations including class distribution and pixel intensity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394c3b3",
   "metadata": {
    "id": "b394c3b3"
   },
   "outputs": [],
   "source": [
    "# Class distribution visualization\n",
    "def plot_class_distribution(labels, title=\"Class Distribution\"):\n",
    "    \"\"\"Plot the distribution of classes in the dataset.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    plt.bar(unique_labels, counts, alpha=0.7, color='skyblue', edgecolor='navy')\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Class ID')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Pixel intensity histograms\n",
    "def plot_intensity_histograms(rgb_data, brightness_data):\n",
    "    \"\"\"Plot histograms of pixel intensities for RGB and brightness channels.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle('Pixel Intensity Distributions', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # RGB histograms\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    for i, color in enumerate(colors):\n",
    "        axes[0, 0].hist(rgb_data[:, i].flatten(), bins=50, alpha=0.6,\n",
    "                       color=color, label=f'{color.upper()} channel')\n",
    "    axes[0, 0].set_title('RGB Channel Intensities')\n",
    "    axes[0, 0].set_xlabel('Pixel Value')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Brightness histogram\n",
    "    axes[0, 1].hist(brightness_data.flatten(), bins=50, alpha=0.7,\n",
    "                   color='gray', edgecolor='black')\n",
    "    axes[0, 1].set_title('Brightness Channel Intensities')\n",
    "    axes[0, 1].set_xlabel('Pixel Value')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Mean pixel values per channel\n",
    "    rgb_means = np.mean(rgb_data, axis=(0, 2, 3))\n",
    "    brightness_mean = np.mean(brightness_data)\n",
    "\n",
    "    channel_names = ['Red', 'Green', 'Blue', 'Brightness']\n",
    "    channel_means = [rgb_means[0], rgb_means[1], rgb_means[2], brightness_mean]\n",
    "\n",
    "    axes[1, 0].bar(channel_names, channel_means,\n",
    "                  color=['red', 'green', 'blue', 'gray'], alpha=0.7)\n",
    "    axes[1, 0].set_title('Mean Pixel Values by Channel')\n",
    "    axes[1, 0].set_ylabel('Mean Pixel Value')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Sample grid\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Sample grid of images\n",
    "def plot_sample_grid(rgb_data, labels, grid_size=(4, 8)):\n",
    "    \"\"\"Plot a grid of sample images.\"\"\"\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(16, 8))\n",
    "    fig.suptitle('Sample Images from CIFAR-100 Dataset', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for i in range(grid_size[0]):\n",
    "        for j in range(grid_size[1]):\n",
    "            idx = i * grid_size[1] + j\n",
    "            if idx < len(rgb_data):\n",
    "                img = np.transpose(rgb_data[idx], (1, 2, 0))\n",
    "                class_name = cifar100_fine_labels[labels[idx]]\n",
    "\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].set_title(class_name, fontsize=8)\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate visualizations\n",
    "print(\"ðŸ“Š Generating additional visualizations...\")\n",
    "\n",
    "# Class distribution\n",
    "plot_class_distribution(train_labels, \"Training Set Class Distribution\")\n",
    "\n",
    "# Intensity histograms\n",
    "plot_intensity_histograms(train_rgb[:1000], train_brightness[:1000])  # Sample for speed\n",
    "\n",
    "# Sample grid\n",
    "plot_sample_grid(train_rgb, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86919e29",
   "metadata": {
    "id": "86919e29"
   },
   "source": [
    "## 8. Create Multi-Stream Neural Network Models\n",
    "\n",
    "Create both the BaseMultiChannelNetwork (dense) and MultiChannelResNetNetwork (CNN) models for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb91396",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”§ Troubleshooting Appendix\n",
    "\n",
    "**Only run these cells if you encounter specific issues:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ac5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU-only fallback (if CUDA issues persist)\n",
    "print(\"ðŸ”„ Installing CPU-only PyTorch for compatibility...\")\n",
    "\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "!pip install -q numpy==1.24.3 torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install -q tqdm matplotlib seaborn scikit-learn\n",
    "\n",
    "# Test installation\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"âœ… NumPy: {np.__version__}\")\n",
    "print(f\"âœ… PyTorch: {torch.__version__}\")\n",
    "print(f\"âš ï¸ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(\"â„¹ï¸ Note: Using CPU-only version. Training will be slower but more reliable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force NumPy version fix (if NumPy 2.x conflicts occur)\n",
    "print(\"ðŸ”§ Forcing NumPy 1.x for compatibility...\")\n",
    "\n",
    "import numpy as np\n",
    "if np.__version__.startswith('2.'):\n",
    "    print(f\"âš ï¸ NumPy 2.x detected: {np.__version__}\")\n",
    "    !pip install -q \"numpy<2.0\" --force-reinstall\n",
    "    \n",
    "    # Re-import\n",
    "    import importlib\n",
    "    importlib.reload(np)\n",
    "    import numpy as np\n",
    "    print(f\"âœ… NumPy downgraded to: {np.__version__}\")\n",
    "else:\n",
    "    print(f\"âœ… NumPy version OK: {np.__version__}\")\n",
    "\n",
    "# Test PyTorch integration\n",
    "import torch\n",
    "test_array = np.array([1, 2, 3], dtype=np.float32)\n",
    "test_tensor = torch.from_numpy(test_array)\n",
    "print(\"âœ… NumPy-PyTorch integration working!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
