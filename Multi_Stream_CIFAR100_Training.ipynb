{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4f0aae91",
      "metadata": {
        "id": "4f0aae91"
      },
      "source": [
        "# Multi-Stream Neural Networks: CIFAR-100 Training\n",
        "\n",
        "This notebook demonstrates the full pipeline for training multi-stream neural networks on CIFAR-100 data:\n",
        "\n",
        "üöÄ **Features:**\n",
        "- Automatic GPU detection and optimization\n",
        "- RGB to RGBL preprocessing with visualizations\n",
        "- BaseMultiChannelNetwork (Dense) and MultiChannelResNetNetwork (CNN) models\n",
        "- Dynamic progress bars during training\n",
        "- Comprehensive evaluation and analysis\n",
        "\n",
        "**Hardware Requirements:**\n",
        "- Google Colab with GPU runtime (A100/V100 recommended)\n",
        "- Sufficient memory for CIFAR-100 dataset processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7051aee4",
      "metadata": {
        "id": "7051aee4"
      },
      "source": [
        "## 1. Clone Repository and Set Up Working Directory\n",
        "\n",
        "First, we'll clone the Multi-Stream Neural Networks repository to our Google Drive and set up the working directory."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A29FzCJ5c4R",
        "outputId": "9c45fe68-d922-4e02-978d-38efd4c4061d"
      },
      "id": "-A29FzCJ5c4R",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to Drive and clone repository\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "\n",
        "# Clone the repository (replace with your actual repository URL)\n",
        "!git clone https://github.com/clingergab/Multi-Stream-Neural-Networks.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo3JWyNVEGMZ",
        "outputId": "34f5af2f-a23c-4e75-848f-94bbf88fffb4"
      },
      "id": "xo3JWyNVEGMZ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Multi-Stream-Neural-Networks'...\n",
            "remote: Enumerating objects: 228, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 228 (delta 33), reused 221 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (228/228), 258.62 KiB | 2.94 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "432574db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "432574db",
        "outputId": "e6012372-0fbc-4f71-c96a-e18ba6cd3403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content/drive/MyDrive/Multi-Stream-Neural-Networks\n",
            "\n",
            "Directory contents:\n",
            "total 169\n",
            "drwx------ 5 root root  4096 Jun 26 02:28 archive\n",
            "-rw------- 1 root root  3785 Jun 26 02:28 cleanup_comprehensive.py\n",
            "-rw------- 1 root root  5595 Jun 26 02:28 cleanup_empty_files.py\n",
            "drwx------ 5 root root  4096 Jun 26 02:28 configs\n",
            "-rw------- 1 root root 94768 Jun 26 02:28 DESIGN.md\n",
            "drwx------ 2 root root  4096 Jun 26 02:28 docs\n",
            "drwx------ 2 root root  4096 Jun 26 02:28 examples\n",
            "drwx------ 3 root root  4096 Jun 26 02:28 experiments\n",
            "drwx------ 8 root root  4096 Jun 26 02:28 .git\n",
            "-rw------- 1 root root   587 Jun 26 02:28 .gitignore\n",
            "-rw------- 1 root root  1084 Jun 26 02:28 LICENSE\n",
            "drwx------ 2 root root  4096 Jun 26 02:28 notebooks\n",
            "-rw------- 1 root root  4477 Jun 26 02:28 README.md\n",
            "-rw------- 1 root root   106 Jun 26 02:28 requirements.txt\n",
            "-rw------- 1 root root  4892 Jun 26 02:28 safe_cleanup_empty_files.py\n",
            "drwx------ 3 root root  4096 Jun 26 02:28 scripts\n",
            "-rw------- 1 root root   440 Jun 26 02:28 setup.py\n",
            "drwx------ 9 root root  4096 Jun 26 02:28 src\n",
            "drwx------ 7 root root  4096 Jun 26 02:28 tests\n",
            "-rw------- 1 root root  1694 Jun 26 02:28 test_simple.py\n",
            "drwx------ 2 root root  4096 Jun 26 02:28 verification\n",
            "-rw------- 1 root root  1598 Jun 26 02:28 verify_optimizations.py\n",
            "-rw------- 1 root root  5298 Jun 26 02:28 verify_unified_progress_bar.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Change to the project directory\n",
        "os.chdir('/content/drive/MyDrive/Multi-Stream-Neural-Networks')\n",
        "\n",
        "# Verify we're in the right directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"\\nDirectory contents:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac36a39",
      "metadata": {
        "id": "3ac36a39"
      },
      "source": [
        "## 2. Install and Import Required Libraries\n",
        "\n",
        "Install any missing dependencies and import all necessary libraries for the multi-stream neural network training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0c193f97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0c193f97",
        "outputId": "1786d6e3-0a7e-4e72-8267-b9b469dbcf78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=12.4. Please reinstall the torchvision that matches your PyTorch install.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2174902703.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Don't re-order these, we need to load the _C extension (done when importing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0m_check_cuda_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/extension.py\u001b[0m in \u001b[0;36m_check_cuda_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mt_minor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_version\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_major\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtv_major\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;34m\"Detected that PyTorch and torchvision were compiled with different CUDA major versions. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;34mf\"PyTorch has CUDA Version={t_major}.{t_minor} and torchvision has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=12.4. Please reinstall the torchvision that matches your PyTorch install."
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install tqdm matplotlib seaborn scikit-learn\n",
        "\n",
        "# System and utility imports\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project to Python path\n",
        "sys.path.append('/content/drive/MyDrive/Multi-Stream-Neural-Networks')\n",
        "\n",
        "# Core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Data and visualization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import pickle\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üì¶ All libraries imported successfully!\")\n",
        "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"üöÄ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4abf9ff",
      "metadata": {
        "id": "d4abf9ff"
      },
      "source": [
        "## 3. Load CIFAR-100 Dataset\n",
        "\n",
        "Load the CIFAR-100 dataset from the data folder. We assume the data folder structure matches the repository structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0884a06",
      "metadata": {
        "id": "a0884a06"
      },
      "outputs": [],
      "source": [
        "# Import our data loading utilities\n",
        "from src.utils.colab_utils import load_cifar10  # We'll adapt this for CIFAR-100\n",
        "\n",
        "# Check if data folder exists\n",
        "data_path = \"data/cifar-100\"\n",
        "if os.path.exists(data_path):\n",
        "    print(f\"‚úÖ Data folder found at: {data_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Data folder not found. Creating data structure...\")\n",
        "    os.makedirs(data_path, exist_ok=True)\n",
        "    print(\"üìÅ Please manually upload CIFAR-100 data to the data folder\")\n",
        "\n",
        "# Define CIFAR-100 classes for reference\n",
        "cifar100_fine_labels = [\n",
        "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
        "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
        "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
        "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
        "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
        "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
        "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
        "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
        "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
        "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
        "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
        "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
        "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
        "    'worm'\n",
        "]\n",
        "\n",
        "# Load CIFAR-100 data using torchvision (fallback if data folder is empty)\n",
        "def load_cifar100_data():\n",
        "    # Transform to convert PIL images to tensors\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    try:\n",
        "        # Try loading from local data folder first\n",
        "        train_dataset = torchvision.datasets.CIFAR100(\n",
        "            root='./data', train=True, download=False, transform=transform\n",
        "        )\n",
        "        test_dataset = torchvision.datasets.CIFAR100(\n",
        "            root='./data', train=False, download=False, transform=transform\n",
        "        )\n",
        "        print(\"‚úÖ Loaded CIFAR-100 from local data folder\")\n",
        "    except:\n",
        "        # Download if not available locally\n",
        "        print(\"‚¨áÔ∏è Downloading CIFAR-100 dataset...\")\n",
        "        train_dataset = torchvision.datasets.CIFAR100(\n",
        "            root='./data', train=True, download=True, transform=transform\n",
        "        )\n",
        "        test_dataset = torchvision.datasets.CIFAR100(\n",
        "            root='./data', train=False, download=True, transform=transform\n",
        "        )\n",
        "        print(\"‚úÖ CIFAR-100 dataset downloaded and loaded\")\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# Load the datasets\n",
        "train_dataset, test_dataset = load_cifar100_data()\n",
        "\n",
        "print(f\"üìä Dataset Info:\")\n",
        "print(f\"   Training samples: {len(train_dataset)}\")\n",
        "print(f\"   Test samples: {len(test_dataset)}\")\n",
        "print(f\"   Number of classes: 100\")\n",
        "print(f\"   Image size: 32x32x3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6ae3dd",
      "metadata": {
        "id": "1a6ae3dd"
      },
      "source": [
        "## 4. Preprocess Data: RGB to RGBL Transformation\n",
        "\n",
        "Apply preprocessing to convert RGB images to both RGB and brightness (luminance) channels. This creates our multi-stream data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945c9ead",
      "metadata": {
        "id": "945c9ead"
      },
      "outputs": [],
      "source": [
        "# Import our RGB to RGBL transformation\n",
        "from src.transforms.rgb_to_rgbl import RGBtoRGBL\n",
        "\n",
        "def convert_dataset_to_multi_stream(dataset, max_samples=None):\n",
        "    \"\"\"\n",
        "    Convert a CIFAR-100 dataset to multi-stream format (RGB + Brightness).\n",
        "\n",
        "    Args:\n",
        "        dataset: CIFAR-100 dataset\n",
        "        max_samples: Maximum number of samples to process (for faster testing)\n",
        "\n",
        "    Returns:\n",
        "        rgb_data: RGB channel data [N, 3, 32, 32]\n",
        "        brightness_data: Brightness channel data [N, 1, 32, 32]\n",
        "        labels: Class labels [N]\n",
        "    \"\"\"\n",
        "    print(f\"üîÑ Converting dataset to multi-stream format...\")\n",
        "\n",
        "    # Initialize RGB to RGBL transform\n",
        "    rgb_to_rgbl = RGBtoRGBL()\n",
        "\n",
        "    # Determine number of samples to process\n",
        "    num_samples = len(dataset) if max_samples is None else min(max_samples, len(dataset))\n",
        "\n",
        "    # Initialize arrays\n",
        "    rgb_data = []\n",
        "    brightness_data = []\n",
        "    labels = []\n",
        "\n",
        "    # Process samples with progress bar\n",
        "    for i in tqdm(range(num_samples), desc=\"Processing images\"):\n",
        "        image, label = dataset[i]\n",
        "\n",
        "        # Convert to RGBL\n",
        "        rgbl_image = rgb_to_rgbl(image)\n",
        "\n",
        "        # Split RGB and brightness channels\n",
        "        rgb_channels = rgbl_image[:3]  # First 3 channels (RGB)\n",
        "        brightness_channel = rgbl_image[3:4]  # Last channel (Brightness)\n",
        "\n",
        "        rgb_data.append(rgb_channels)\n",
        "        brightness_data.append(brightness_channel)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    rgb_data = torch.stack(rgb_data).numpy()\n",
        "    brightness_data = torch.stack(brightness_data).numpy()\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    print(f\"‚úÖ Conversion complete!\")\n",
        "    print(f\"   RGB data shape: {rgb_data.shape}\")\n",
        "    print(f\"   Brightness data shape: {brightness_data.shape}\")\n",
        "    print(f\"   Labels shape: {labels.shape}\")\n",
        "\n",
        "    return rgb_data, brightness_data, labels\n",
        "\n",
        "# Convert training data (use subset for faster processing in demo)\n",
        "print(\"üöÄ Processing training data...\")\n",
        "train_rgb, train_brightness, train_labels = convert_dataset_to_multi_stream(\n",
        "    train_dataset, max_samples=5000  # Reduce for faster demo\n",
        ")\n",
        "\n",
        "# Convert test data (use subset for faster processing in demo)\n",
        "print(\"\\nüß™ Processing test data...\")\n",
        "test_rgb, test_brightness, test_labels = convert_dataset_to_multi_stream(\n",
        "    test_dataset, max_samples=1000  # Reduce for faster demo\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Final Dataset Shapes:\")\n",
        "print(f\"   Training RGB: {train_rgb.shape}\")\n",
        "print(f\"   Training Brightness: {train_brightness.shape}\")\n",
        "print(f\"   Training Labels: {train_labels.shape}\")\n",
        "print(f\"   Test RGB: {test_rgb.shape}\")\n",
        "print(f\"   Test Brightness: {test_brightness.shape}\")\n",
        "print(f\"   Test Labels: {test_labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73e3a1b",
      "metadata": {
        "id": "e73e3a1b"
      },
      "source": [
        "## 5. Visualize Sample Images: RGB and Brightness Side by Side\n",
        "\n",
        "Display sample images showing the original RGB and extracted brightness channels to understand the multi-stream transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68afa3b1",
      "metadata": {
        "id": "68afa3b1"
      },
      "outputs": [],
      "source": [
        "def visualize_rgb_brightness_samples(rgb_data, brightness_data, labels, num_samples=5):\n",
        "    \"\"\"\n",
        "    Visualize RGB and brightness images side by side.\n",
        "\n",
        "    Args:\n",
        "        rgb_data: RGB image data [N, 3, H, W]\n",
        "        brightness_data: Brightness image data [N, 1, H, W]\n",
        "        labels: Image labels\n",
        "        num_samples: Number of samples to visualize\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(num_samples, 2, figsize=(8, 2.5 * num_samples))\n",
        "    fig.suptitle('RGB vs Brightness Channel Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Get RGB image (convert from CHW to HWC for matplotlib)\n",
        "        rgb_img = np.transpose(rgb_data[i], (1, 2, 0))\n",
        "\n",
        "        # Get brightness image (squeeze channel dimension)\n",
        "        brightness_img = brightness_data[i, 0]  # Remove channel dimension\n",
        "\n",
        "        # Get class name\n",
        "        class_name = cifar100_fine_labels[labels[i]]\n",
        "\n",
        "        # Plot RGB image\n",
        "        axes[i, 0].imshow(rgb_img)\n",
        "        axes[i, 0].set_title(f'RGB - {class_name}', fontweight='bold')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Plot brightness image\n",
        "        axes[i, 1].imshow(brightness_img, cmap='gray')\n",
        "        axes[i, 1].set_title(f'Brightness - {class_name}', fontweight='bold')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize sample images\n",
        "print(\"üñºÔ∏è Sample RGB vs Brightness Images:\")\n",
        "visualize_rgb_brightness_samples(train_rgb, train_brightness, train_labels, num_samples=5)\n",
        "\n",
        "# Show data statistics\n",
        "def show_data_statistics(rgb_data, brightness_data, labels):\n",
        "    \"\"\"Show basic statistics about the data.\"\"\"\n",
        "    print(f\"\\nüìä Data Statistics:\")\n",
        "    print(f\"   RGB data range: [{rgb_data.min():.3f}, {rgb_data.max():.3f}]\")\n",
        "    print(f\"   Brightness data range: [{brightness_data.min():.3f}, {brightness_data.max():.3f}]\")\n",
        "    print(f\"   Number of unique classes: {len(np.unique(labels))}\")\n",
        "\n",
        "    # Class distribution\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    print(f\"   Samples per class: {counts.min()} - {counts.max()}\")\n",
        "    print(f\"   Average samples per class: {counts.mean():.1f}\")\n",
        "\n",
        "show_data_statistics(train_rgb, train_brightness, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a90244",
      "metadata": {
        "id": "c4a90244"
      },
      "source": [
        "## 6. Additional Data Visualizations\n",
        "\n",
        "Let's explore the data with helpful visualizations including class distribution and pixel intensity analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b394c3b3",
      "metadata": {
        "id": "b394c3b3"
      },
      "outputs": [],
      "source": [
        "# Class distribution visualization\n",
        "def plot_class_distribution(labels, title=\"Class Distribution\"):\n",
        "    \"\"\"Plot the distribution of classes in the dataset.\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "    plt.bar(unique_labels, counts, alpha=0.7, color='skyblue', edgecolor='navy')\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Class ID')\n",
        "    plt.ylabel('Number of Samples')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Pixel intensity histograms\n",
        "def plot_intensity_histograms(rgb_data, brightness_data):\n",
        "    \"\"\"Plot histograms of pixel intensities for RGB and brightness channels.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    fig.suptitle('Pixel Intensity Distributions', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # RGB histograms\n",
        "    colors = ['red', 'green', 'blue']\n",
        "    for i, color in enumerate(colors):\n",
        "        axes[0, 0].hist(rgb_data[:, i].flatten(), bins=50, alpha=0.6,\n",
        "                       color=color, label=f'{color.upper()} channel')\n",
        "    axes[0, 0].set_title('RGB Channel Intensities')\n",
        "    axes[0, 0].set_xlabel('Pixel Value')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Brightness histogram\n",
        "    axes[0, 1].hist(brightness_data.flatten(), bins=50, alpha=0.7,\n",
        "                   color='gray', edgecolor='black')\n",
        "    axes[0, 1].set_title('Brightness Channel Intensities')\n",
        "    axes[0, 1].set_xlabel('Pixel Value')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Mean pixel values per channel\n",
        "    rgb_means = np.mean(rgb_data, axis=(0, 2, 3))\n",
        "    brightness_mean = np.mean(brightness_data)\n",
        "\n",
        "    channel_names = ['Red', 'Green', 'Blue', 'Brightness']\n",
        "    channel_means = [rgb_means[0], rgb_means[1], rgb_means[2], brightness_mean]\n",
        "\n",
        "    axes[1, 0].bar(channel_names, channel_means,\n",
        "                  color=['red', 'green', 'blue', 'gray'], alpha=0.7)\n",
        "    axes[1, 0].set_title('Mean Pixel Values by Channel')\n",
        "    axes[1, 0].set_ylabel('Mean Pixel Value')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Sample grid\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Sample grid of images\n",
        "def plot_sample_grid(rgb_data, labels, grid_size=(4, 8)):\n",
        "    \"\"\"Plot a grid of sample images.\"\"\"\n",
        "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(16, 8))\n",
        "    fig.suptitle('Sample Images from CIFAR-100 Dataset', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for i in range(grid_size[0]):\n",
        "        for j in range(grid_size[1]):\n",
        "            idx = i * grid_size[1] + j\n",
        "            if idx < len(rgb_data):\n",
        "                img = np.transpose(rgb_data[idx], (1, 2, 0))\n",
        "                class_name = cifar100_fine_labels[labels[idx]]\n",
        "\n",
        "                axes[i, j].imshow(img)\n",
        "                axes[i, j].set_title(class_name, fontsize=8)\n",
        "                axes[i, j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate visualizations\n",
        "print(\"üìä Generating additional visualizations...\")\n",
        "\n",
        "# Class distribution\n",
        "plot_class_distribution(train_labels, \"Training Set Class Distribution\")\n",
        "\n",
        "# Intensity histograms\n",
        "plot_intensity_histograms(train_rgb[:1000], train_brightness[:1000])  # Sample for speed\n",
        "\n",
        "# Sample grid\n",
        "plot_sample_grid(train_rgb, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86919e29",
      "metadata": {
        "id": "86919e29"
      },
      "source": [
        "## 7. Create Multi-Stream Neural Network Models\n",
        "\n",
        "Now we'll create both the BaseMultiChannelNetwork (dense) and MultiChannelResNetNetwork (CNN) models for comparison."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}